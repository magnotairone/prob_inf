## 24 Introdução: O Dilema do Teste A/B

Imagine que você é um Cientista de Dados em uma empresa de e-commerce. O time de design propõe um novo botão de "Comprar" (Versão B), com uma cor diferente, alegando que ele aumentará a taxa de cliques em relação ao botão atual (Versão A).

Para validar essa hipótese, você implementa um teste A/B: 500 usuários aleatórios veem a Versão A, e outros 500 veem a Versão B. Ao final do experimento, você observa os resultados:

* **Versão A (Controle):** 25 cliques em 500 visualizações (taxa de 5%).
* **Versão B (Tratamento):** 30 cliques em 500 visualizações (taxa de 6%).

A Versão B parece melhor. Mas a pergunta central que define a sua carreira como cientista é: **essa diferença de 1% é real e significativa, ou pode ser apenas fruto do acaso?** Se mostrarmos os botões para outros 500 usuários, talvez os resultados se invertam.

Para responder a essa pergunta com confiança, precisamos de um framework rigoroso para "aprender" sobre a realidade a partir de dados limitados e ruidosos. Esta aula irá construir esse framework, peça por peça, usando a inferência estatística.

## O Framework da Inferência: Do Problema à Modelagem

O primeiro passo é traduzir nosso problema prático para uma linguagem matemática formal.

* **Dados (observações):** Os dados são valores observados de variáveis aleatórias que seguem uma distribuição de probabilidade conjunta P, que pertence a uma classe (conhecida) $\mathcal{P}$. Frequentemente, $\mathcal{P}$ é indexada por um parâmetro $\theta \in \Theta$.
    $$ \mathcal{P} = \{ P_{\theta}, \theta \in \Theta \} $$

* **Objetivo:** fazer inferência sobre $\theta$ ou $g(\theta)$ com base nos dados observados.
    * estimação pontual ou intervalar
    * teste de hipóteses

> **Perspectiva de Data Science:**
>
> * **Parâmetro ($\theta$): A Verdade Oculta.** $\theta$ é a **verdadeira, mas desconhecida, taxa de cliques** de um botão se pudéssemos mostrá-lo a um número infinito de usuários. É a realidade que queremos descobrir. No nosso caso, temos dois parâmetros de interesse: $\theta_A$ e $\theta_B$.
> * **Modelo ($\mathcal{P}$): Nossa Hipótese sobre o Mundo.** $\mathcal{P}$ é a nossa **escolha de modelagem**. Ao rodar o teste A/B, assumimos que a decisão de cada usuário de clicar (ou não) é um evento independente, como um "cara ou coroa" com uma moeda viciada. Esse processo é descrito pela **distribuição de Bernoulli**. Portanto, nosso modelo para a Versão B é a família de todas as distribuições de Bernoulli, $\mathcal{P} = \{ \text{Bernoulli}(\theta_B), \theta_B \in [0, 1] \}$.

## Estimação Pontual: O Melhor Chute a partir dos Dados

Nosso primeiro objetivo é usar os dados para dar um "chute" único e bem fundamentado sobre o valor do nosso parâmetro $\theta$.

**Ingredientes:**

1.  Uma função real g, definida no espaço paramétrico $\Theta$, cujo valor $g(\theta)$ é o que gostaríamos de obter informação / estimar.
    $g(\theta)$: **estimando**.

2.  Um vetor aleatório $\underline{X}$ (observável) tomando valores no espaço amostral $\mathcal{X}$, de acordo com uma distribuição $P_{\theta} \in \mathcal{P}$. O valor observado de $\underline{X}$, $\underline{x}$ é o conjunto de dados. Muitas vezes, nos referimos a $\underline{X} = (X_1, ..., X_n)$ como **amostra**.

**Ideia:** especificar um valor plausível para $g(\theta)$.

::: {#def-estatistica-estimador name="Estatística e Estimador"}
Qualquer função da amostra $\underline{X}$ que não depende de quantidades desconhecidas é uma **estatística**. Uma estatística usada para estimar $g(\theta)$ é chamada de **estimador**.

**Notação:**

* Estatística: $T = T(X_1, ..., X_n)$
* Estimador: $\delta = \delta(X_1, ..., X_n)$ ou $\hat{\theta} = \hat{\theta}(X_1, ..., X_n)$
* Valor observado do estimador, isto é $\delta(\underline{x})$, é chamado de **estimativa**.
:::

> **Perspectiva de Data Science:**
>
> * **Amostra ($\underline{X}$): A Evidência Coletada.** Para o botão B, nossa amostra é um vetor de 500 elementos, $\underline{X} = (X_1, ..., X_{500})$, onde $X_i=1$ se o i-ésimo usuário clicou, e $X_i=0$ caso contrário.
> * **Estimador ($\hat{\theta}$): Nosso Algoritmo de Aprendizagem.** O estimador é a **receita** ou **algoritmo** que transforma os dados brutos em um chute para $\theta$. A receita mais intuitiva para estimar a taxa de cliques é simplesmente calcular a média da amostra: $\hat{\theta}_B = \bar{X}_n = \frac{1}{n}\sum X_i$.
> * **Estimativa:** A estimativa é o número que nosso algoritmo produz: $\hat{\theta}_B(\underline{x}) = 30/500 = 0.06$.

::: {#exm-vida-lampada name="Tempo de Vida de Lâmpadas"}
Seja X = tempo de vida de lâmpadas de certa marca. Assuma que $X \sim \text{exp}(\theta)$, $\theta > 0$. Suponha que $(X_1, ..., X_n)$ é uma a.a. de X.

Aqui, temos que $\mathcal{P} = \{f_{\theta}, \theta > 0\}$, com $f_{\theta}(x) = \theta e^{-\theta x} \mathbb{I}_{(0, \infty)}(x)$.

**Exemplos de estatísticas:**

* $S_n = X_1 + ... + X_n$ (tempo total de vida)
* $X_{(1)} = \min\{X_1, ..., X_n\}$ (menor tempo de vida)
* $\bar{X}_n = \frac{1}{n} \sum_{i=1}^{n} X_i$ (média amostral dos tempos de vida)
* $S_n^2 = \frac{1}{n-1} \sum_{i=1}^{n} (X_i - \bar{X}_n)^2$ (variância amostral)

Qual é um estimador razoável para o tempo médio de vida? E para $\theta$?

* $g(\theta) = E_{\theta}(X) = \frac{1}{\theta} \rightarrow$ possível estimador: $\widehat{g(\theta)} = \bar{X}_n$.
* $g(\theta) = \theta \rightarrow$ possível estimador: $\hat{\theta} = \frac{1}{\bar{X}_n}$.
:::

## O Motor da Inferência: A Função de Verossimilhança

Temos um algoritmo intuitivo para estimar $\theta$ (a média amostral), mas como podemos justificar que ele é um bom algoritmo? E se houvesse outros? A resposta está em um dos conceitos mais importantes da estatística e do Machine Learning: a **verossimilhança**.

A verossimilhança responde à seguinte pergunta: **"Dado os dados que observei, qual valor do parâmetro $\theta$ torna minhas observações mais prováveis (ou menos surpreendentes)?"**

Ela funciona como uma função de pontuação (score) para diferentes hipóteses sobre a "verdade" $\theta$.

::: {#def-verossimilhanca name="Função de Verossimilhança"}
A função de verossimilhança de $\theta \in \Theta$, com base na amostra observada $\underline{x} = (x_1, ..., x_n)$, é dada por
$$ L(\theta) = L(\theta; \underline{x}) = f_{X_1, ..., X_n}(x_1, ..., x_n; \theta), \quad \theta \in \Theta $$

**Nota:** se $\underline{X}$ é uma a.a. de X, então $L(\theta) = \prod_{i=1}^{n} f_X(x_i; \theta)$ (i.i.d.'s)
:::

::: {#exm-funcoes-verossimilhanca name="Funções de Verossimilhança"}
Obtenha a função de verossimilhança em cada caso assumindo uma a.a. $\underline{X} = (X_1, ..., X_n)$ de X.

**a) $X \sim \text{Bernoulli}(\theta)$**
$$ L(\theta) = \prod_{i=1}^{n} \theta^{x_i} (1-\theta)^{1-x_i} = \theta^{\sum_{i=1}^{n} x_i} (1-\theta)^{n - \sum_{i=1}^{n} x_i}, \quad \theta \in (0,1). $$
$\rightarrow L(\theta)$ depende da realização de $T = \sum_{i=1}^{n} X_i$.

> **Conexão com o Teste A/B:** Esta é exatamente a função de verossimilhança para o nosso problema! Para o botão B, observamos $\sum x_i = 30$ e $n=500$. A função se torna $L(\theta_B) = \theta_B^{30}(1-\theta_B)^{470}$. Agora podemos "testar" diferentes valores de $\theta_B$ e ver qual deles maximiza essa função. O valor que a maximiza é, de fato, $30/500 = 0.06$, justificando nosso estimador intuitivo. Este é o **Princípio da Máxima Verossimilhança**.

**b) $X \sim \text{Poisson}(\theta)$**
$$ L(\theta) = \prod_{i=1}^{n} \frac{e^{-\theta} \theta^{x_i}}{x_i!} = \frac{e^{-n\theta} \theta^{\sum_{i=1}^{n} x_i}}{\prod_{i=1}^{n} x_i!}, \quad \theta > 0. $$
$\rightarrow L(\theta)$ depende da realização de $T = \sum_{i=1}^{n} X_i$.

**c) $X \sim U(0, \theta)$, $\theta > 0$**
$$ L(\theta) = \prod_{i=1}^{n} f_{\theta}(x_i) = \prod_{i=1}^{n} \frac{1}{\theta} \mathbb{I}_{(0, \theta)}(x_i) = \frac{1}{\theta^n} \prod_{i=1}^{n} \mathbb{I}_{(0, \theta)}(x_i) $$
A indicadora $\prod_{i=1}^{n} \mathbb{I}_{(0, \theta)}(x_i) = 1$ se, e somente se, $0 < x_i < \theta$ para todo $i=1, ..., n$, o que é equivalente a $0 < x_{(1)} \le ... \le x_{(n)} < \theta$.
Então,
$$ L(\theta) = \frac{1}{\theta^n} \mathbb{I}_{(x_{(n)}, \infty)}(\theta), \quad \theta > 0 $$
$\rightarrow L(\theta)$ envolve a realização de $T = X_{(n)}$.

**d) $X \sim N(\mu, \sigma^2)$, $\theta = (\mu, \sigma^2)$, $\mu \in \mathbb{R}, \sigma^2 > 0$**
$$ L(\theta) = \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x_i - \mu)^2}{2\sigma^2}} = \frac{1}{(2\pi\sigma^2)^{n/2}} e^{-\frac{1}{2\sigma^2} \sum_{i=1}^{n} (x_i - \mu)^2} $$
$$ = \frac{1}{(2\pi)^{n/2}} \frac{1}{(\sigma^2)^{n/2}} \exp\left\{-\frac{1}{2\sigma^2} \sum_{i=1}^{n} (x_i^2 - 2x_i\mu + \mu^2)\right\} $$
$$ = \frac{1}{(2\pi)^{n/2}} \frac{1}{(\sigma^2)^{n/2}} \exp\left\{-\frac{1}{2\sigma^2} \sum_{i=1}^{n} x_i^2 + \frac{\mu}{\sigma^2} \sum_{i=1}^{n} x_i - \frac{n\mu^2}{2\sigma^2}\right\}, \quad \mu \in \mathbb{R}, \sigma^2 > 0. $$
$\rightarrow L(\theta)$ envolve a realização de $T_n = (\sum_{i=1}^{n} X_i^2, \sum_{i=1}^{n} X_i)$.
:::

> **Conexão com Machine Learning:**
> O processo de "treinar" um modelo de Machine Learning (como uma Regressão Logística ou mesmo uma rede neural para classificação) é, em sua essência, um processo de otimização para encontrar os parâmetros do modelo ($\theta$) que **maximizam a função de verossimilhança** (ou a log-verossimilhança) para os dados de treinamento. O framework que construímos aqui é a base teórica para a maior parte do aprendizado de máquina supervisionado.


