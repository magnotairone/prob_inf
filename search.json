[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Probabilidade e Inferência Estatística para Ciência de Dados",
    "section": "",
    "text": "Introdução\nNotas de aula de um curso de Probabilidade e Inferência para Ciência de Dados. Baseado nas notas de aula do curso MAE5702 do professor Felipe de Queiroz, a quem agradeço pela gentil disponibilização do material.",
    "crumbs": [
      "Introdução"
    ]
  },
  {
    "objectID": "010_probabilidade.html",
    "href": "010_probabilidade.html",
    "title": "Módulo Probabilidade",
    "section": "",
    "text": "TODO: descrever essa parte",
    "crumbs": [
      "Módulo Probabilidade"
    ]
  },
  {
    "objectID": "aula01.html",
    "href": "aula01.html",
    "title": "1  Introdução: Da Teoria à Prática Analítica",
    "section": "",
    "text": "1.1 A Linguagem dos Dados: Conjuntos e Eventos\nImagine que você trabalha como Cientista de Dados em uma empresa de streaming de música. Uma pergunta fundamental do negócio é: “Quais são os nossos perfis de usuários? Quem são os ouvintes leais e quem são os esporádicos?”. Para responder a isso, você tem acesso aos dados de login de cada usuário, mês a mês.\nComo poderíamos definir matematicamente o que significa ser um “ouvinte leal”? Seria alguém que logou todos os meses? Ou alguém que, a partir de certo ponto, nunca mais deixou de logar? E o “ouvinte esporádico”? Seria aquele que, mesmo que desapareça por alguns meses, sempre acaba voltando?\nPara responder a essas perguntas de forma precisa e rigorosa, precisamos de uma linguagem formal. Essa linguagem é a Teoria dos Conjuntos. Nesta aula, vamos construir o alicerce matemático que nos permitirá não apenas estruturar nosso pensamento analítico, mas também desenvolver as ferramentas para analisar o comportamento de sistemas que evoluem ao longo do tempo. Cada definição e proposição que veremos é um passo em direção à solução do nosso problema.\nPara analisar dados, primeiro precisamos defini-los. A teoria dos conjuntos nos fornece o vocabulário fundamental para isso.",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução: Da Teoria à Prática Analítica</span>"
    ]
  },
  {
    "objectID": "aula01.html#a-linguagem-dos-dados-conjuntos-e-eventos",
    "href": "aula01.html#a-linguagem-dos-dados-conjuntos-e-eventos",
    "title": "1  Introdução: Da Teoria à Prática Analítica",
    "section": "",
    "text": "Definição 1.1 (Conjunto) Um conjunto \\(\\Omega\\) é uma coleção de objetos distintos, que serão denotados por \\(\\omega\\).\n\n\\(\\omega \\in \\Omega\\) (elemento \\(\\omega\\) pertence ao conjunto \\(\\Omega\\)).\n\\(\\omega \\notin \\Omega\\) (elemento \\(\\omega\\) não pertence ao conjunto \\(\\Omega\\)).\n\n\n\nPerspectiva de Data Science: Pense no conjunto universal \\(\\Omega\\) como todo o seu universo de dados, ou espaço amostral. Cada elemento \\(\\omega\\) é uma unidade observacional: um cliente, uma transação, um produto. Por exemplo, \\(\\Omega\\) pode ser “o conjunto de todos os usuários da nossa plataforma”.\n\n\nDefinição 1.2 (Subconjunto) Dizemos que A é um subconjunto de \\(\\Omega\\), ou que A está contido em \\(\\Omega\\), e denotamos por \\(A \\subseteq \\Omega\\), se \\(\\forall \\omega \\in A \\rightarrow \\omega \\in \\Omega\\).\n\n\nPerspectiva de Data Science: Um subconjunto é um segmento de interesse ou um evento dentro do seu universo de dados, geralmente obtido através de um filtro ou consulta.\n\nSe \\(\\Omega\\) é o conjunto de todos os usuários, um subconjunto \\(A\\) pode ser: \\(A = \\{\\)usuários do plano Premium\\(\\}\\).\nOutro subconjunto \\(B\\) poderia ser: \\(B = \\{\\)usuários que ouviram mais de 100 horas de música no último mês\\(\\}\\).",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução: Da Teoria à Prática Analítica</span>"
    ]
  },
  {
    "objectID": "aula01.html#a-gramática-da-análise-operações-com-conjuntos",
    "href": "aula01.html#a-gramática-da-análise-operações-com-conjuntos",
    "title": "1  Introdução: Da Teoria à Prática Analítica",
    "section": "1.2 A Gramática da Análise: Operações com Conjuntos",
    "text": "1.2 A Gramática da Análise: Operações com Conjuntos\nCom nossos segmentos definidos, precisamos de uma forma de combiná-los e compará-los. As operações com conjuntos são a “gramática” que nos permite realizar análises complexas.\nSejam A, \\(A_1\\), \\(A_2\\),… subconjuntos de \\(\\Omega\\). Temos as seguintes operações:\n\nComplementar de A: \\(A^{c} = \\{ \\omega \\in \\Omega : \\omega \\notin A \\}\\).\nUnião: \\(\\bigcup_{i=1}^{n} A_{i} = \\{ \\omega \\in \\Omega : \\omega \\in A_{i} \\text{ para ao menos um } i=1,2,...,n \\}\\).\nIntersecção: \\(\\bigcap_{i=1}^{n} A_{i} = \\{ \\omega \\in \\Omega : \\omega \\in A_{i}, \\forall i=1,...,n \\}\\).\nDiferença: \\(A_{1} - A_{2} = \\{ \\omega \\in \\Omega : \\omega \\in A_{1}, \\omega \\notin A_{2} \\} = A_{1} \\cap A_{2}^{c}\\).\nDiferença simétrica: \\(A_{1} \\Delta A_{2} = (A_{1} - A_{2}) \\cup (A_{2} - A_{1}) = (A_{1} \\cap A_{2}^{c}) \\cup (A_{1}^{c} \\cap A_{2})\\).\n\n\nConjunto vazio (\\(\\emptyset\\)): não contém nenhum elemento.\n\n\nPerspectiva de Data Science: Cada operação corresponde diretamente a uma operação lógica em uma consulta de dados:\n\nIntersecção (\\(A \\cap B\\)) é a lógica E (AND). Ex: “Usuários do plano Premium E que ouviram mais de 100 horas”.\nUnião (\\(A \\cup B\\)) é a lógica OU (OR). Ex: “Usuários do plano Premium OU que ouviram mais de 100 horas”.\nComplementar (\\(A^c\\)) é a lógica NÃO (NOT). Ex: “Usuários que NÃO são do plano Premium”.\n\n\n\nDefinição 1.3 (Relações entre Conjuntos)  \n\nDizemos que \\(A_{1}\\) e \\(A_{2}\\) são disjuntos se \\(A_{1} \\cap A_{2} = \\emptyset\\).\nDizemos que \\(A_{1} = A_{2}\\) se \\(A_{1} \\subseteq A_{2}\\) e \\(A_{2} \\subseteq A_{1}\\).\nDizemos que \\(A_1, A_2, ...\\) são mutuamente disjuntos se \\(A_{i} \\cap A_{j} = \\emptyset\\), \\(\\forall i \\neq j\\).\n\n\n\nProposição 1.1 (Lei de De Morgan) Sejam \\(A_{1}, A_{2}, ...\\) subconjuntos de \\(\\Omega\\). Então:\n\n\\((\\bigcup_{i=1}^{\\infty} A_{i})^{c} = \\bigcap_{i=1}^{\\infty} A_{i}^{c}\\)\n\\((\\bigcap_{i=1}^{\\infty} A_{i})^{c} = \\bigcup_{i=1}^{\\infty} A_{i}^{c}\\)\n\n\n\nNota: As Leis de De Morgan são extremamente úteis para simplificar consultas lógicas complexas. A negação de uma condição “OU” ampla é o mesmo que exigir que todas as condições “E” individuais sejam falsas.\n\nDemonstração (a):\nPrecisamos mostrar que \\((\\bigcup_{i=1}^{\\infty} A_{i})^{c} \\subseteq \\bigcap_{i=1}^{\\infty} A_{i}^{c}\\) e \\(\\bigcap_{i=1}^{\\infty} A_{i}^{c} \\subseteq (\\bigcup_{i=1}^{\\infty} A_{i})^{c}.\\)\nParte 1: \\((\\bigcup_{i=1}^{\\infty} A_{i})^{c} \\subseteq \\bigcap_{i=1}^{\\infty} A_{i}^{c}\\)\n\nTome \\(\\omega \\in (\\bigcup_{i=1}^{\\infty} A_{i})^{c}\\)\n\\(\\Rightarrow \\omega \\notin \\bigcup_{i=1}^{\\infty} A_{i}\\) (Por definição de complementar)\n\\(\\Rightarrow \\omega \\notin A_{i}, \\forall i=1,2,...\\) (Se não está na união, não está em nenhum conjunto)\n\\(\\Rightarrow \\omega \\in A_{i}^{c}, \\forall i=1,2,...\\) (Por definição de complementar)\n\\(\\Rightarrow \\omega \\in \\bigcap_{i=1}^{\\infty} A_{i}^{c}\\) (Se pertence a todos os complementares, pertence à intersecção deles)\n\nParte 2: \\(\\bigcap_{i=1}^{\\infty} A_{i}^{c} \\subseteq (\\bigcup_{i=1}^{\\infty} A_{i})^{c}\\)\n\nTome \\(\\omega \\in \\bigcap_{i=1}^{\\infty} A_{i}^{c}\\)\n\\(\\Rightarrow \\omega \\in A_{i}^{c}, \\forall i=1,2,...\\) (Por definição de intersecção)\n\\(\\Rightarrow \\omega \\notin A_{i}, \\forall i=1,2,...\\) (Por definição de complementar)\n\\(\\Rightarrow \\omega \\notin \\bigcup_{i=1}^{\\infty} A_{i}\\) (Se não está em nenhum conjunto, não está na união)\n\\(\\Rightarrow \\omega \\in (\\bigcup_{i=1}^{\\infty} A_{i})^{c}\\) (Por definição de complementar)",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução: Da Teoria à Prática Analítica</span>"
    ]
  },
  {
    "objectID": "aula01.html#análise-dinâmica-sequências-de-conjuntos",
    "href": "aula01.html#análise-dinâmica-sequências-de-conjuntos",
    "title": "1  Introdução: Da Teoria à Prática Analítica",
    "section": "1.3 Análise Dinâmica: Sequências de Conjuntos",
    "text": "1.3 Análise Dinâmica: Sequências de Conjuntos\nAgora, voltamos ao nosso problema original: analisar o comportamento dos usuários ao longo do tempo. Para isso, introduzimos o conceito de sequências de conjuntos.\n\nDefinição 1.4 (Sequência Monótona) Uma sequência \\(\\{A_{n}\\}_{n \\ge 1}\\) é dita ser monótona se:\n\n\\(A_{1} \\subseteq A_{2} \\subseteq A_{3} \\subseteq ...\\) (isto é, \\(A_n\\) é não decrescente, denotado por \\(A_n \\uparrow\\)).\n\\(A_{1} \\supseteq A_{2} \\supseteq A_{3} \\supseteq ...\\) (isto é, \\(A_n\\) é não crescente, denotado por \\(A_n \\downarrow\\)).\n\nO limite de uma sequência monótona é denotado por:\n\nse \\(A_n \\uparrow\\), \\(\\lim_{n \\to \\infty} A_{n} = \\bigcup_{i=1}^{\\infty} A_{i}\\).\nse \\(A_n \\downarrow\\), \\(\\lim_{n \\to \\infty} A_{n} = \\bigcap_{i=1}^{\\infty} A_{i}\\).\n\n\n\nPerspectiva de Data Science: Sequências monótonas modelam processos de acumulação ou desgaste.\n\nNão decrescente (\\(A_n \\uparrow\\)): Representa a aquisição cumulativa. Se \\(A_n = \\{\\)usuários que fizeram login pelo menos uma vez até o mês \\(n\\)\\(\\}\\), este conjunto só pode crescer. O limite é o conjunto de todos os usuários que já logaram alguma vez na história.\nNão crescente (\\(A_n \\downarrow\\)): Representa a retenção de uma coorte. Se \\(A_1 = \\{\\)usuários que se cadastraram em Janeiro\\(\\}\\) e \\(A_n = \\{\\)usuários de Janeiro que ainda estavam ativos no mês \\(n\\)\\(\\}\\), este conjunto só pode diminuir. O limite representa os usuários de Janeiro que permaneceram leais para sempre.\n\n\n\nExemplo 1.1 Considere \\(\\Omega = \\mathbb{N}\\) e as sequências:\n\n\\(\\{A_{n}\\}_{n \\ge 1}\\) com \\(A_{n} = \\{1, 2, ..., n\\}\\).\n\\(\\{B_{n}\\}_{n \\ge 1}\\) com \\(B_{n} = \\{2n, 2n+2, 2n+4, ...\\}\\).\n\nLimites de \\(A_n\\) e \\(B_n\\):\n\nNotemos que \\(A_{1}=\\{1\\}, A_{2}=\\{1,2\\},... \\rightarrow A_{1} \\subseteq A_{2} \\subseteq ...\\). Então \\(\\{A_{n}\\}_{n \\ge 1}\\) é monótona não decrescente. Logo, \\(\\lim_{n \\to \\infty} A_{n} = \\bigcup_{i=1}^{\\infty} A_{i} = \\{1\\} \\cup \\{1,2\\} \\cup \\dots = \\mathbb{N} - \\{0\\}\\).\n\\(B_{1}=\\{2,4,6,...\\}, B_{2}=\\{4,6,...\\},... \\Rightarrow B_{1} \\supseteq B_{2} \\supseteq ...\\). A sequência \\(\\{B_{n}\\}_{n \\ge 1}\\) é monótona não crescente. Logo, \\(\\lim_{n \\to \\infty} B_{n} = \\bigcap_{i=1}^{\\infty} B_{i} = \\{2,4,6,...\\} \\cap \\{4,6,...\\} \\cap ... = \\emptyset\\).",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução: Da Teoria à Prática Analítica</span>"
    ]
  },
  {
    "objectID": "aula01.html#comportamento-de-longo-prazo-limite-de-sequências",
    "href": "aula01.html#comportamento-de-longo-prazo-limite-de-sequências",
    "title": "1  Introdução: Da Teoria à Prática Analítica",
    "section": "1.4 Comportamento de Longo Prazo: Limite de Sequências",
    "text": "1.4 Comportamento de Longo Prazo: Limite de Sequências\nMas e o comportamento geral de login, que não é necessariamente monótono? Um usuário pode estar ativo um mês e inativo no outro. É aqui que os conceitos de limite superior e inferior se tornam ferramentas analíticas poderosas para resolver nosso problema.\n\nDefinição 1.5 (Limite Superior e Inferior) Para definir o limite de uma sequência qualquer de conjuntos \\(\\{A_{n}\\}_{n \\ge 1}\\), considere duas sequências auxiliares \\(\\{B_{n}\\}_{n \\ge 1}\\) e \\(\\{C_{n}\\}_{n \\ge 1}\\):\n\\[B_{n} = \\bigcap_{k=n}^{\\infty} A_{k}, \\quad n \\ge 1 \\tag{1.1}\\] \\[C_{n} = \\bigcup_{k=n}^{\\infty} A_{k}, \\quad n \\ge 1 \\tag{1.2}\\]\n\\(B_{1} = A_{1} \\cap A_{2} \\cap A_{3} \\cap ...\\) \\(B_{2} = A_{2} \\cap A_{3} \\cap ...\\)\n\\(C_{1} = A_{1} \\cup A_{2} \\cup A_{3} \\cup ...\\) \\(C_{2} = A_{2} \\cup A_{3} \\cup ...\\)\n\\(\\Rightarrow \\{B_{n}\\}_{n \\ge 1}\\) é uma sequência monótona não decrescente. \\(\\rightarrow \\{C_{n}\\}_{n \\ge 1}\\) é uma sequência monótona não crescente.\n\\(B_n \\subseteq A_n \\subseteq C_n\\).\nDessa forma, como sequências monótonas, seus limites existem:\n\\[\\lim_{n \\to \\infty} B_{n} = \\bigcup_{n=1}^{\\infty} B_{n} = \\bigcup_{n=1}^{\\infty} \\bigcap_{k=n}^{\\infty} A_{k} \\tag{1.3}\\] \\[\\lim_{n \\to \\infty} C_{n} = \\bigcap_{n=1}^{\\infty} C_{n} = \\bigcap_{n=1}^{\\infty} \\bigcup_{k=n}^{\\infty} A_{k} \\tag{1.4}\\]\nCom base nesses limites, podemos definir o comportamento de longo prazo de qualquer sequência \\(\\{A_n\\}\\).\nSe \\(A_1, A_2, ...\\) é uma sequência de conjuntos:\n\nO limite superior da sequência é definido por: \\[\\limsup_{n \\to \\infty} A_{n} = \\bigcap_{n=1}^{\\infty} \\bigcup_{k=n}^{\\infty} A_{k}\\]\nO limite inferior da sequência é definido por: \\[\\liminf_{n \\to \\infty} A_{n} = \\bigcup_{n=1}^{\\infty} \\bigcap_{k=n}^{\\infty} A_{k}\\]\n\n\n\nPerspectiva de Data Science (A Solução): Seja \\(A_n = \\{\\)usuários ativos no mês \\(n\\)\\(\\}\\).\n\nliminf Aₙ (Limite Inferior): É o conjunto dos elementos que pertencem a \\(A_n\\) para todo \\(n\\) a partir de um certo ponto. Este é o conjunto dos usuários leais (hardcore). São aqueles que, após um tempo, se tornam permanentemente ativos.\nlimsup Aₙ (Limite Superior): É o conjunto dos elementos que pertencem a \\(A_n\\) para infinitos valores de \\(n\\). Este é o conjunto dos usuários esporádicos (recorrentes). São aqueles que podem desaparecer, mas sempre acabam voltando.\n\n\n\n1.4.0.1 Interpretação Matemática Rigorosa\nA seguir, demonstramos formalmente por que limsup corresponde à noção de “pertencer a infinitos conjuntos da sequência”.\nConforme a Definição 1.5, se \\(\\omega \\in \\limsup A_n\\), então \\(\\omega \\in \\bigcup_{k=n}^{\\infty} A_k, \\forall n=1,2,...\\)\nEm particular, \\(\\omega \\in C_1 = \\bigcup_{k=1}^{\\infty} A_k\\). Então, \\(\\exists n_1\\) tal que \\(\\omega \\in A_{n_1}\\).\nTambém, \\(\\omega \\in C_{n_1+1} = \\bigcup_{k=n_1+1}^{\\infty} A_k\\). \\(\\Rightarrow \\exists n_2 \\ge n_1+1\\) tal que \\(\\omega \\in A_{n_2}\\).\nProcedendo sempre indutivamente dessa forma, concluímos que existe uma subsequência \\(\\{A_{n_k} : k \\ge 1\\}\\) de tal forma que \\(\\omega \\in A_{n_k}, \\forall k=1,2,...\\)\nReciprocamente, dado \\(\\omega\\) qualquer, suponha que consigamos uma subsequência \\(\\{A_{n_k}\\}_{k \\ge 1}\\) tal que \\(\\omega \\in A_{n_k}, k=1,2,...\\). Dado \\(n\\) positivo, \\(\\exists n_k\\) tal que \\(n_k \\ge n\\). Como \\(\\omega \\in A_{n_k}\\) e \\(n_k \\ge n\\), \\(\\Rightarrow \\omega \\in \\bigcup_{k=n}^{\\infty} A_k\\).\nLogo, \\(\\omega \\in C_n, \\forall n=1,2,... \\rightarrow \\omega \\in \\limsup A_n\\).\nFinalmente, \\(\\omega \\in \\limsup A_n\\) significa existir uma subsequência \\(\\{A_{n_k}\\}_{k \\ge 1}\\) com \\(\\omega \\in A_{n_k}, \\forall k=1,2,...\\).\nPortanto, equivale a \\(\\omega\\) pertencer a infinitos elementos da sequência \\(\\{A_n\\}_{n \\ge 1}\\). Notação: \\(\\{\\limsup A_n\\} = \\{A_n \\text{ infinitas vezes}\\}\\).\n\nDefinição 1.6 (Limite de Sequência de Conjuntos) Dizemos que \\(\\{A_n\\}_{n \\ge 1}\\) tem limite \\(A\\), e escrevemos \\(\\lim_{n \\to \\infty} A_n = A\\), quando: \\[\\liminf_{n \\to \\infty} A_n = \\limsup_{n \\to \\infty} A_n = A\\]\n\n\nNota: Em Data Science, o caso onde liminf = limsup significa que, no longo prazo, o comportamento do sistema se estabiliza. Os usuários esporádicos eventualmente se tornam leais ou desaparecem, e o conjunto de usuários ativos para de flutuar.\n\n\nExemplo 1.2 Seja \\(\\{A_{n}\\}_{n \\ge 1}\\) com \\(A_{n} = [0, \\frac{n}{n+1})\\). Encontre \\(\\lim_{n \\to \\infty} A_n\\).\n\nLimite inferior: \\(\\liminf_{n \\to \\infty} A_{n} = \\bigcup_{n=1}^{\\infty} \\bigcap_{k=n}^{\\infty} A_{k}\\). \\(\\bigcap_{k=n}^{\\infty} A_{k} = \\left[0, \\frac{n}{n+1}\\right) \\cap \\left[0, \\frac{n+1}{n+2}\\right) \\cap \\dots = \\left[0, \\frac{n}{n+1}\\right)\\). \\(\\bigcup_{n=1}^{\\infty} \\left[0, \\frac{n}{n+1}\\right) = [0, 1)\\).\nLimite superior: \\(\\limsup_{n \\to \\infty} A_{n} = \\bigcap_{n=1}^{\\infty} \\bigcup_{k=n}^{\\infty} A_{k}\\). \\(\\bigcup_{k=n}^{\\infty} A_{k} = \\left[0, \\frac{n}{n+1}\\right) \\cup \\left[0, \\frac{n+1}{n+2}\\right) \\cup \\dots = [0, 1)\\). \\(\\bigcap_{n=1}^{\\infty} [0, 1) = [0, 1)\\).\n\nEntão, como vimos na Definição 1.6, \\(\\liminf_{n \\to \\infty} A_{n} = \\limsup_{n \\to \\infty} A_{n} = \\lim_{n \\to \\infty} A_{n} = [0, 1)\\).",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução: Da Teoria à Prática Analítica</span>"
    ]
  },
  {
    "objectID": "aula01.html#implementação-prática-em-r",
    "href": "aula01.html#implementação-prática-em-r",
    "title": "1  Introdução: Da Teoria à Prática Analítica",
    "section": "1.5 Implementação Prática em R",
    "text": "1.5 Implementação Prática em R\nAgora que estabelecemos o formalismo matemático, vamos traduzir esses conceitos para a prática computacional. Usaremos a linguagem R para simular o problema dos usuários de streaming e aplicar as operações de conjuntos para encontrar, de fato, os usuários “leais” e os “esporádicos”.\n\n1.5.1 Operações Básicas com Vetores\nEm R, um vetor de elementos únicos se comporta de maneira análoga a um conjunto. Funções base como union(), intersect() e setdiff() implementam as operações que discutimos.\n\n# Nosso universo de dados: 20 usuários\nOmega &lt;- 1:20\n\n# Segmento A: Usuários do plano Premium\nA &lt;- c(1, 5, 8, 12, 15, 18)\n\n# Segmento B: Usuários que ouviram &gt;100 horas no mês\nB &lt;- c(2, 5, 8, 9, 10, 15, 20)\n\n# Intersecção (A ∩ B): Usuários Premium E que ouviram &gt;100h\nintersect(A, B)\n\n[1]  5  8 15\n\n# União (A U B): Usuários Premium OU que ouviram &gt;100h\nunion(A, B)\n\n [1]  1  5  8 12 15 18  2  9 10 20\n\n# Diferença (A - B): Usuários Premium que NÃO ouviram &gt;100h\nsetdiff(A, B)\n\n[1]  1 12 18\n\n# Complementar (A^c): Usuários que NÃO são Premium\nsetdiff(Omega, A)\n\n [1]  2  3  4  6  7  9 10 11 13 14 16 17 19 20\n\n\n\n\n1.5.2 Analisando o Comportamento de Usuários ao Longo do Tempo\nVamos agora simular 12 meses de atividade para nossos 20 usuários. Criaremos uma lista de conjuntos, An_list, onde An_list[[n]] contém os IDs dos usuários ativos no mês n.\nPara tornar o exemplo claro, vamos criar perfis de usuários específicos: * Usuários Leais (Hardcore): {1, 2}. Estão sempre ativos. * Usuários Esporádicos (Recorrentes): {10, 11}. Ficam ativos em meses pares. * Usuários “Churned” (Desistentes): {18, 19}. Ativos no início, mas somem. * Usuário Novo: {20}. Aparece apenas no final.\n\nset.seed(1)\n\n# Definindo nossos usuários\nleais &lt;- c(1, 2)\nesporadicos &lt;- c(10, 11)\nchurned &lt;- c(18, 19)\nnovo &lt;- 20\noutros_aleatorios &lt;- c(5, 8, 15) # Atividade irregular\n\n# Criando a lista de conjuntos de usuários ativos para 12 meses\nAn_list &lt;- vector(\"list\", 12)\nfor (n in 1:12) {\n  ativos_n &lt;- leais # Leais estão sempre ativos\n  \n  # Esporádicos ativos em meses pares, mas garantimos que não no último mês\n  if (n %% 2 == 0 && n &lt; 12) { \n    ativos_n &lt;- c(ativos_n, esporadicos)\n  }\n  \n  if (n &lt; 6) { # Desistentes\n    ativos_n &lt;- c(ativos_n, churned)\n  }\n  \n  if (n &gt; 9 && n &lt; 12) { # Novo usuário, mas não no último mês\n    ativos_n &lt;- c(ativos_n, novo)\n  }\n  \n  # Atividade aleatória, mas não no último mês\n  if (n &lt; 12) {\n    ativos_n &lt;- c(ativos_n, sample(outros_aleatorios, 1))\n  }\n  \n  An_list[[n]] &lt;- unique(ativos_n)\n}\n\n# Vamos inspecionar os usuários ativos no Mês 2 e Mês 11\nprint(\"Usuários Ativos no Mês 2:\")\n\n[1] \"Usuários Ativos no Mês 2:\"\n\nprint(sort(An_list[[2]]))\n\n[1]  1  2 10 11 15 18 19\n\nprint(\"Usuários Ativos no Mês 11:\")\n\n[1] \"Usuários Ativos no Mês 11:\"\n\nprint(sort(An_list[[11]]))\n\n[1]  1  2 15 20\n\n\n\nNota sobre a Simulação Finita: Os conceitos de liminf e limsup são definidos para sequências infinitas (\\(n \\to \\infty\\)). Ao aplicá-los a uma sequência finita (N=12), surge um “efeito de borda”: o cálculo do liminf é fortemente influenciado pelo último mês da observação, o que pode distorcer a identificação dos usuários verdadeiramente “leais”.\nPara contornar essa limitação e garantir que nosso exemplo prático ilustre corretamente a teoria, ajustamos deliberadamente a simulação. Modelamos o último mês como um período em que o sistema já atingiu um “estado estável”, onde apenas os usuários leais permanecem. Esta não é uma “trapaça”, mas sim uma estratégia de modelagem consciente para emular um comportamento de longo prazo dentro de uma janela de tempo finita, tornando o propósito pedagógico do exemplo mais claro e preciso.\n\n\n\n1.5.3 Calculando liminf e limsup\nCom nossa sequência de conjuntos An_list, podemos agora implementar as definições de liminf e limsup para encontrar nossos perfis de usuários. A função Reduce() é perfeita para aplicar uma operação (como union ou intersect) de forma cumulativa a uma lista de conjuntos.\n\n# Número de meses\nN &lt;- length(An_list)\n\n# --- Cálculo do Limite Superior (Usuários Esporádicos + Leais) ---\n# limsup An = Intersecção(n=1 a N) de [União(k=n a N) de Ak]\n\nCn_list &lt;- vector(\"list\", N)\nfor (n in 1:N) {\n  # União de todos os conjuntos de k=n até o final\n  Cn_list[[n]] &lt;- Reduce(union, An_list[n:N])\n}\nlimsup_An &lt;- Reduce(intersect, Cn_list)\n\nprint(\"Limite Superior (Usuários Leais e Esporádicos):\")\n\n[1] \"Limite Superior (Usuários Leais e Esporádicos):\"\n\nprint(sort(limsup_An))\n\n[1] 1 2\n\n# --- Cálculo do Limite Inferior (Apenas Usuários Leais) ---\n# liminf An = União(n=1 a N) de [Intersecção(k=n a N) de Ak]\n\nBn_list &lt;- vector(\"list\", N)\nfor (n in 1:N) {\n  # Intersecção de todos os conjuntos de k=n até o final\n  Bn_list[[n]] &lt;- Reduce(intersect, An_list[n:N])\n}\nliminf_An &lt;- Reduce(union, Bn_list)\n\nprint(\"Limite Inferior (Apenas Usuários Leais):\")\n\n[1] \"Limite Inferior (Apenas Usuários Leais):\"\n\nprint(sort(liminf_An))\n\n[1] 1 2\n\n\nComo podemos ver, o resultado do código corresponde exatamente à nossa intuição analítica:\n\nO limsup identificou corretamente os usuários que sempre voltam ({1, 2}) e os que aparecem com frequência ({10, 11}).\nO liminf filtrou apenas os usuários que são permanentemente ativos a partir de um certo ponto, ou seja, os verdadeiramente leais ({1, 2}).\n\nEsta seção prática demonstra como a Teoria dos Conjuntos fornece não apenas uma base teórica, mas também um roteiro direto para a implementação de análises de comportamento complexas.",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução: Da Teoria à Prática Analítica</span>"
    ]
  },
  {
    "objectID": "020_inferencia.html",
    "href": "020_inferencia.html",
    "title": "Módulo Inferência Estatística",
    "section": "",
    "text": "TODO: descrever essa parte",
    "crumbs": [
      "Módulo Inferência Estatística"
    ]
  },
  {
    "objectID": "aula24.html",
    "href": "aula24.html",
    "title": "2  24 Introdução: O Dilema do Teste A/B",
    "section": "",
    "text": "2.1 O Framework da Inferência: Do Problema à Modelagem\nImagine que você é um Cientista de Dados em uma empresa de e-commerce. O time de design propõe um novo botão de “Comprar” (Versão B), com uma cor diferente, alegando que ele aumentará a taxa de cliques em relação ao botão atual (Versão A).\nPara validar essa hipótese, você implementa um teste A/B: 500 usuários aleatórios veem a Versão A, e outros 500 veem a Versão B. Ao final do experimento, você observa os resultados:\nA Versão B parece melhor. Mas a pergunta central que define a sua carreira como cientista é: essa diferença de 1% é real e significativa, ou pode ser apenas fruto do acaso? Se mostrarmos os botões para outros 500 usuários, talvez os resultados se invertam.\nPara responder a essa pergunta com confiança, precisamos de um framework rigoroso para “aprender” sobre a realidade a partir de dados limitados e ruidosos. Esta aula irá construir esse framework, peça por peça, usando a inferência estatística.\nO primeiro passo é traduzir nosso problema prático para uma linguagem matemática formal.",
    "crumbs": [
      "Módulo Inferência Estatística",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>24 Introdução: O Dilema do Teste A/B</span>"
    ]
  },
  {
    "objectID": "aula24.html#o-framework-da-inferência-do-problema-à-modelagem",
    "href": "aula24.html#o-framework-da-inferência-do-problema-à-modelagem",
    "title": "2  24 Introdução: O Dilema do Teste A/B",
    "section": "",
    "text": "Dados (observações): Os dados são valores observados de variáveis aleatórias que seguem uma distribuição de probabilidade conjunta P, que pertence a uma classe (conhecida) \\(\\mathcal{P}\\). Frequentemente, \\(\\mathcal{P}\\) é indexada por um parâmetro \\(\\theta \\in \\Theta\\). \\[ \\mathcal{P} = \\{ P_{\\theta}, \\theta \\in \\Theta \\} \\]\nObjetivo: fazer inferência sobre \\(\\theta\\) ou \\(g(\\theta)\\) com base nos dados observados.\n\nestimação pontual ou intervalar\nteste de hipóteses\n\n\n\nPerspectiva de Data Science:\n\nParâmetro (\\(\\theta\\)): A Verdade Oculta. \\(\\theta\\) é a verdadeira, mas desconhecida, taxa de cliques de um botão se pudéssemos mostrá-lo a um número infinito de usuários. É a realidade que queremos descobrir. No nosso caso, temos dois parâmetros de interesse: \\(\\theta_A\\) e \\(\\theta_B\\).\nModelo (\\(\\mathcal{P}\\)): Nossa Hipótese sobre o Mundo. \\(\\mathcal{P}\\) é a nossa escolha de modelagem. Ao rodar o teste A/B, assumimos que a decisão de cada usuário de clicar (ou não) é um evento independente, como um “cara ou coroa” com uma moeda viciada. Esse processo é descrito pela distribuição de Bernoulli. Portanto, nosso modelo para a Versão B é a família de todas as distribuições de Bernoulli, \\(\\mathcal{P} = \\{ \\text{Bernoulli}(\\theta_B), \\theta_B \\in [0, 1] \\}\\).",
    "crumbs": [
      "Módulo Inferência Estatística",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>24 Introdução: O Dilema do Teste A/B</span>"
    ]
  },
  {
    "objectID": "aula24.html#estimação-pontual-o-melhor-chute-a-partir-dos-dados",
    "href": "aula24.html#estimação-pontual-o-melhor-chute-a-partir-dos-dados",
    "title": "2  24 Introdução: O Dilema do Teste A/B",
    "section": "2.2 Estimação Pontual: O Melhor Chute a partir dos Dados",
    "text": "2.2 Estimação Pontual: O Melhor Chute a partir dos Dados\nNosso primeiro objetivo é usar os dados para dar um “chute” único e bem fundamentado sobre o valor do nosso parâmetro \\(\\theta\\).\nIngredientes:\n\nUma função real g, definida no espaço paramétrico \\(\\Theta\\), cujo valor \\(g(\\theta)\\) é o que gostaríamos de obter informação / estimar. \\(g(\\theta)\\): estimando.\nUm vetor aleatório \\(\\underline{X}\\) (observável) tomando valores no espaço amostral \\(\\mathcal{X}\\), de acordo com uma distribuição \\(P_{\\theta} \\in \\mathcal{P}\\). O valor observado de \\(\\underline{X}\\), \\(\\underline{x}\\) é o conjunto de dados. Muitas vezes, nos referimos a \\(\\underline{X} = (X_1, ..., X_n)\\) como amostra.\n\nIdeia: especificar um valor plausível para \\(g(\\theta)\\).\n\nDefinição 2.1 (Estatística e Estimador) Qualquer função da amostra \\(\\underline{X}\\) que não depende de quantidades desconhecidas é uma estatística. Uma estatística usada para estimar \\(g(\\theta)\\) é chamada de estimador.\nNotação:\n\nEstatística: \\(T = T(X_1, ..., X_n)\\)\nEstimador: \\(\\delta = \\delta(X_1, ..., X_n)\\) ou \\(\\hat{\\theta} = \\hat{\\theta}(X_1, ..., X_n)\\)\nValor observado do estimador, isto é \\(\\delta(\\underline{x})\\), é chamado de estimativa.\n\n\n\nPerspectiva de Data Science:\n\nAmostra (\\(\\underline{X}\\)): A Evidência Coletada. Para o botão B, nossa amostra é um vetor de 500 elementos, \\(\\underline{X} = (X_1, ..., X_{500})\\), onde \\(X_i=1\\) se o i-ésimo usuário clicou, e \\(X_i=0\\) caso contrário.\nEstimador (\\(\\hat{\\theta}\\)): Nosso Algoritmo de Aprendizagem. O estimador é a receita ou algoritmo que transforma os dados brutos em um chute para \\(\\theta\\). A receita mais intuitiva para estimar a taxa de cliques é simplesmente calcular a média da amostra: \\(\\hat{\\theta}_B = \\bar{X}_n = \\frac{1}{n}\\sum X_i\\).\nEstimativa: A estimativa é o número que nosso algoritmo produz: \\(\\hat{\\theta}_B(\\underline{x}) = 30/500 = 0.06\\).\n\n\n\nExemplo 2.1 (Tempo de Vida de Lâmpadas) Seja X = tempo de vida de lâmpadas de certa marca. Assuma que \\(X \\sim \\text{exp}(\\theta)\\), \\(\\theta &gt; 0\\). Suponha que \\((X_1, ..., X_n)\\) é uma a.a. de X.\nAqui, temos que \\(\\mathcal{P} = \\{f_{\\theta}, \\theta &gt; 0\\}\\), com \\(f_{\\theta}(x) = \\theta e^{-\\theta x} \\mathbb{I}_{(0, \\infty)}(x)\\).\nExemplos de estatísticas:\n\n\\(S_n = X_1 + ... + X_n\\) (tempo total de vida)\n\\(X_{(1)} = \\min\\{X_1, ..., X_n\\}\\) (menor tempo de vida)\n\\(\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i\\) (média amostral dos tempos de vida)\n\\(S_n^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\bar{X}_n)^2\\) (variância amostral)\n\nQual é um estimador razoável para o tempo médio de vida? E para \\(\\theta\\)?\n\n\\(g(\\theta) = E_{\\theta}(X) = \\frac{1}{\\theta} \\rightarrow\\) possível estimador: \\(\\widehat{g(\\theta)} = \\bar{X}_n\\).\n\\(g(\\theta) = \\theta \\rightarrow\\) possível estimador: \\(\\hat{\\theta} = \\frac{1}{\\bar{X}_n}\\).",
    "crumbs": [
      "Módulo Inferência Estatística",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>24 Introdução: O Dilema do Teste A/B</span>"
    ]
  },
  {
    "objectID": "aula24.html#o-motor-da-inferência-a-função-de-verossimilhança",
    "href": "aula24.html#o-motor-da-inferência-a-função-de-verossimilhança",
    "title": "2  24 Introdução: O Dilema do Teste A/B",
    "section": "2.3 O Motor da Inferência: A Função de Verossimilhança",
    "text": "2.3 O Motor da Inferência: A Função de Verossimilhança\nTemos um algoritmo intuitivo para estimar \\(\\theta\\) (a média amostral), mas como podemos justificar que ele é um bom algoritmo? E se houvesse outros? A resposta está em um dos conceitos mais importantes da estatística e do Machine Learning: a verossimilhança.\nA verossimilhança responde à seguinte pergunta: “Dado os dados que observei, qual valor do parâmetro \\(\\theta\\) torna minhas observações mais prováveis (ou menos surpreendentes)?”\nEla funciona como uma função de pontuação (score) para diferentes hipóteses sobre a “verdade” \\(\\theta\\).\n\nDefinição 2.2 (Função de Verossimilhança) A função de verossimilhança de \\(\\theta \\in \\Theta\\), com base na amostra observada \\(\\underline{x} = (x_1, ..., x_n)\\), é dada por \\[ L(\\theta) = L(\\theta; \\underline{x}) = f_{X_1, ..., X_n}(x_1, ..., x_n; \\theta), \\quad \\theta \\in \\Theta \\]\nNota: se \\(\\underline{X}\\) é uma a.a. de X, então \\(L(\\theta) = \\prod_{i=1}^{n} f_X(x_i; \\theta)\\) (i.i.d.’s)\n\n\nExemplo 2.2 (Funções de Verossimilhança) Obtenha a função de verossimilhança em cada caso assumindo uma a.a. \\(\\underline{X} = (X_1, ..., X_n)\\) de X.\na) \\(X \\sim \\text{Bernoulli}(\\theta)\\) \\[ L(\\theta) = \\prod_{i=1}^{n} \\theta^{x_i} (1-\\theta)^{1-x_i} = \\theta^{\\sum_{i=1}^{n} x_i} (1-\\theta)^{n - \\sum_{i=1}^{n} x_i}, \\quad \\theta \\in (0,1). \\] \\(\\rightarrow L(\\theta)\\) depende da realização de \\(T = \\sum_{i=1}^{n} X_i\\).\n\nConexão com o Teste A/B: Esta é exatamente a função de verossimilhança para o nosso problema! Para o botão B, observamos \\(\\sum x_i = 30\\) e \\(n=500\\). A função se torna \\(L(\\theta_B) = \\theta_B^{30}(1-\\theta_B)^{470}\\). Agora podemos “testar” diferentes valores de \\(\\theta_B\\) e ver qual deles maximiza essa função. O valor que a maximiza é, de fato, \\(30/500 = 0.06\\), justificando nosso estimador intuitivo. Este é o Princípio da Máxima Verossimilhança.\n\nb) \\(X \\sim \\text{Poisson}(\\theta)\\) \\[ L(\\theta) = \\prod_{i=1}^{n} \\frac{e^{-\\theta} \\theta^{x_i}}{x_i!} = \\frac{e^{-n\\theta} \\theta^{\\sum_{i=1}^{n} x_i}}{\\prod_{i=1}^{n} x_i!}, \\quad \\theta &gt; 0. \\] \\(\\rightarrow L(\\theta)\\) depende da realização de \\(T = \\sum_{i=1}^{n} X_i\\).\nc) \\(X \\sim U(0, \\theta)\\), \\(\\theta &gt; 0\\) \\[ L(\\theta) = \\prod_{i=1}^{n} f_{\\theta}(x_i) = \\prod_{i=1}^{n} \\frac{1}{\\theta} \\mathbb{I}_{(0, \\theta)}(x_i) = \\frac{1}{\\theta^n} \\prod_{i=1}^{n} \\mathbb{I}_{(0, \\theta)}(x_i) \\] A indicadora \\(\\prod_{i=1}^{n} \\mathbb{I}_{(0, \\theta)}(x_i) = 1\\) se, e somente se, \\(0 &lt; x_i &lt; \\theta\\) para todo \\(i=1, ..., n\\), o que é equivalente a \\(0 &lt; x_{(1)} \\le ... \\le x_{(n)} &lt; \\theta\\). Então, \\[ L(\\theta) = \\frac{1}{\\theta^n} \\mathbb{I}_{(x_{(n)}, \\infty)}(\\theta), \\quad \\theta &gt; 0 \\] \\(\\rightarrow L(\\theta)\\) envolve a realização de \\(T = X_{(n)}\\).\nd) \\(X \\sim N(\\mu, \\sigma^2)\\), \\(\\theta = (\\mu, \\sigma^2)\\), \\(\\mu \\in \\mathbb{R}, \\sigma^2 &gt; 0\\) \\[ L(\\theta) = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x_i - \\mu)^2}{2\\sigma^2}} = \\frac{1}{(2\\pi\\sigma^2)^{n/2}} e^{-\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i - \\mu)^2} \\] \\[ = \\frac{1}{(2\\pi)^{n/2}} \\frac{1}{(\\sigma^2)^{n/2}} \\exp\\left\\{-\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i^2 - 2x_i\\mu + \\mu^2)\\right\\} \\] \\[ = \\frac{1}{(2\\pi)^{n/2}} \\frac{1}{(\\sigma^2)^{n/2}} \\exp\\left\\{-\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} x_i^2 + \\frac{\\mu}{\\sigma^2} \\sum_{i=1}^{n} x_i - \\frac{n\\mu^2}{2\\sigma^2}\\right\\}, \\quad \\mu \\in \\mathbb{R}, \\sigma^2 &gt; 0. \\] \\(\\rightarrow L(\\theta)\\) envolve a realização de \\(T_n = (\\sum_{i=1}^{n} X_i^2, \\sum_{i=1}^{n} X_i)\\).\n\n\nConexão com Aprendizagem Estatística: O processo de “treinar” um modelo de Aprendizagem Estatística (como uma Regressão Logística ou mesmo uma rede neural para classificação) é, em sua essência, um processo de otimização para encontrar os parâmetros do modelo (\\(\\theta\\)) que maximizam a função de verossimilhança (ou a log-verossimilhança) para os dados de treinamento. O framework que construímos aqui é a base teórica para a maior parte do aprendizado de máquina supervisionado.",
    "crumbs": [
      "Módulo Inferência Estatística",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>24 Introdução: O Dilema do Teste A/B</span>"
    ]
  },
  {
    "objectID": "aula24.html#implementação-prática-em-r",
    "href": "aula24.html#implementação-prática-em-r",
    "title": "2  24 Introdução: O Dilema do Teste A/B",
    "section": "2.4 Implementação Prática em R",
    "text": "2.4 Implementação Prática em R\n\nNa aula, afirmamos que a nossa estimativa intuitiva para a taxa de cliques (6%) era justificada pelo Princípio da Máxima Verossimilhança. Ou seja, de todas as “verdades” possíveis (\\(\\theta_B\\)), o valor \\(0.06\\) é o que torna os dados que realmente observamos (\\(k=30\\) cliques em \\(n=500\\) tentativas) os mais prováveis.\nVamos provar isso visualmente. Em vez de usar cálculo para encontrar o máximo da função, vamos simplesmente “testar” milhares de valores de \\(\\theta_B\\) e plotar a pontuação de verossimilhança que cada um recebe.\n\n2.4.1 1. O Problema e a Função\nConforme o Exemplo (a), a função de verossimilhança para um processo Bernoulli é:\n\\[L(\\theta) = \\theta^{k} (1-\\theta)^{n - k}\\]\nOnde: * \\(n = 500\\) (visualizações da Versão B) * \\(k = 30\\) (cliques na Versão B)\nNota Importante: \\(L(\\theta)\\) é um número absurdamente pequeno (ex: \\(0.06^{30} \\times (1-0.06)^{470}\\)). Computadores têm dificuldade com números tão próximos de zero. Por isso, na prática, nós sempre trabalhamos com a Log-Verossimilhança (ou “log-likelihood”).\n\\[\\ell(\\theta) = \\log(L(\\theta)) = k \\cdot \\log(\\theta) + (n - k) \\cdot \\log(1-\\theta)\\]\nEncontrar o \\(\\theta\\) que maximiza \\(L(\\theta)\\) é o mesmo que encontrar o \\(\\theta\\) que maximiza \\(\\ell(\\theta)\\), mas os números são muito mais estáveis.\n\n\n2.4.2 2. Implementação em R\nNão precisamos implementar essa função manualmente. O R já a possui: é a função de densidade da distribuição Binomial, dbinom(). Pedindo o logarítmico dela (log = TRUE), obtemos exatamente a log-verossimilhança.\nVamos: 1. Definir nossos dados observados. 2. Criar um “grid” de hipóteses para \\(\\theta_B\\) (ex: de 0.01 a 0.15). 3. Calcular a log-verossimilhança para cada hipótese. 4. Plotar e encontrar o pico.\n\nlibrary(ggplot2) # Para criar os gráficos\n\n# 1. Nossos dados observados para a Versão B\nn_B &lt;- 500\ncliques_B &lt;- 30\nestimativa_observada &lt;- cliques_B / n_B\n\n# 2. Criar um \"grid\" de hipóteses para a verdadeira taxa de cliques (theta_B)\n# Vamos testar 1000 valores possíveis entre 1% e 15%\nhipoteses_theta &lt;- seq(from = 0.01, to = 0.15, by = 0.0001)\n\n# 3. Calcular a log-verossimilhança para cada hipótese\n# Usamos dbinom() para calcular a \"pontuação\" de cada hipótese,\n# dado que observamos 'cliques_B' em 'n_B' tentativas.\n# log = TRUE nos dá a log-verossimilhança.\nlog_like &lt;- dbinom(x = cliques_B, \n                   size = n_B, \n                   prob = hipoteses_theta, \n                   log = TRUE)\n\n# 4. Preparar os dados para plotar\ndf_like &lt;- data.frame(\n  theta = hipoteses_theta,\n  log_likelihood = log_like\n)\n\n# 5. Encontrar o valor de theta que maximiza a log-verossimilhança\ntheta_max &lt;- hipoteses_theta[which.max(log_like)]\n\nprint(paste(\"Estimativa Observada (nosso 'chute'):\", estimativa_observada))\n\n[1] \"Estimativa Observada (nosso 'chute'): 0.06\"\n\nprint(paste(\"Estimativa de Máxima Verossimilhança (pico do gráfico):\", theta_max))\n\n[1] \"Estimativa de Máxima Verossimilhança (pico do gráfico): 0.06\"\n\n# 6. Plotar!\nggplot(df_like, aes(x = theta, y = log_likelihood)) +\n  geom_line(color = \"blue\", size = 1) +\n  # Adiciona uma linha vertical no pico encontrado\n  geom_vline(xintercept = theta_max, \n             color = \"red\", \n             linetype = \"dashed\", \n             size = 1) +\n  labs(\n    title = \"O Princípio da Máxima Verossimilhança na Prática\",\n    subtitle = paste(\"O pico da curva (vermelho) está em\", round(theta_max, 2), \"que é exatamente a nossa estimativa observada.\"),\n    x = \"Hipótese sobre a 'Verdadeira' Taxa de Cliques (theta_B)\",\n    y = \"Log-Verossimilhança (Pontuação da Hipótese)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nComo o gráfico demonstra, a função de log-verossimilhança atinge seu valor máximo exatamente em \\(\\theta = 0.06\\).\nIsso confirma nossa intuição: o “melhor chute” para a realidade desconhecida (\\(\\theta_B\\)) é, de fato, a média que observamos nos nossos dados. O que fizemos aqui foi validar nosso estimador intuitivo \\(\\hat{\\theta} = \\bar{X}_n\\) usando o rigoroso framework da Máxima Verossimilhança.",
    "crumbs": [
      "Módulo Inferência Estatística",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>24 Introdução: O Dilema do Teste A/B</span>"
    ]
  }
]