[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Probabilidade e Inferência Estatística para Ciência de Dados",
    "section": "",
    "text": "Introdução\nNotas de aula de um curso de Probabilidade e Inferência para Ciência de Dados. Baseado nas notas de aula do curso MAE5702 do professor Felipe de Queiroz, a quem agradeço pela gentil disponibilização do material.",
    "crumbs": [
      "Introdução"
    ]
  },
  {
    "objectID": "010_probabilidade.html",
    "href": "010_probabilidade.html",
    "title": "Módulo Probabilidade",
    "section": "",
    "text": "TODO: descrever essa parte",
    "crumbs": [
      "Módulo Probabilidade"
    ]
  },
  {
    "objectID": "aula01.html",
    "href": "aula01.html",
    "title": "1  Introdução",
    "section": "",
    "text": "1.1 Conjuntos e Eventos\nImagine que você trabalha como Cientista de Dados em uma empresa de streaming de música. Uma pergunta fundamental do negócio é: “Quais são os nossos perfis de usuários? Quem são os ouvintes leais e quem são os esporádicos?”. Para responder a isso, você tem acesso aos dados de login de cada usuário, mês a mês.\nComo poderíamos definir matematicamente o que significa ser um “ouvinte leal”? Seria alguém que logou todos os meses? Ou alguém que, a partir de certo ponto, nunca mais deixou de logar? E o “ouvinte esporádico”? Seria aquele que, mesmo que desapareça por alguns meses, sempre acaba voltando?\nPara responder a essas perguntas de forma precisa e rigorosa, precisamos de uma linguagem formal. Essa linguagem é a Teoria dos Conjuntos. Nesta aula, vamos construir o alicerce matemático que nos permitirá não apenas estruturar nosso pensamento analítico, mas também desenvolver as ferramentas para analisar o comportamento de sistemas que evoluem ao longo do tempo. Cada definição e proposição que veremos é um passo em direção à solução do nosso problema.\nPara analisar dados, primeiro precisamos defini-los. A teoria dos conjuntos nos fornece o vocabulário fundamental para isso.",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "aula01.html#conjuntos-e-eventos",
    "href": "aula01.html#conjuntos-e-eventos",
    "title": "1  Introdução",
    "section": "",
    "text": "Definição 1.1 (Conjunto) Um conjunto \\(\\Omega\\) é uma coleção de objetos distintos, que serão denotados por \\(\\omega\\).\n\n\\(\\omega \\in \\Omega\\) (elemento \\(\\omega\\) pertence ao conjunto \\(\\Omega\\)).\n\\(\\omega \\notin \\Omega\\) (elemento \\(\\omega\\) não pertence ao conjunto \\(\\Omega\\)).\n\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science\n\n\n\nPense no conjunto universal \\(\\Omega\\) como todo o seu universo de dados, ou espaço amostral. Cada elemento \\(\\omega\\) é uma unidade observacional: um cliente, uma transação, um produto. Por exemplo, \\(\\Omega\\) pode ser “o conjunto de todos os usuários da nossa plataforma”.\n\n\n\nDefinição 1.2 (Subconjunto) Dizemos que A é um subconjunto de \\(\\Omega\\), ou que A está contido em \\(\\Omega\\), e denotamos por \\(A \\subseteq \\Omega\\), se \\(\\forall \\omega \\in A \\rightarrow \\omega \\in \\Omega\\).\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science\n\n\n\nUm subconjunto é um segmento de interesse ou um evento dentro do seu universo de dados, geralmente obtido através de um filtro ou consulta.\n\nSe \\(\\Omega\\) é o conjunto de todos os usuários, um subconjunto \\(A\\) pode ser: \\(A = \\{\\)usuários do plano Premium\\(\\}\\).\nOutro subconjunto \\(B\\) poderia ser: \\(B = \\{\\)usuários que ouviram mais de 100 horas de música no último mês\\(\\}\\).",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "aula01.html#operações-com-conjuntos",
    "href": "aula01.html#operações-com-conjuntos",
    "title": "1  Introdução",
    "section": "1.2 Operações com Conjuntos",
    "text": "1.2 Operações com Conjuntos\nCom nossos segmentos definidos, precisamos de uma forma de combiná-los e compará-los. As operações com conjuntos são a “gramática” que nos permite realizar análises complexas.\nSejam A, \\(A_1\\), \\(A_2\\),… subconjuntos de \\(\\Omega\\). Temos as seguintes operações:\n\nComplementar de A: \\(A^{c} = \\{ \\omega \\in \\Omega : \\omega \\notin A \\}\\).\nUnião: \\(\\bigcup_{i=1}^{n} A_{i} = \\{ \\omega \\in \\Omega : \\omega \\in A_{i} \\text{ para ao menos um } i=1,2,...,n \\}\\).\nIntersecção: \\(\\bigcap_{i=1}^{n} A_{i} = \\{ \\omega \\in \\Omega : \\omega \\in A_{i}, \\forall i=1,...,n \\}\\).\nDiferença: \\(A_{1} - A_{2} = \\{ \\omega \\in \\Omega : \\omega \\in A_{1}, \\omega \\notin A_{2} \\} = A_{1} \\cap A_{2}^{c}\\).\nDiferença simétrica: \\(A_{1} \\Delta A_{2} = (A_{1} - A_{2}) \\cup (A_{2} - A_{1}) = (A_{1} \\cap A_{2}^{c}) \\cup (A_{1}^{c} \\cap A_{2})\\).\n\n\nConjunto vazio (\\(\\emptyset\\)): não contém nenhum elemento.\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science\n\n\n\nCada operação corresponde diretamente a uma operação lógica em uma consulta de dados:\n\nIntersecção (\\(A \\cap B\\)) é a lógica E (AND). Ex: “Usuários do plano Premium E que ouviram mais de 100 horas”.\nUnião (\\(A \\cup B\\)) é a lógica OU (OR). Ex: “Usuários do plano Premium OU que ouviram mais de 100 horas”.\nComplementar (\\(A^c\\)) é a lógica NÃO (NOT). Ex: “Usuários que NÃO são do plano Premium”.\n\n\n\n\nDefinição 1.3 (Relações entre Conjuntos)  \n\nDizemos que \\(A_{1}\\) e \\(A_{2}\\) são disjuntos se \\(A_{1} \\cap A_{2} = \\emptyset\\).\nDizemos que \\(A_{1} = A_{2}\\) se \\(A_{1} \\subseteq A_{2}\\) e \\(A_{2} \\subseteq A_{1}\\).\nDizemos que \\(A_1, A_2, ...\\) são mutuamente disjuntos se \\(A_{i} \\cap A_{j} = \\emptyset\\), \\(\\forall i \\neq j\\).\n\n\n\nProposição 1.1 (Lei de De Morgan) Sejam \\(A_{1}, A_{2}, ...\\) subconjuntos de \\(\\Omega\\). Então:\n\n\\((\\bigcup_{i=1}^{\\infty} A_{i})^{c} = \\bigcap_{i=1}^{\\infty} A_{i}^{c}\\)\n\\((\\bigcap_{i=1}^{\\infty} A_{i})^{c} = \\bigcup_{i=1}^{\\infty} A_{i}^{c}\\)\n\n\n\nNota: As Leis de De Morgan são extremamente úteis para simplificar consultas lógicas complexas. A negação de uma condição “OU” ampla é o mesmo que exigir que todas as condições “E” individuais sejam falsas.\n\nDemonstração (a):\nPrecisamos mostrar que \\((\\bigcup_{i=1}^{\\infty} A_{i})^{c} \\subseteq \\bigcap_{i=1}^{\\infty} A_{i}^{c}\\) e \\(\\bigcap_{i=1}^{\\infty} A_{i}^{c} \\subseteq (\\bigcup_{i=1}^{\\infty} A_{i})^{c}.\\)\nParte 1: \\((\\bigcup_{i=1}^{\\infty} A_{i})^{c} \\subseteq \\bigcap_{i=1}^{\\infty} A_{i}^{c}\\)\n\nTome \\(\\omega \\in (\\bigcup_{i=1}^{\\infty} A_{i})^{c}\\)\n\\(\\Rightarrow \\omega \\notin \\bigcup_{i=1}^{\\infty} A_{i}\\) (Por definição de complementar)\n\\(\\Rightarrow \\omega \\notin A_{i}, \\forall i=1,2,...\\) (Se não está na união, não está em nenhum conjunto)\n\\(\\Rightarrow \\omega \\in A_{i}^{c}, \\forall i=1,2,...\\) (Por definição de complementar)\n\\(\\Rightarrow \\omega \\in \\bigcap_{i=1}^{\\infty} A_{i}^{c}\\) (Se pertence a todos os complementares, pertence à intersecção deles)\n\nParte 2: \\(\\bigcap_{i=1}^{\\infty} A_{i}^{c} \\subseteq (\\bigcup_{i=1}^{\\infty} A_{i})^{c}\\)\n\nTome \\(\\omega \\in \\bigcap_{i=1}^{\\infty} A_{i}^{c}\\)\n\\(\\Rightarrow \\omega \\in A_{i}^{c}, \\forall i=1,2,...\\) (Por definição de intersecção)\n\\(\\Rightarrow \\omega \\notin A_{i}, \\forall i=1,2,...\\) (Por definição de complementar)\n\\(\\Rightarrow \\omega \\notin \\bigcup_{i=1}^{\\infty} A_{i}\\) (Se não está em nenhum conjunto, não está na união)\n\\(\\Rightarrow \\omega \\in (\\bigcup_{i=1}^{\\infty} A_{i})^{c}\\) (Por definição de complementar)",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "aula01.html#sequências-de-conjuntos",
    "href": "aula01.html#sequências-de-conjuntos",
    "title": "1  Introdução",
    "section": "1.3 Sequências de Conjuntos",
    "text": "1.3 Sequências de Conjuntos\nAgora, voltamos ao nosso problema original: analisar o comportamento dos usuários ao longo do tempo. Para isso, introduzimos o conceito de sequências de conjuntos.\n\nDefinição 1.4 (Sequência Monótona) Uma sequência \\(\\{A_{n}\\}_{n \\ge 1}\\) é dita ser monótona se:\n\n\\(A_{1} \\subseteq A_{2} \\subseteq A_{3} \\subseteq ...\\) (isto é, \\(A_n\\) é não decrescente, denotado por \\(A_n \\uparrow\\)).\n\\(A_{1} \\supseteq A_{2} \\supseteq A_{3} \\supseteq ...\\) (isto é, \\(A_n\\) é não crescente, denotado por \\(A_n \\downarrow\\)).\n\nO limite de uma sequência monótona é denotado por:\n\nse \\(A_n \\uparrow\\), \\(\\lim_{n \\to \\infty} A_{n} = \\bigcup_{i=1}^{\\infty} A_{i}\\).\nse \\(A_n \\downarrow\\), \\(\\lim_{n \\to \\infty} A_{n} = \\bigcap_{i=1}^{\\infty} A_{i}\\).\n\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science\n\n\n\nSequências monótonas modelam processos de acumulação ou desgaste.\n\nNão decrescente (\\(A_n \\uparrow\\)): Representa a aquisição cumulativa. Se \\(A_n = \\{\\)usuários que fizeram login pelo menos uma vez até o mês \\(n\\)\\(\\}\\), este conjunto só pode crescer. O limite é o conjunto de todos os usuários que já logaram alguma vez na história.\nNão crescente (\\(A_n \\downarrow\\)): Representa a retenção de uma coorte. Se \\(A_1 = \\{\\)usuários que se cadastraram em Janeiro\\(\\}\\) e \\(A_n = \\{\\)usuários de Janeiro que ainda estavam ativos no mês \\(n\\)\\(\\}\\), este conjunto só pode diminuir. O limite representa os usuários de Janeiro que permaneceram leais para sempre.\n\n\n\n\nExemplo 1.1 Considere \\(\\Omega = \\mathbb{N}\\) e as sequências:\n\n\\(\\{A_{n}\\}_{n \\ge 1}\\) com \\(A_{n} = \\{1, 2, ..., n\\}\\).\n\\(\\{B_{n}\\}_{n \\ge 1}\\) com \\(B_{n} = \\{2n, 2n+2, 2n+4, ...\\}\\).\n\nLimites de \\(A_n\\) e \\(B_n\\):\n\nNotemos que \\(A_{1}=\\{1\\}, A_{2}=\\{1,2\\},... \\rightarrow A_{1} \\subseteq A_{2} \\subseteq ...\\). Então \\(\\{A_{n}\\}_{n \\ge 1}\\) é monótona não decrescente. Logo, \\(\\lim_{n \\to \\infty} A_{n} = \\bigcup_{i=1}^{\\infty} A_{i} = \\{1\\} \\cup \\{1,2\\} \\cup \\dots = \\mathbb{N} - \\{0\\}\\).\n\\(B_{1}=\\{2,4,6,...\\}, B_{2}=\\{4,6,...\\},... \\Rightarrow B_{1} \\supseteq B_{2} \\supseteq ...\\). A sequência \\(\\{B_{n}\\}_{n \\ge 1}\\) é monótona não crescente. Logo, \\(\\lim_{n \\to \\infty} B_{n} = \\bigcap_{i=1}^{\\infty} B_{i} = \\{2,4,6,...\\} \\cap \\{4,6,...\\} \\cap ... = \\emptyset\\).",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "aula01.html#limite-de-sequências",
    "href": "aula01.html#limite-de-sequências",
    "title": "1  Introdução",
    "section": "1.4 Limite de Sequências",
    "text": "1.4 Limite de Sequências\nMas e o comportamento geral de login, que não é necessariamente monótono? Um usuário pode estar ativo um mês e inativo no outro. É aqui que os conceitos de limite superior e inferior se tornam ferramentas analíticas poderosas para resolver nosso problema.\n\nDefinição 1.5 (Limite Superior e Inferior) Para definir o limite de uma sequência qualquer de conjuntos \\(\\{A_{n}\\}_{n \\ge 1}\\), considere duas sequências auxiliares \\(\\{B_{n}\\}_{n \\ge 1}\\) e \\(\\{C_{n}\\}_{n \\ge 1}\\):\n\\[B_{n} = \\bigcap_{k=n}^{\\infty} A_{k}, \\quad n \\ge 1 \\tag{1.1}\\] \\[C_{n} = \\bigcup_{k=n}^{\\infty} A_{k}, \\quad n \\ge 1 \\tag{1.2}\\]\n\\(B_{1} = A_{1} \\cap A_{2} \\cap A_{3} \\cap ...\\) \\(B_{2} = A_{2} \\cap A_{3} \\cap ...\\)\n\\(C_{1} = A_{1} \\cup A_{2} \\cup A_{3} \\cup ...\\) \\(C_{2} = A_{2} \\cup A_{3} \\cup ...\\)\n\\(\\Rightarrow \\{B_{n}\\}_{n \\ge 1}\\) é uma sequência monótona não decrescente. \\(\\rightarrow \\{C_{n}\\}_{n \\ge 1}\\) é uma sequência monótona não crescente.\n\\(B_n \\subseteq A_n \\subseteq C_n\\).\nDessa forma, como sequências monótonas, seus limites existem:\n\\[\\lim_{n \\to \\infty} B_{n} = \\bigcup_{n=1}^{\\infty} B_{n} = \\bigcup_{n=1}^{\\infty} \\bigcap_{k=n}^{\\infty} A_{k} \\tag{1.3}\\] \\[\\lim_{n \\to \\infty} C_{n} = \\bigcap_{n=1}^{\\infty} C_{n} = \\bigcap_{n=1}^{\\infty} \\bigcup_{k=n}^{\\infty} A_{k} \\tag{1.4}\\]\nCom base nesses limites, podemos definir o comportamento de longo prazo de qualquer sequência \\(\\{A_n\\}\\).\nSe \\(A_1, A_2, ...\\) é uma sequência de conjuntos:\n\nO limite superior da sequência é definido por: \\[\\limsup_{n \\to \\infty} A_{n} = \\bigcap_{n=1}^{\\infty} \\bigcup_{k=n}^{\\infty} A_{k}\\]\nO limite inferior da sequência é definido por: \\[\\liminf_{n \\to \\infty} A_{n} = \\bigcup_{n=1}^{\\infty} \\bigcap_{k=n}^{\\infty} A_{k}\\]\n\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science\n\n\n\nSeja \\(A_n = \\{\\)usuários ativos no mês \\(n\\)\\(\\}\\).\n\nliminf Aₙ (Limite Inferior): É o conjunto dos elementos que pertencem a \\(A_n\\) para todo \\(n\\) a partir de um certo ponto. Este é o conjunto dos usuários leais (hardcore). São aqueles que, após um tempo, se tornam permanentemente ativos.\nlimsup Aₙ (Limite Superior): É o conjunto dos elementos que pertencem a \\(A_n\\) para infinitos valores de \\(n\\). Este é o conjunto dos usuários esporádicos (recorrentes). São aqueles que podem desaparecer, mas sempre acabam voltando.\n\n\n\n\n1.4.0.1 Interpretação Matemática Rigorosa\nA seguir, demonstramos formalmente por que limsup corresponde à noção de “pertencer a infinitos conjuntos da sequência”.\nConforme a Definição 1.5, se \\(\\omega \\in \\limsup A_n\\), então \\(\\omega \\in \\bigcup_{k=n}^{\\infty} A_k, \\forall n=1,2,...\\)\nEm particular, \\(\\omega \\in C_1 = \\bigcup_{k=1}^{\\infty} A_k\\). Então, \\(\\exists n_1\\) tal que \\(\\omega \\in A_{n_1}\\).\nTambém, \\(\\omega \\in C_{n_1+1} = \\bigcup_{k=n_1+1}^{\\infty} A_k\\). \\(\\Rightarrow \\exists n_2 \\ge n_1+1\\) tal que \\(\\omega \\in A_{n_2}\\).\nProcedendo sempre indutivamente dessa forma, concluímos que existe uma subsequência \\(\\{A_{n_k} : k \\ge 1\\}\\) de tal forma que \\(\\omega \\in A_{n_k}, \\forall k=1,2,...\\)\nReciprocamente, dado \\(\\omega\\) qualquer, suponha que consigamos uma subsequência \\(\\{A_{n_k}\\}_{k \\ge 1}\\) tal que \\(\\omega \\in A_{n_k}, k=1,2,...\\). Dado \\(n\\) positivo, \\(\\exists n_k\\) tal que \\(n_k \\ge n\\). Como \\(\\omega \\in A_{n_k}\\) e \\(n_k \\ge n\\), \\(\\Rightarrow \\omega \\in \\bigcup_{k=n}^{\\infty} A_k\\).\nLogo, \\(\\omega \\in C_n, \\forall n=1,2,... \\rightarrow \\omega \\in \\limsup A_n\\).\nFinalmente, \\(\\omega \\in \\limsup A_n\\) significa existir uma subsequência \\(\\{A_{n_k}\\}_{k \\ge 1}\\) com \\(\\omega \\in A_{n_k}, \\forall k=1,2,...\\).\nPortanto, equivale a \\(\\omega\\) pertencer a infinitos elementos da sequência \\(\\{A_n\\}_{n \\ge 1}\\). Notação: \\(\\{\\limsup A_n\\} = \\{A_n \\text{ infinitas vezes}\\}\\).\n\nDefinição 1.6 (Limite de Sequência de Conjuntos) Dizemos que \\(\\{A_n\\}_{n \\ge 1}\\) tem limite \\(A\\), e escrevemos \\(\\lim_{n \\to \\infty} A_n = A\\), quando: \\[\\liminf_{n \\to \\infty} A_n = \\limsup_{n \\to \\infty} A_n = A\\]\n\n\nNota: Em Data Science, o caso onde liminf = limsup significa que, no longo prazo, o comportamento do sistema se estabiliza. Os usuários esporádicos eventualmente se tornam leais ou desaparecem, e o conjunto de usuários ativos para de flutuar.\n\n\nExemplo 1.2 Seja \\(\\{A_{n}\\}_{n \\ge 1}\\) com \\(A_{n} = [0, \\frac{n}{n+1})\\). Encontre \\(\\lim_{n \\to \\infty} A_n\\).\n\nLimite inferior: \\(\\liminf_{n \\to \\infty} A_{n} = \\bigcup_{n=1}^{\\infty} \\bigcap_{k=n}^{\\infty} A_{k}\\). \\(\\bigcap_{k=n}^{\\infty} A_{k} = \\left[0, \\frac{n}{n+1}\\right) \\cap \\left[0, \\frac{n+1}{n+2}\\right) \\cap \\dots = \\left[0, \\frac{n}{n+1}\\right)\\). \\(\\bigcup_{n=1}^{\\infty} \\left[0, \\frac{n}{n+1}\\right) = [0, 1)\\).\nLimite superior: \\(\\limsup_{n \\to \\infty} A_{n} = \\bigcap_{n=1}^{\\infty} \\bigcup_{k=n}^{\\infty} A_{k}\\). \\(\\bigcup_{k=n}^{\\infty} A_{k} = \\left[0, \\frac{n}{n+1}\\right) \\cup \\left[0, \\frac{n+1}{n+2}\\right) \\cup \\dots = [0, 1)\\). \\(\\bigcap_{n=1}^{\\infty} [0, 1) = [0, 1)\\).\n\nEntão, como vimos na Definição 1.6, \\(\\liminf_{n \\to \\infty} A_{n} = \\limsup_{n \\to \\infty} A_{n} = \\lim_{n \\to \\infty} A_{n} = [0, 1)\\).",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "aula01.html#implementação-prática-em-r",
    "href": "aula01.html#implementação-prática-em-r",
    "title": "1  Introdução",
    "section": "1.5 Implementação Prática em R",
    "text": "1.5 Implementação Prática em R\nAgora que estabelecemos o formalismo matemático, vamos traduzir esses conceitos para a prática computacional. Usaremos a linguagem R para simular o problema dos usuários de streaming e aplicar as operações de conjuntos para encontrar, de fato, os usuários “leais” e os “esporádicos”.\n\n1.5.1 Operações Básicas com Vetores\nEm R, um vetor de elementos únicos se comporta de maneira análoga a um conjunto. Funções base como union(), intersect() e setdiff() implementam as operações que discutimos.\n\n# Nosso universo de dados: 20 usuários\nOmega &lt;- 1:20\n\n# Segmento A: Usuários do plano Premium\nA &lt;- c(1, 5, 8, 12, 15, 18)\n\n# Segmento B: Usuários que ouviram &gt;100 horas no mês\nB &lt;- c(2, 5, 8, 9, 10, 15, 20)\n\n# Intersecção (A ∩ B): Usuários Premium E que ouviram &gt;100h\nintersect(A, B)\n\n[1]  5  8 15\n\n# União (A U B): Usuários Premium OU que ouviram &gt;100h\nunion(A, B)\n\n [1]  1  5  8 12 15 18  2  9 10 20\n\n# Diferença (A - B): Usuários Premium que NÃO ouviram &gt;100h\nsetdiff(A, B)\n\n[1]  1 12 18\n\n# Complementar (A^c): Usuários que NÃO são Premium\nsetdiff(Omega, A)\n\n [1]  2  3  4  6  7  9 10 11 13 14 16 17 19 20\n\n\n\n\n1.5.2 Analisando o Comportamento de Usuários ao Longo do Tempo\nVamos agora simular 12 meses de atividade para nossos 20 usuários. Criaremos uma lista de conjuntos, An_list, onde An_list[[n]] contém os IDs dos usuários ativos no mês n.\nPara tornar o exemplo claro, vamos criar perfis de usuários específicos: * Usuários Leais (Hardcore): {1, 2}. Estão sempre ativos. * Usuários Esporádicos (Recorrentes): {10, 11}. Ficam ativos em meses pares. * Usuários “Churned” (Desistentes): {18, 19}. Ativos no início, mas somem. * Usuário Novo: {20}. Aparece apenas no final.\n\nset.seed(1)\n\n# Definindo nossos usuários\nleais &lt;- c(1, 2)\nesporadicos &lt;- c(10, 11)\nchurned &lt;- c(18, 19)\nnovo &lt;- 20\noutros_aleatorios &lt;- c(5, 8, 15) # Atividade irregular\n\n# Criando a lista de conjuntos de usuários ativos para 12 meses\nAn_list &lt;- vector(\"list\", 12)\nfor (n in 1:12) {\n  ativos_n &lt;- leais # Leais estão sempre ativos\n  \n  # Esporádicos ativos em meses pares, mas garantimos que não no último mês\n  if (n %% 2 == 0 && n &lt; 12) { \n    ativos_n &lt;- c(ativos_n, esporadicos)\n  }\n  \n  if (n &lt; 6) { # Desistentes\n    ativos_n &lt;- c(ativos_n, churned)\n  }\n  \n  if (n &gt; 9 && n &lt; 12) { # Novo usuário, mas não no último mês\n    ativos_n &lt;- c(ativos_n, novo)\n  }\n  \n  # Atividade aleatória, mas não no último mês\n  if (n &lt; 12) {\n    ativos_n &lt;- c(ativos_n, sample(outros_aleatorios, 1))\n  }\n  \n  An_list[[n]] &lt;- unique(ativos_n)\n}\n\n# Vamos inspecionar os usuários ativos no Mês 2 e Mês 11\nprint(\"Usuários Ativos no Mês 2:\")\n\n[1] \"Usuários Ativos no Mês 2:\"\n\nprint(sort(An_list[[2]]))\n\n[1]  1  2 10 11 15 18 19\n\nprint(\"Usuários Ativos no Mês 11:\")\n\n[1] \"Usuários Ativos no Mês 11:\"\n\nprint(sort(An_list[[11]]))\n\n[1]  1  2 15 20\n\n\n\nNota sobre a Simulação Finita: Os conceitos de liminf e limsup são definidos para sequências infinitas (\\(n \\to \\infty\\)). Ao aplicá-los a uma sequência finita (N=12), surge um “efeito de borda”: o cálculo do liminf é fortemente influenciado pelo último mês da observação, o que pode distorcer a identificação dos usuários verdadeiramente “leais”.\nPara contornar essa limitação e garantir que nosso exemplo prático ilustre corretamente a teoria, ajustamos deliberadamente a simulação. Modelamos o último mês como um período em que o sistema já atingiu um “estado estável”, onde apenas os usuários leais permanecem. Esta não é uma “trapaça”, mas sim uma estratégia de modelagem consciente para emular um comportamento de longo prazo dentro de uma janela de tempo finita, tornando o propósito pedagógico do exemplo mais claro e preciso.\n\n\n\n1.5.3 Calculando liminf e limsup\nCom nossa sequência de conjuntos An_list, podemos agora implementar as definições de liminf e limsup para encontrar nossos perfis de usuários. A função Reduce() é perfeita para aplicar uma operação (como union ou intersect) de forma cumulativa a uma lista de conjuntos.\n\n# Número de meses\nN &lt;- length(An_list)\n\n# --- Cálculo do Limite Superior (Usuários Esporádicos + Leais) ---\n# limsup An = Intersecção(n=1 a N) de [União(k=n a N) de Ak]\n\nCn_list &lt;- vector(\"list\", N)\nfor (n in 1:N) {\n  # União de todos os conjuntos de k=n até o final\n  Cn_list[[n]] &lt;- Reduce(union, An_list[n:N])\n}\nlimsup_An &lt;- Reduce(intersect, Cn_list)\n\nprint(\"Limite Superior (Usuários Leais e Esporádicos):\")\n\n[1] \"Limite Superior (Usuários Leais e Esporádicos):\"\n\nprint(sort(limsup_An))\n\n[1] 1 2\n\n# --- Cálculo do Limite Inferior (Apenas Usuários Leais) ---\n# liminf An = União(n=1 a N) de [Intersecção(k=n a N) de Ak]\n\nBn_list &lt;- vector(\"list\", N)\nfor (n in 1:N) {\n  # Intersecção de todos os conjuntos de k=n até o final\n  Bn_list[[n]] &lt;- Reduce(intersect, An_list[n:N])\n}\nliminf_An &lt;- Reduce(union, Bn_list)\n\nprint(\"Limite Inferior (Apenas Usuários Leais):\")\n\n[1] \"Limite Inferior (Apenas Usuários Leais):\"\n\nprint(sort(liminf_An))\n\n[1] 1 2\n\n\nComo podemos ver, o resultado do código corresponde exatamente à nossa intuição analítica:\n\nO limsup identificou corretamente os usuários que sempre voltam ({1, 2}) e os que aparecem com frequência ({10, 11}).\nO liminf filtrou apenas os usuários que são permanentemente ativos a partir de um certo ponto, ou seja, os verdadeiramente leais ({1, 2}).\n\nEsta seção prática demonstra como a Teoria dos Conjuntos fornece não apenas uma base teórica, mas também um roteiro direto para a implementação de análises de comportamento complexas.",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "aula02.html",
    "href": "aula02.html",
    "title": "2  Parte 1: Espaço de Probabilidade",
    "section": "",
    "text": "2.1 Um Espaço de Probabilidade\nUm espaço de probabilidade tem três componentes:\nGostaríamos, em princípio, de atribuir probabilidade a qualquer subconjunto de \\(\\Omega\\), isto é, considerar \\(\\mathcal{F}=\\mathcal{P}(\\Omega)\\) (conjunto das partes de \\(\\Omega\\)).\nSe \\(\\Omega\\) for finito ou infinito enumerável, isso é possível. Se \\(\\Omega\\) for não enumerável, por ex. \\(\\Omega=\\mathbb{R}^{2}\\), existem subconjuntos de \\(\\Omega\\) aos quais não é possível “medir” (veja, por ex. Rolla & Lima, Problema da Agulha de Buffon, p. 27).\nIdeia: Restringir \\(\\mathcal{F}\\).\nVamos exigir o seguinte para \\(\\mathcal{F}\\):",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Parte 1: Espaço de Probabilidade</span>"
    ]
  },
  {
    "objectID": "aula02.html#um-espaço-de-probabilidade",
    "href": "aula02.html#um-espaço-de-probabilidade",
    "title": "2  Parte 1: Espaço de Probabilidade",
    "section": "",
    "text": "Um conjunto \\(\\Omega\\) formado pelos resultados do experimento aleatório (espaço amostral).\nUma classe de subconjuntos de \\(\\Omega\\), denotada aqui por \\(\\mathcal{F}\\), chamados de eventos aleatórios. São os conjuntos de \\(\\mathcal{F}\\) que gostaríamos de “medir” (atribuir probabilidade).\nUma função \\(\\mathbb{P}\\) que associa a cada evento aleatório em \\(\\mathcal{F}\\) um número real, chamada probabilidade ou medida de probabilidade.\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science\n\n\n\nComo podemos traduzir esses conceitos para o nosso dia a dia?\n\n\\(\\Omega\\) (Espaço Amostral): Pense em \\(\\Omega\\) como o seu data frame ou tabela inteira (df). É o universo de todas as observações possíveis que seu experimento (coleta de dados) poderia gerar.\n\\(\\omega\\) (Resultado): Um \\(\\omega\\) (um elemento de \\(\\Omega\\)) é uma única linha do seu data frame. Pode ser um usuário (user_id = 123), uma transação (transaction_id = 9A8B), ou uma sessão de site.\n\\(A\\) (Evento): Um evento \\(A\\) (um subconjunto de \\(\\Omega\\)) é o resultado de uma consulta (query) ou filtro (subset) que você aplica ao seu data frame.\n\nPor exemplo:\n\ndf[df$segmento == \"VIP\", ] é o evento \\(A = \\text{\"Clientes VIP\"}\\).\ndf[df$clicou == 1 & df$pais == \"BR\", ] é o evento \\(B \\cap C\\), onde \\(B = \\text{\"Clicou\"}\\) e \\(C = \\text{\"Brasil\"}\\).\n\nA Teoria da Probabilidade nos dá as regras formais para calcular o “tamanho” (a probabilidade) desses subconjuntos.\n\n\n\n\n\n\n\nDefinição 2.3 (\\(\\sigma\\)-álgebra) Dizemos que uma classe \\(\\mathcal{F}\\) de subconjuntos de \\(\\Omega\\) é uma \\(\\sigma\\)-álgebra se \\(\\mathcal{F}\\) satisfaz:\n\n\\(\\Omega \\in \\mathcal{F}\\).\n\\(\\forall A \\in \\mathcal{F} \\Rightarrow A^{c} \\in \\mathcal{F}\\).\nSe \\(A_{1}, A_{2}, ... \\in \\mathcal{F} \\Rightarrow \\bigcup_{n=1}^{\\infty} A_{n} \\in \\mathcal{F}\\).\n\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science: A \\(\\sigma\\)-álgebra como o Schema dos Dados\n\n\n\nO conceito de \\(\\sigma\\)-álgebra (\\(\\mathcal{F}\\)) é um dos mais abstratos, mas tem uma analogia prática: pense em \\(\\mathcal{F}\\) como as “perguntas que o seu schema de dados permite fazer”.\nO \\(\\mathcal{F}\\) define quais eventos são “mensuráveis”. Em Data Science, isso é definido pelas features (colunas) que você coletou.\n\nSe seu data frame \\(\\Omega\\) tem colunas idade e genero, sua \\(\\sigma\\)-álgebra \\(\\mathcal{F}\\) permite “medir” (filtrar, agrupar, calcular probabilidades) eventos como “clientes com mais de 30 anos” (\\(A\\)) ou “clientes do gênero feminino” (\\(B\\)).\nAs propriedades da \\(\\sigma\\)-álgebra garantem que você também pode medir combinações:\n\n\nNOT \\(A\\): “clientes com 30 anos ou menos” (\\(A^c\\)).\n\n\n\\(A \\cup B\\): “clientes com mais de 30 anos OU femininos”.\n\n(Prop. 1.1) \\(A \\cap B\\): “clientes femininos com mais de 30 anos”.\n\n\nSe uma feature não foi coletada (ex: renda), eventos como “clientes com renda &gt; 10k” não estão em \\(\\mathcal{F}\\). Não podemos medir sua probabilidade porque essa informação não existe no nosso espaço. A \\(\\sigma\\)-álgebra é, portanto, o conjunto de todas as queries que podemos construir a partir das colunas disponíveis.\n\n\n\nExemplo 2.3 (Exemplo 1.3) \\(\\Omega \\neq \\emptyset\\) qualquer. \\(\\mathcal{F}=\\mathcal{P}(\\Omega)=\\{A:A\\subseteq\\Omega\\}\\) é \\(\\sigma\\)-algebra (maior \\(\\sigma\\)-algebra).\nDe fato, \\(\\mathcal{P}(\\Omega)\\) é uma \\(\\sigma\\)-álgebra (maior \\(\\sigma\\)-álgebra):\n\n\\(\\Omega \\in \\mathcal{F}=\\mathcal{P}(\\Omega)\\).\n\\(A \\in \\mathcal{F} \\Rightarrow A^{c} \\in \\mathcal{F}\\).\n\\(A_{1}, A_{2}, ... \\in \\mathcal{F} \\Rightarrow \\bigcup_{i=1}^{\\infty} A_{i} \\in \\mathcal{F}\\).\n\n\n\nExemplo 2.4 (Exemplo 1.4) \\(\\Omega \\neq \\emptyset\\) qualquer. \\(\\mathcal{F}=\\{\\emptyset, \\Omega\\}\\) (\\(\\sigma\\)-álgebra trivial).\n\n\nExemplo 2.5 (Exemplo 1.5) \\(\\Omega\\) qualquer e \\(B \\subseteq \\Omega\\). \\(\\mathcal{F}=\\{\\emptyset, \\Omega, B, B^{c}\\}\\) (menor \\(\\sigma\\)-álgebra que contém B).\n\n\nProposição 2.1 (Proposição 1.1) Se \\(\\mathcal{F}\\) é \\(\\sigma\\)-álgebra em \\(\\Omega\\), então:\n\n\\(\\emptyset \\in \\mathcal{F}\\).\n\\(A_{1}, A_{2}, ... \\in \\mathcal{F} \\Rightarrow \\bigcap_{n=1}^{\\infty} A_{n} \\in \\mathcal{F}\\).\nSe \\(A, B \\in \\mathcal{F} \\Rightarrow A-B \\in \\mathcal{F}\\), \\(A-B=A \\cap B^{c}\\).\n\nDemonstração:\nSeja \\(\\mathcal{F}\\) uma \\(\\sigma\\)-álgebra em \\(\\Omega\\).\n\n\\(\\Omega \\in \\mathcal{F} \\Rightarrow \\Omega^{c} \\in \\mathcal{F} \\Rightarrow \\emptyset \\in \\mathcal{F}\\).\n\\(A_{1}, A_{2}, ... \\in \\mathcal{F} \\Rightarrow A_{1}^{c}, A_{2}^{c}, ... \\in \\mathcal{F} \\Rightarrow \\bigcup_{n=1}^{\\infty} A_{n}^{c} \\in \\mathcal{F}\\). \\(\\Rightarrow (\\bigcup_{n=1}^{\\infty} A_{n}^{c})^{c} \\in \\mathcal{F} \\Rightarrow \\bigcap_{n=1}^{\\infty} A_{n} \\in \\mathcal{F}\\).\n\n\n\nProposição 2.2 (Proposição 1.2) Sejam \\(\\mathcal{F}_{1}, \\mathcal{F}_{2}\\) duas \\(\\sigma\\)-álgebras de subconjuntos de \\(\\Omega\\). Então \\(\\mathcal{F}_{1} \\cap \\mathcal{F}_{2}\\) é, também, \\(\\sigma\\)-álgebra de \\(\\Omega\\).\nDemonstração:\nSejam \\(\\mathcal{F}_{1}, \\mathcal{F}_{2}\\) \\(\\sigma\\)-álgebras de subconj. de \\(\\Omega\\).\n\n\\(\\begin{cases} \\Omega \\in \\mathcal{F}_{1} \\\\ e \\\\ \\Omega \\in \\mathcal{F}_{2} \\end{cases} \\Rightarrow \\Omega \\in \\mathcal{F}_{1} \\cap \\mathcal{F}_{2}\\)\n\\(A \\in \\mathcal{F}_{1} \\cap \\mathcal{F}_{2} \\Rightarrow \\begin{cases} A \\in \\mathcal{F}_{1} \\Rightarrow A^{c} \\in \\mathcal{F}_{1} \\\\ A \\in \\mathcal{F}_{2} \\Rightarrow A^{c} \\in \\mathcal{F}_{2} \\end{cases} \\Rightarrow A^{c} \\in \\mathcal{F}_{1} \\cap \\mathcal{F}_{2}\\)\n\\(A_{1}, A_{2}, ... \\in \\mathcal{F}_{1} \\cap \\mathcal{F}_{2}\\), então \\(\\begin{cases} \\bigcup_{n=1}^{\\infty} A_{n} \\in \\mathcal{F}_{1} \\\\ \\bigcup_{n=1}^{\\infty} A_{n} \\in \\mathcal{F}_{2} \\end{cases} \\Rightarrow \\bigcup_{n=1}^{\\infty} A_{n} \\in \\mathcal{F}_{1} \\cap \\mathcal{F}_{2}\\)",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Parte 1: Espaço de Probabilidade</span>"
    ]
  },
  {
    "objectID": "aula02.html#sigma-algebra-gerada",
    "href": "aula02.html#sigma-algebra-gerada",
    "title": "2  Parte 1: Espaço de Probabilidade",
    "section": "2.2 \\(\\sigma\\)-algebra Gerada",
    "text": "2.2 \\(\\sigma\\)-algebra Gerada\nSeja \\(\\Omega \\neq \\emptyset\\) e \\(\\mathcal{C}\\) uma classe de subconjuntos de \\(\\Omega\\), isto é, \\(\\mathcal{C} \\subseteq \\mathcal{P}(\\Omega)\\).\nPara toda classe \\(\\mathcal{C} \\subseteq \\mathcal{P}(\\Omega)\\), existe ao menos uma \\(\\sigma\\)-álgebra que contém \\(\\mathcal{C}\\), a saber \\(\\mathcal{P}(\\Omega)\\).\nEm geral, seja \\(\\mathcal{C} \\subseteq \\mathcal{P}(\\Omega)\\). Definamos \\(\\mathbb{F}(\\mathcal{C})\\) o conjunto de todas as \\(\\sigma\\)-álgebras de \\(\\Omega\\) que contêm \\(\\mathcal{C}\\).\nNote que \\(\\mathbb{F}(\\mathcal{C}) \\neq \\emptyset\\), pois \\(\\mathcal{P}(\\Omega) \\in \\mathbb{F}(\\mathcal{C})\\).\nDefina \\[\\sigma(\\mathcal{C}) = \\bigcap_{\\mathcal{F} \\in \\mathbb{F}(\\mathcal{C})} \\mathcal{F}\\]\nEntão \\(\\sigma(\\mathcal{C})\\) é a “menor” \\(\\sigma\\)-álgebra que contém \\(\\mathcal{C}\\) (\\(\\sigma\\)-álgebra gerada por \\(\\mathcal{C}\\)).\n\nExemplo 2.6 (Exemplo 1.6) Sejam \\(\\Omega=\\{1,2,3,4,5,6\\}\\) e \\(\\mathcal{C}=\\{\\{1,2,3,4\\},\\{5,6\\}\\}\\).\nTemos que \\(\\mathcal{F}_{1}=\\{\\emptyset, \\Omega, \\{1,2,3,4\\}, \\{5,6\\}\\}\\) e \\(\\mathcal{F}_{2}=\\{\\emptyset, \\Omega, \\{1,2\\}, \\{3,4\\}, \\{5,6\\}, \\{1,2,3,4\\}, \\{1,2,5,6\\}, \\{3,4,5,6\\}\\}\\) são \\(\\sigma\\)-álgebras que contêm \\(\\mathcal{C}\\).\nNote que \\(\\mathcal{F}_{1}\\) é a menor \\(\\sigma\\)-álgebra que contém \\(\\mathcal{C}\\), isto é, \\(\\sigma(\\mathcal{C})\\).\n\n\nExemplo 2.7 (Exemplo 1.7) Sejam \\(\\Omega=\\mathbb{R}\\) e \\(\\mathcal{C}=\\{(-\\infty, x] : x \\in \\mathbb{R}\\}\\).\nA \\(\\sigma(\\mathcal{C})\\) é chamada de \\(\\sigma\\)-álgebra de Borel em \\(\\mathbb{R}\\).\nNotação: \\(\\sigma(\\mathcal{C}) = \\mathcal{B}(\\mathbb{R}) = \\mathcal{B}\\).\nSe \\(B \\in \\mathcal{B}(\\mathbb{R})\\), dizemos que B é um Boreliano. (será o domínio da função de probabilidade).",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Parte 1: Espaço de Probabilidade</span>"
    ]
  },
  {
    "objectID": "aula02.html#implementação-prática-em-r",
    "href": "aula02.html#implementação-prática-em-r",
    "title": "2  Parte 1: Espaço de Probabilidade",
    "section": "2.3 Implementação Prática em R",
    "text": "2.3 Implementação Prática em R\nNesta seção, ilustramos os conceitos de Espaço Amostral (\\(\\Omega\\)) e Eventos (\\(\\mathcal{F}\\)) usando R. Em ciência de dados, frequentemente lidamos com \\(\\Omega\\) como o conjunto de todas as observações (linhas) em um dataset.\n\n2.3.1 Espaço Amostral Finito: Segmentação de Clientes\nVamos usar o contexto do Exemplo 2.6. Nosso espaço amostral \\(\\Omega\\) é o conjunto de 6 segmentos de clientes.\n\n# Nosso espaço amostral (universo)\nOmega &lt;- 1:6\nprint(Omega)\n\n[1] 1 2 3 4 5 6\n\n\nUm evento \\(A\\) é um subconjunto de \\(\\Omega\\). Por exemplo, o evento “Segmento de Alta Prioridade”.\n\n# Evento A: \"Alta Prioridade\"\nA &lt;- c(1, 2, 3, 4)\n\n# Evento B (complementar de A): \"Baixa Prioridade\"\nB &lt;- c(5, 6)\n\nA \\(\\sigma\\)-álgebra \\(\\mathcal{F}\\) define quais perguntas podemos “fazer” aos nossos dados. A \\(\\sigma\\)-álgebra gerada por \\(\\mathcal{C}=\\{A, B\\}\\) (como no Exemplo 1.6, onde \\(B=A^c\\)) é:\n\\(\\mathcal{F} = \\{\\emptyset, \\Omega, A, B\\}\\)\nVamos verificar as propriedades da \\(\\sigma\\)-álgebra em R:\n\n# (i) Omega está em F\n# (Omega já foi definido)\n\n# (ii) O complemento de um evento em F também está em F\n# A complemento (A^c) em relação a Omega\nA_comp &lt;- setdiff(Omega, A)\nprint(paste(\"Complemento de A:\", list(A_comp)))\n\n[1] \"Complemento de A: 5:6\"\n\n# B complemento (B^c) em relação a Omega\nB_comp &lt;- setdiff(Omega, B)\nprint(paste(\"Complemento de B:\", list(B_comp)))\n\n[1] \"Complemento de B: 1:4\"\n\n# Note que A_comp é B, e B_comp é A. Ambos estão em F.\n\n# (iii) A união de eventos em F está em F\nA_union_B &lt;- union(A, B)\nprint(paste(\"União de A e B:\", list(A_union_B)))\n\n[1] \"União de A e B: c(1, 2, 3, 4, 5, 6)\"\n\n# Note que a união é o próprio Omega, que está em F.\n\n\n\n2.3.2 Eventos como Subconjuntos de um Data Frame\nNa prática, \\(\\Omega\\) é muitas vezes o conjunto de todas as unidades observacionais (ex: todos os usuários, todas as transações). Os eventos são subconjuntos (filtros) desse dataset.\n\n# Criando um Omega (nosso dataset de usuários)\nset.seed(42) # Para reprodutibilidade\nOmega_data &lt;- data.frame(\n  user_id = 1:100,\n  segmento = sample(c(\"VIP\", \"Regular\", \"Novo\"), 100, replace = TRUE),\n  clicou_anuncio = sample(c(0, 1), 100, replace = TRUE)\n)\n\n# head(Omega_data)\n\nAqui, \\(\\Omega\\) é o conjunto dos 100 user_ids.\nVamos definir alguns eventos:\n\n\\(A\\): Usuários que são “VIP”.\n\\(B\\): Usuários que “clicaram no anúncio” (resultado 1).\n\n\n# Evento A: \"Usuário é VIP\"\nA &lt;- subset(Omega_data, segmento == \"VIP\")\ncat(\"Número de elementos em A (VIPs):\", nrow(A), \"\\n\")\n\nNúmero de elementos em A (VIPs): 40 \n\n# Evento B: \"Usuário clicou\"\nB &lt;- subset(Omega_data, clicou_anuncio == 1)\ncat(\"Número de elementos em B (Clicaram):\", nrow(B), \"\\n\")\n\nNúmero de elementos em B (Clicaram): 56 \n\n\nPodemos usar as operações de conjunto (que são a base da \\(\\sigma\\)-álgebra) para definir eventos mais complexos:\n\n# 1. Evento Complemento: A^c (Não-VIPs)\n# A^c = Omega - A\nA_comp &lt;- subset(Omega_data, segmento != \"VIP\")\ncat(\"Número de elementos em A^c (Não-VIPs):\", nrow(A_comp), \"\\n\")\n\nNúmero de elementos em A^c (Não-VIPs): 60 \n\n# 2. Evento Interseção: A ∩ B (Usuários VIP que clicaram)\nA_inter_B &lt;- subset(Omega_data, segmento == \"VIP\" & clicou_anuncio == 1)\n# ou\n# A_inter_B &lt;- merge(A, B)\ncat(\"Número de elementos em A ∩ B (VIPs que clicaram):\", nrow(A_inter_B), \"\\n\")\n\nNúmero de elementos em A ∩ B (VIPs que clicaram): 22 \n\n# 3. Evento União: A U B (Usuários que são VIP ou clicaram)\nA_union_B &lt;- subset(Omega_data, segmento == \"VIP\" | clicou_anuncio == 1)\ncat(\"Número de elementos em A U B (VIPs ou clicaram):\", nrow(A_union_B), \"\\n\")\n\nNúmero de elementos em A U B (VIPs ou clicaram): 74 \n\n\nEste exercício mostra como as operações teóricas de \\(\\sigma\\)-álgebra (complemento, união, interseção) são mapeadas diretamente para as operações de filtro (E/OU/NÃO) que usamos diariamente em R (e SQL) para análise de dados.",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Parte 1: Espaço de Probabilidade</span>"
    ]
  },
  {
    "objectID": "aula03.html",
    "href": "aula03.html",
    "title": "3  Definição Axiomática de Probabilidade",
    "section": "",
    "text": "3.1 Propriedades\nNa aula anterior, definimos nosso “universo” (\\(\\Omega\\)) e os “eventos” (\\(\\mathcal{F}\\)) como filtros ou queries que podemos aplicar a ele. Na prática, em ciência de dados, costumamos calcular probabilidades usando a intuição de contagem (frequência relativa):\n\\(\\mathbb{P}(A) = \\frac{\\text{Número de linhas que satisfazem A}}{\\text{Número total de linhas em } \\Omega} = \\frac{\\text{nrow}(A)}{\\text{nrow}(\\Omega)}\\)\nIsso funciona bem para datasets finitos. Mas e se \\(\\Omega\\) for infinito? (Ex: “o conjunto de todas as possíveis transações futuras”)? E se \\(\\Omega\\) for contínuo? (Ex: \\(\\Omega = \\mathbb{R}\\), o tempo de resposta de um servidor)? Não podemos mais “contar linhas”.\nPrecisamos de um sistema de regras mais fundamental e robusto, que funcione para qualquer tipo de espaço amostral. Esse sistema é a definição axiomática. Ela define as “regras do jogo” que qualquer função \\(\\mathbb{P}\\) deve obedecer para ser chamada de “probabilidade”.\nNotas:\nSeja \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) um espaço de probabilidade e \\(A, B, A_1, A_2, ... \\in \\mathcal{F}\\). Então:\nDemonstração",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Definição Axiomática de Probabilidade</span>"
    ]
  },
  {
    "objectID": "aula03.html#propriedades",
    "href": "aula03.html#propriedades",
    "title": "3  Definição Axiomática de Probabilidade",
    "section": "",
    "text": "\\(\\mathbb{P}(\\emptyset) = 0\\)\n\\(\\mathbb{P}(A^{c}) = 1 - \\mathbb{P}(A)\\) 2’) \\(A_{1}, ..., A_{n}\\) disjuntos \\(\\Rightarrow \\mathbb{P}(\\bigcup_{i=1}^{n} A_{i}) = \\sum_{i=1}^{n} \\mathbb{P}(A_{i})\\)\nSe \\(A \\subseteq B \\Rightarrow \\mathbb{P}(A) \\le \\mathbb{P}(B)\\) e \\(\\mathbb{P}(B-A) = \\mathbb{P}(B) - \\mathbb{P}(A)\\).\n\\(\\mathbb{P}(\\bigcup_{n=1}^{\\infty} A_{n}) \\le \\sum_{n=1}^{\\infty} \\mathbb{P}(A_{n})\\)\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)\n\n\n\nSeja \\(A_{1} = \\Omega\\) e \\(A_{n} = \\emptyset, \\forall n \\ge 2\\). Então \\(\\Omega = \\bigcup_{n=1}^{\\infty} A_{n}\\). \\(1 = \\mathbb{P}(\\Omega) = \\sum_{n=1}^{\\infty} \\mathbb{P}(A_{n}) = \\mathbb{P}(\\Omega) + \\sum_{n=2}^{\\infty} \\mathbb{P}(\\emptyset) = 1 + \\sum_{n=2}^{\\infty} \\mathbb{P}(\\emptyset)\\). Suponha que \\(\\mathbb{P}(\\emptyset) &gt; 0 \\Rightarrow\\) absurdo. Logo, \\(\\mathbb{P}(\\emptyset) = 0\\). Aqui usamos Ax. 1 e 3.\nSeja \\(A_{1} = A\\), \\(A_{2} = A^{c}\\), \\(A_{n} = \\emptyset, n \\ge 3\\). \\(1 = \\mathbb{P}(\\Omega) = \\mathbb{P}(\\bigcup_{n=1}^{\\infty} A_{n}) = \\sum_{n=1}^{\\infty} \\mathbb{P}(A_{n})\\) \\(= \\mathbb{P}(A) + \\mathbb{P}(A^{c}) + \\sum_{n=3}^{\\infty} \\mathbb{P}(A_{n}) \\Rightarrow 1 = \\mathbb{P}(A) + \\mathbb{P}(A^{c}) + 0\\). \\(\\Rightarrow \\mathbb{P}(A^{c}) = 1 - \\mathbb{P}(A)\\). (Fazer 2’).\nPodemos escrever \\(B = A \\cup (B-A)\\) (união disjunta). \\(\\Rightarrow \\mathbb{P}(B) = \\mathbb{P}(A) + \\mathbb{P}(B-A) \\Rightarrow \\mathbb{P}(B-A) = \\mathbb{P}(B) - \\mathbb{P}(A)\\). Como \\(\\mathbb{P}(B-A) \\ge 0 \\Rightarrow \\mathbb{P}(A) \\le \\mathbb{P}(B)\\).\nVamos escrever \\(\\bigcup_{n=1}^{\\infty} A_{n}\\) como uma união de eventos disjuntos. Seja \\(B_{1} = A_{1}\\) e \\(B_{n} = (\\bigcup_{k=1}^{n-1} A_{k})^{c} \\cap A_{n}, n \\ge 2\\). Então \\(B_n \\subseteq A_n, \\forall n\\)  Portanto, \\[\\mathbb{P}(\\bigcup_{n=1}^{\\infty} A_{n}) = \\mathbb{P}(\\bigcup_{n=1}^{\\infty} B_{n}) = \\sum_{n=1}^{\\infty} \\mathbb{P}(B_{n}) \\le \\sum_{n=1}^{\\infty} \\mathbb{P}(A_{n})\\] (Pois \\(B_n \\subseteq A_n \\Rightarrow \\mathbb{P}(B_n) \\le \\mathbb{P}(A_n)\\) pela prop. 3).\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science: Propriedades como ‘Sanity Checks’\n\n\n\nEssas propriedades são ferramentas de “sanidade” que usamos o tempo todo, muitas vezes sem perceber.\n\nProp 2 (Complemento): \\(\\mathbb{P}(\\text{taxa de churn}) = 1 - \\mathbb{P}(\\text{taxa de retenção})\\). É a base para modelar problemas binários (fraude/não-fraude, clicou/não-clicou).\nProp 3 (Monotonicidade): \\(\\mathbb{P}(\\text{Clicou E Comprou}) \\le \\mathbb{P}(\\text{Clicou})\\). A probabilidade de um evento mais específico (um subconjunto) nunca pode ser maior que a do evento geral. Se seu dashboard mostrar o contrário, há um erro no filtro.\nProp 5 (Inclusão-Exclusão): Essencial para evitar contagem dupla. Se você quer saber a proporção de usuários que são “VIP” ou “clicaram em e-mails” (grupos com sobreposição), você não pode simplesmente somar as duas proporções. Você deve subtrair a interseção: \\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\).\n\n\n\n\nTeorema 3.1 (Teorema 1.1 (Continuidade da probabilidade)) Seja \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) um espaço de probabilidade. Se \\(\\{A_n\\}_{n \\ge 1} \\in \\mathcal{F}\\) com \\(A_n \\uparrow A\\) ou \\(A_n \\downarrow A\\), e \\(A \\in \\mathcal{F}\\). Então \\[\\lim_{n \\to \\infty} \\mathbb{P}(A_{n}) = \\mathbb{P}(A).\\]\nDemonstração\nConsidere \\(A_n \\uparrow A\\), isto é, \\(A_{1} \\subseteq A_{2} \\subseteq A_{3} \\subseteq ...\\) Note que \\(A = \\bigcup_{n=1}^{\\infty} A_{n}\\). Defina \\(B_{1} = A_{1}\\), \\(B_{n} = A_{n} - A_{n-1}\\), \\(n \\ge 2\\). Os \\(B_k\\) são disjuntos e \\(\\bigcup_{k=1}^{\\infty} B_k = \\bigcup_{k=1}^{\\infty} A_k = A\\).\n\\[\\mathbb{P}(A) = \\mathbb{P}(\\bigcup_{k=1}^{\\infty} A_{k}) = \\mathbb{P}(\\bigcup_{k=1}^{\\infty} B_{k}) = \\sum_{k=1}^{\\infty} \\mathbb{P}(B_{k})\\] \\[= \\lim_{n \\to \\infty} \\sum_{k=1}^{n} \\mathbb{P}(B_{k}) = \\lim_{n \\to \\infty} [ \\mathbb{P}(A_{1}) + \\sum_{k=2}^{n} \\mathbb{P}(A_{k} - A_{k-1}) ]\\] \\[= \\lim_{n \\to \\infty} ( \\mathbb{P}(A_{1}) + [\\mathbb{P}(A_{2}) - \\mathbb{P}(A_{1})] + [\\mathbb{P}(A_{3}) - \\mathbb{P}(A_{2})] + ... + [\\mathbb{P}(A_{n}) - \\mathbb{P}(A_{n-1})] )\\] \\[= \\lim_{n \\to \\infty} \\mathbb{P}(A_{n})\\]",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Definição Axiomática de Probabilidade</span>"
    ]
  },
  {
    "objectID": "aula03.html#modelos-probabilisticos",
    "href": "aula03.html#modelos-probabilisticos",
    "title": "3  Definição Axiomática de Probabilidade",
    "section": "3.2 Modelos Probabilisticos",
    "text": "3.2 Modelos Probabilisticos\n\n3.2.1 Modelos Probabilísticos Discretos\nSeja \\(\\Omega=\\{\\omega_{1}, \\omega_{2}, ...\\}\\), \\(\\mathcal{F}=\\mathcal{P}(\\Omega)\\). Considere \\(\\{p_{n}\\}_{n \\ge 1}\\) uma sequência de números reais não negativos, tal que \\[ \\sum_{n=1}^{\\infty} p_{n} = 1. \\]\nBasta definir, para \\(n \\ge 1\\), \\(\\mathbb{P}(\\{\\omega_{n}\\}) = p_{n}\\) e para \\(A \\in \\mathcal{F}\\) \\[ \\mathbb{P}(A) = \\sum_{\\{n \\geq 1 \\: \\omega_{n} \\in A\\}} p_{n} = \\sum_{n=1}^{\\infty} p_n \\mathbb{I}_A(\\omega_n).\\]\n\\(\\mathbb{P}\\) definida dessa forma é uma Probabilidade em \\((\\Omega, \\mathcal{F})\\).\n\n\n3.2.2 Modelos Probabilísticos Contínuos\n\\(\\Omega=\\mathbb{R}\\), \\(\\mathcal{F}=\\mathcal{B}(\\mathbb{R})\\)\nSeja \\(f: \\mathbb{R} \\Rightarrow \\mathbb{R}_{+}\\) tal que \\[ \\int_{-\\infty}^{\\infty} f(t) dt = 1 \\]\nPara \\(A \\in \\mathcal{B}(\\mathbb{R})\\), \\[ \\mathbb{P}(A) = \\int_{A} f(t) dt. \\]",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Definição Axiomática de Probabilidade</span>"
    ]
  },
  {
    "objectID": "aula03.html#implementação-prática-em-r",
    "href": "aula03.html#implementação-prática-em-r",
    "title": "3  Definição Axiomática de Probabilidade",
    "section": "3.3 Implementação Prática em R",
    "text": "3.3 Implementação Prática em R\nNa prática, em ciência de dados, trabalhamos com a medida de probabilidade empírica, que é simplesmente a frequência relativa observada em nosso dataset.\nVamos criar um dataset \\(\\:\\Omega\\) e verificar como as propriedades dos axiomas se aplicam a ele.\n\n# Criar nosso universo (Omega)\nset.seed(42)\nOmega_data &lt;- data.frame(\n  user_id = 1:1000,\n  segmento = sample(c(\"VIP\", \"Regular\", \"Novo\"), 1000, replace = TRUE, prob = c(0.1, 0.6, 0.3)),\n  clicou = sample(c(0, 1), 1000, replace = TRUE, prob = c(0.8, 0.2))\n)\n\nhead(Omega_data)\n\n\n\n\n\n\nuser_id\nsegmento\nclicou\n\n\n\n\n1\nVIP\n1\n\n\n2\nVIP\n0\n\n\n3\nRegular\n1\n\n\n4\nNovo\n0\n\n\n5\nNovo\n0\n\n\n6\nRegular\n0\n\n\n\n\n\n\n3.3.1 Definindo nossa Medida de Probabilidade Empírica\nNossa função \\(\\mathbb{P}\\) será baseada na contagem de linhas.\n\n# P(A) = nrow(A) / nrow(Omega)\nP &lt;- function(evento_subset) {\n  nrow(evento_subset) / nrow(Omega_data)\n}\n\n\n\n3.3.2 Verificando os Axiomas e Propriedades\n\n# Axioma 1: P(Omega) = 1\ncat(\"Axioma 1: P(Omega) =\", P(Omega_data), \"\\n\")\n\nAxioma 1: P(Omega) = 1 \n\n# Axioma 2: P(A) &gt;= 0\nA &lt;- subset(Omega_data, segmento == \"VIP\")\ncat(\"Axioma 2: P(A='VIP') =\", P(A), \"(&gt;= 0)\\n\")\n\nAxioma 2: P(A='VIP') = 0.111 (&gt;= 0)\n\n# Axioma 3 (Prop. 2'): Aditividade para eventos disjuntos\nA_vip &lt;- subset(Omega_data, segmento == \"VIP\")\nB_reg &lt;- subset(Omega_data, segmento == \"Regular\")\nA_ou_B &lt;- subset(Omega_data, segmento %in% c(\"VIP\", \"Regular\"))\n\n# Verificando se P(A U B) = P(A) + P(B)\ncat(\"  P(A U B) =\", P(A_ou_B), \"\\n\")\n\n  P(A U B) = 0.734 \n\ncat(\"  P(A) + P(B) =\", P(A_vip) + P(B_reg), \"\\n\")\n\n  P(A) + P(B) = 0.734 \n\n\n\n# Propriedade 2: P(A^c) = 1 - P(A)\nA_clicou &lt;- subset(Omega_data, clicou == 1)\nAc_nao_clicou &lt;- subset(Omega_data, clicou != 1) # ou clicou == 0\n\ncat(\"  P(A^c) =\", P(Ac_nao_clicou), \"\\n\")\n\n  P(A^c) = 0.795 \n\ncat(\"  1 - P(A) =\", 1 - P(A_clicou), \"\\n\")\n\n  1 - P(A) = 0.795 \n\n\n\n# Propriedade 5: P(A U B) = P(A) + P(B) - P(A ∩ B) (Eventos NÃO disjuntos)\n# A = \"Usuário é VIP\"\n# B = \"Usuário Clicou\"\nA &lt;- subset(Omega_data, segmento == \"VIP\")\nB &lt;- subset(Omega_data, clicou == 1)\n\n# A U B (União: VIP OU Clicou)\nA_ou_B_nao_disj &lt;- subset(Omega_data, segmento == \"VIP\" | clicou == 1)\n\n# A ∩ B (Interseção: VIP E Clicou)\nA_e_B &lt;- subset(Omega_data, segmento == \"VIP\" & clicou == 1)\n\ncat(\"  Lado Esquerdo: P(A U B) =\", P(A_ou_B_nao_disj), \"\\n\")\n\n  Lado Esquerdo: P(A U B) = 0.297 \n\ncat(\"  Lado Direito: P(A) + P(B) - P(A ∩ B) =\", P(A) + P(B) - P(A_e_B), \"\\n\")\n\n  Lado Direito: P(A) + P(B) - P(A ∩ B) = 0.297 \n\n\nIsso demonstra que a fórmula de Inclusão-Exclusão é necessária para evitar a contagem dupla de usuários que estão em ambos os grupos.",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Definição Axiomática de Probabilidade</span>"
    ]
  },
  {
    "objectID": "aula04.html",
    "href": "aula04.html",
    "title": "4  Probabilidade Condicional",
    "section": "",
    "text": "4.1 Independência de Eventos\nEm ciência de dados, raramente olhamos para a população inteira (\\(\\Omega\\)). Nosso trabalho é quase sempre “fatiar” os dados para entender subpopulações.\nEm todos esses casos, não estamos perguntando \\(\\mathbb{P}(A)\\), mas sim \\(\\mathbb{P}(A|B)\\). Estamos pedindo a probabilidade de \\(A\\) (conversão, churn, fraude) depois de reduzirmos nosso universo \\(\\Omega\\) para um subconjunto \\(B\\) (usuários do Facebook, clientes VIP, transações atípicas). A probabilidade condicional é a formalização matemática dessa “redução de universo” ou “filtro”.\nNotas:\nDizemos que \\(A_1, A_2, \\dots \\in \\mathcal{F}\\) formam uma partição de \\(\\Omega\\) se são (mutuamente) disjuntos e \\(\\bigcup_{k=1}^{\\infty} A_k = \\Omega\\).\nDessa forma, para todo evento \\(B \\subseteq \\Omega\\), \\[ B = \\bigcup_{k=1}^{\\infty} (A_k \\cap B) \\]\nUsando o Teorema 4.2, podemos obter a fórmula de Bayes: \\[ \\mathbb{P}(A_i|B) = \\frac{\\mathbb{P}(A_i \\cap B)}{\\mathbb{P}(B)} = \\frac{\\mathbb{P}(A_i) \\mathbb{P}(B|A_i)}{\\sum_{k=1}^{\\infty} \\mathbb{P}(A_k) \\mathbb{P}(B|A_k)} \\]\nNotas:\nExercício 19 (lista 2) \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) espaço de probabilidade, \\(A \\in \\mathcal{F}\\), com \\(\\mathbb{P}(A) \\in (0, 1)\\). A e B são independentes se, e só se, \\(\\mathbb{P}(B|A) = \\mathbb{P}(B|A^c)\\).",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probabilidade Condicional</span>"
    ]
  },
  {
    "objectID": "aula04.html#independência-de-eventos",
    "href": "aula04.html#independência-de-eventos",
    "title": "4  Probabilidade Condicional",
    "section": "",
    "text": "Definição 4.2 (Definição 1.6 (Independência)) Seja \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) um espaço de probabilidade. Os eventos A e B são independentes se, e somente se, \\[ \\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\mathbb{P}(B) \\]\n\n\n\nEventos de probabilidade zero ou um são independentes de qualquer outro.\nDois eventos são independentes se, e somente se, \\(\\mathbb{P}(A|B) = \\mathbb{P}(A)\\).\nSe \\(A \\cap B = \\emptyset,\\) então A e B não são independentes (a menos que um deles tenha probabilidade zero).\n\n\nProposição 4.1 (Proposição 1.3) A é independente de si mesmo se, e somente se, \\(\\mathbb{P}(A)=0\\) ou \\(\\mathbb{P}(A)=1\\).\nDemonstração: De fato, \\(\\mathbb{P}(A \\cap A) = \\mathbb{P}(A) \\mathbb{P}(A) \\Leftrightarrow \\mathbb{P}(A) = [\\mathbb{P}(A)]^2\\) \\(\\Leftrightarrow \\mathbb{P}(A) = 0 \\text{ ou } \\mathbb{P}(A) = 1\\).\n\n\nProposição 4.2 (Proposição 1.4) Se A e B são independentes, então A e \\(B^c\\) também são independentes. (e também \\(A^c\\) e B, e ainda \\(A^c\\) e \\(B^c\\)).\nDemonstração: \\(A \\text{ e } B \\text{ indep.} \\Rightarrow \\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\mathbb{P}(B)\\) Temos \\(A = (A \\cap B) \\cup (A \\cap B^c)\\). \\[ \\mathbb{P}(A \\cap B^c) = \\mathbb{P}(A - (A \\cap B)) = \\mathbb{P}(A) - \\mathbb{P}(A \\cap B) \\] \\[ = \\mathbb{P}(A) - \\mathbb{P}(A)\\mathbb{P}(B) \\] \\[ = \\mathbb{P}(A) [1 - \\mathbb{P}(B)] = \\mathbb{P}(A) \\mathbb{P}(B^c). \\]\n\n\nDefinição 4.3 (Definição 1.7) Os eventos aleatórios \\(\\{A_i\\}_{i \\in I}\\) são independentes 2 a 2 se \\[ \\mathbb{P}(A_i \\cap A_j) = \\mathbb{P}(A_i) \\mathbb{P}(A_j), \\quad \\forall i, j \\in I, i \\neq j \\]\n\n\nDefinição 4.4 (Definição 1.8) Os eventos aleatórios \\(\\{A_i\\}_{i \\in I}\\) são (mutuamente) independentes se, e só se, dado qualquer conjunto de índices distintos \\(i_1, \\dots, i_n \\in I\\), \\(n \\ge 2\\), vale \\[ \\mathbb{P}(A_{i_1} \\cap A_{i_2} \\cap \\dots \\cap A_{i_n}) = \\prod_{k=1}^{n} \\mathbb{P}(A_{i_k}) \\]\n\n\nExemplo 4.2 (Exemplo 1.14) Seja \\(\\Omega = \\{u_1, u_2, u_3, u_4\\}\\) (4 usuários), com \\(\\mathbb{P}(\\{u_i\\}) = 1/4, \\forall i\\). Defina os eventos (características dos usuários):\n\n\\(A\\) = “Engajamento Alto” = \\(\\{u_2, u_4\\}\\)\n\\(B\\) = “Região Sudeste” = \\(\\{u_1, u_2\\}\\)\n\\(C\\) = “Acesso via Mobile” = \\(\\{u_1, u_4\\}\\)\n\nVerifique que A, B e C são 2 a 2 independentes, mas não coletivamente independentes.\n\\(\\mathbb{P}(A) = 2/4 = 1/2\\) \\(\\mathbb{P}(B) = 2/4 = 1/2\\) \\(\\mathbb{P}(C) = 2/4 = 1/2\\)\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(\\{u_2\\}) = 1/4\\). Logo \\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A)\\mathbb{P}(B)\\). (A e B são indep.)\n\\(\\mathbb{P}(B \\cap C) = \\mathbb{P}(\\{u_1\\}) = 1/4\\). Logo \\(\\mathbb{P}(B \\cap C) = \\mathbb{P}(B)\\mathbb{P}(C)\\). (B e C são indep.)\n\\(\\mathbb{P}(A \\cap C) = \\mathbb{P}(\\{u_4\\}) = 1/4\\). Logo \\(\\mathbb{P}(A \\cap C) = \\mathbb{P}(A)\\mathbb{P}(C)\\). (A e C são indep.)\nMas: \\(\\mathbb{P}(A \\cap B \\cap C) = \\mathbb{P}(\\emptyset) = 0\\).\n\\(\\mathbb{P}(A)\\mathbb{P}(B)\\mathbb{P}(C) = (1/2)^3 = 1/8\\).\nComo \\(0 \\neq 1/8\\), os eventos não são mutuamente independentes. Saber B e C juntos nos diz que o usuário é \\(u_1\\), o que exclui a possibilidade de ser A.\n\n\nExemplo 4.3 (Exemplo 1.15) Mostre que se \\(A_1, A_2, \\dots, A_n\\) são independentes e \\(\\bigcup_{i=1}^n A_i = \\Omega\\), então \\(\\exists i\\) tal que \\(\\mathbb{P}(A_i) = 1\\).\nDemonstração: \\(\\bigcup_{i=1}^n A_i = \\Omega \\Rightarrow \\mathbb{P}(\\bigcup_{i=1}^n A_i) = 1\\). Pela Lei de De Morgan: \\(1 = \\mathbb{P}((\\bigcap_{i=1}^n A_i^c)^c) = 1 - \\mathbb{P}(\\bigcap_{i=1}^n A_i^c)\\)\n\\(\\Rightarrow \\mathbb{P}(\\bigcap_{i=1}^n A_i^c) = 0\\).\n\\(A_i\\) independentes \\(\\Rightarrow A_i^c\\) independentes \\(\\Rightarrow \\prod_{i=1}^n \\mathbb{P}(A_i^c) = 0\\).\nEntão, \\(\\exists i\\) tal que \\(\\mathbb{P}(A_i^c) = 0 \\Rightarrow \\mathbb{P}(A_i) = 1\\).\n\n\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science: A Hipótese Nula de um Teste A/B\n\n\n\nEste exercício é a definição matemática da hipótese nula (\\(H_0\\)) em um teste A/B.\n\n\\(B\\) = O evento de interesse (ex: “Compra”)\n\\(A\\) = “Usuário viu a Versão A (Tratamento)”\n\\(A^c\\) = “Usuário viu a Versão B (Controle)”\n\nA afirmação \\(\\mathbb{P}(B|A) = \\mathbb{P}(B|A^c)\\) se traduz em: “A taxa de compra no grupo Tratamento é exatamente igual à taxa de compra no grupo Controle.”\nO exercício prova que isso é matematicamente equivalente a dizer que “fazer a compra” (\\(B\\)) é independente do “grupo que o usuário viu” (\\(A\\)).\nNosso objetivo no teste é justamente tentar rejeitar essa afirmação, provando que os eventos são dependentes e que \\(\\mathbb{P}(B|A) \\neq \\mathbb{P}(B|A^c)\\).",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probabilidade Condicional</span>"
    ]
  },
  {
    "objectID": "aula04.html#implementação-prática-em-r",
    "href": "aula04.html#implementação-prática-em-r",
    "title": "4  Probabilidade Condicional",
    "section": "4.2 Implementação Prática em R",
    "text": "4.2 Implementação Prática em R\nVamos usar o dataset da aula anterior para verificar esses conceitos na prática.\n\n# Criar nosso universo (Omega)\nset.seed(42)\nOmega_data &lt;- data.frame(\n  user_id = 1:1000,\n  segmento = sample(c(\"VIP\", \"Regular\", \"Novo\"), 1000, replace = TRUE, prob = c(0.1, 0.6, 0.3)),\n  clicou = sample(c(0, 1), 1000, replace = TRUE, prob = c(0.8, 0.2))\n)\n\n# Definindo nossa função de probabilidade empírica\nP &lt;- function(evento_subset) {\n  nrow(evento_subset) / nrow(Omega_data)\n}\n\nQual a probabilidade de um usuário “clicar” (\\(A\\)) dado que ele é “VIP” (\\(B\\))?\n\n# P(A|B) = P(A ∩ B) / P(B)\n\nlibrary(tidyverse)\n\n# Eventos\nA_clicou &lt;- Omega_data |&gt; filter(clicou == 1)\nB_vip &lt;- Omega_data |&gt; filter(segmento == \"VIP\")\nA_e_B &lt;- Omega_data |&gt; filter(clicou == 1 & segmento == \"VIP\")\n\n# Probabilidades\nP_A_e_B &lt;- P(A_e_B)\nP_B &lt;- P(B_vip)\n\nP_A_dado_B &lt;- P_A_e_B / P_B\ncat(\"P(Clicou | VIP) via fórmula:\", P_A_dado_B, \"\\n\")\n\nP(Clicou | VIP) via fórmula: 0.1711712 \n\n\n\n# Forma Direta (Reduzindo o Universo)\n# 1. Reduzimos nosso universo para Omega' = B_vip\nOmega_filtrado &lt;- Omega_data |&gt; filter(segmento == \"VIP\")\n\n# 2. Calculamos a probabilidade de A dentro desse NOVO universo\n# Note que aqui o denominador é nrow(Omega_filtrado)\nP_A_no_universo_B &lt;- sum(Omega_filtrado$clicou == 1) / nrow(Omega_filtrado)\n\ncat(\"P(Clicou | VIP) via filtro direto:\", P_A_no_universo_B, \"\\n\")\n\nP(Clicou | VIP) via filtro direto: 0.1711712 \n\n\nOs resultados são idênticos, validando a definição.\nOs eventos \\(A\\)=“clicou” e \\(B\\)=“VIP” são independentes? Verificamos se \\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\times \\mathbb{P}(B)\\).\n\nP_A &lt;- P(A_clicou)\n# P_B e P_A_e_B já foram calculados\n\ncat(\"Verificando Independência (Clicou e VIP):\\n\")\n\nVerificando Independência (Clicou e VIP):\n\ncat(\"  Lado Esquerdo: P(A ∩ B) =\", P_A_e_B, \"\\n\")\n\n  Lado Esquerdo: P(A ∩ B) = 0.019 \n\ncat(\"  Lado Direito: P(A) * P(B) =\", P_A * P_B, \"\\n\")\n\n  Lado Direito: P(A) * P(B) = 0.022755 \n\n\nComo os valores são diferentes, os eventos NÃO são independentes. Saber que um usuário é “VIP” MUDA a probabilidade de ele “clicar”.\nA partição do nosso universo são os segmentos: \\(A_1\\)=“VIP”, \\(A_2\\)=“Regular”, \\(A_3\\)=“Novo”. O evento \\(B\\) é “clicou”.\nVamos “remontar” a \\(\\mathbb{P}(B)\\) geral usando a fórmula: \\(\\mathbb{P}(B) = \\mathbb{P}(B|A_1)\\mathbb{P}(A_1) + \\mathbb{P}(B|A_2)\\mathbb{P}(A_2) + \\mathbb{P}(B|A_3)\\mathbb{P}(A_3)\\)\n\n# 1. Probabilidades da Partição P(A_k)\nP_A1_vip &lt;- P(Omega_data |&gt; filter(segmento == \"VIP\"))\nP_A2_reg &lt;- P(Omega_data |&gt; filter(segmento == \"Regular\"))\nP_A3_nov &lt;- P(Omega_data |&gt; filter(segmento == \"Novo\"))\n\n# 2. Probabilidades Condicionais P(B | A_k)\n# Usando o método direto (filtrado)\nP_B_dado_A1 &lt;- Omega_data |&gt; \n  filter(segmento == \"VIP\") |&gt; \n  summarise(media = mean(clicou)) |&gt; \n  pull(media)\n\nP_B_dado_A2 &lt;- Omega_data |&gt; \n  filter(segmento == \"Regular\") |&gt; \n  summarise(media = mean(clicou)) |&gt; \n  pull(media)\n\nP_B_dado_A3 &lt;- Omega_data |&gt; \n  filter(segmento == \"Novo\") |&gt; \n  summarise(media = mean(clicou)) |&gt; \n  pull(media)\n\ncat(\"P(Clicou|VIP):\", P_B_dado_A1, \"\\n\")\n\nP(Clicou|VIP): 0.1711712 \n\ncat(\"P(Clicou|Regular):\", P_B_dado_A2, \"\\n\")\n\nP(Clicou|Regular): 0.2054575 \n\ncat(\"P(Clicou|Novo):\", P_B_dado_A3, \"\\n\")\n\nP(Clicou|Novo): 0.2180451 \n\n# 3. Média Ponderada\nP_B_calculada &lt;- (P_B_dado_A1 * P_A1_vip) + \n                 (P_B_dado_A2 * P_A2_reg) + \n                 (P_B_dado_A3 * P_A3_nov)\n\ncat(\"P(B) via Lei Total (Média Ponderada):\", P_B_calculada, \"\\n\")\n\nP(B) via Lei Total (Média Ponderada): 0.205 \n\n# 4. Probabilidade Real (Geral)\nP_B_real &lt;- P(Omega_data |&gt; filter(clicou == 1))\ncat(\"P(B) Real (Taxa Geral de Clique):\", P_B_real, \"\\n\")\n\nP(B) Real (Taxa Geral de Clique): 0.205 \n\n\nOs valores são idênticos, validando a Lei da Probabilidade Total.",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probabilidade Condicional</span>"
    ]
  },
  {
    "objectID": "aula05.html",
    "href": "aula05.html",
    "title": "5  Exercícios",
    "section": "",
    "text": "Nesta seção, vamos resolver exercícios que parecem puramente teóricos (e são!). Em vez de calcular a probabilidade de “cliques” ou “segmentos”, vamos provar propriedades fundamentais da própria função \\(\\mathbb{P}\\).\nPor que um cientista de dados faria isso? Porque essas propriedades são as garantias e testes de sanidade que rodam “por baixo dos panos” em toda análise. Elas são a justificativa teórica que nos permite:\n\nConfiar que, se um modelo é 99,99% preciso em n cenários, ele continua sendo confiável.\nEntender o que acontece quando combinamos features (interseções) ou segmentos (uniões).\nUsar a lógica (SE/ENTÃO) para criar regras de negócio a partir dos dados.\n\nVamos ver como.\n\nSeja \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) um espaço de probabilidade e \\(\\{A_n\\}_{n \\ge 1} \\in \\mathcal{F}\\). Mostre que:\n\nSe \\(\\mathbb{P}(A_n) = 0, \\forall n=1, 2, \\dots\\), então \\(\\mathbb{P}(\\bigcup_{n=1}^{\\infty} A_n) = 0\\).\n\nSolução: Pela Propriedade 4 (Subaditividade), sabemos que \\(\\mathbb{P}(\\bigcup_{n=1}^{\\infty} A_n) \\le \\sum_{n=1}^{\\infty} \\mathbb{P}(A_n)\\). Substituindo os valores dados: \\[ \\mathbb{P}(\\bigcup_{n=1}^{\\infty} A_n) \\le \\sum_{n=1}^{\\infty} 0 = 0 \\] Como a probabilidade não pode ser negativa (Axioma 2), Logo, \\(\\mathbb{P}(\\bigcup_{n=1}^{\\infty} A_n) = 0\\).\n\nSe \\(\\mathbb{P}(A_n) = 1, \\forall n=1, 2, \\dots\\), então \\(\\mathbb{P}(\\bigcap_{n=1}^{\\infty} A_n) = 1\\).\n\nSolução: Usando a Lei de De Morgan e a Propriedade 2: \\[ \\mathbb{P}(\\bigcap_{n=1}^{\\infty} A_n) = 1 - \\mathbb{P}((\\bigcap_{n=1}^{\\infty} A_n)^c) = 1 - \\mathbb{P}(\\bigcup_{n=1}^{\\infty} A_n^c) \\] Se \\(\\mathbb{P}(A_n) = 1\\), então \\(\\mathbb{P}(A_n^c) = 1 - \\mathbb{P}(A_n) = 0, \\forall n\\). Pelo item (a), se \\(\\mathbb{P}(A_n^c) = 0, \\forall n\\), então \\(\\mathbb{P}(\\bigcup_{n=1}^{\\infty} A_n^c) = 0\\). Substituindo na equação: \\[ \\mathbb{P}(\\bigcap_{n=1}^{\\infty} A_n) = 1 - 0 = 1 \\]\nSeja \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) um espaço de probabilidade e \\(\\{A_n\\}_{n \\ge 1} \\in \\mathcal{F}, \\{B_n\\}_{n \\ge 1} \\in \\mathcal{F}\\). com \\(\\lim_{n \\to \\infty} \\mathbb{P}(A_n) = 1\\) e \\(\\lim_{n \\to \\infty} \\mathbb{P}(B_n) = p\\). Mostre que \\(\\lim_{n \\to \\infty} \\mathbb{P}(A_n \\cap B_n) = p\\).\nSolução: Sabemos que \\(A_n \\subseteq A_n \\cup B_n \\Rightarrow \\mathbb{P}(A_n) \\le \\mathbb{P}(A_n \\cup B_n)\\). Como \\(\\mathbb{P}(A_n \\cup B_n) \\le 1\\), temos: \\[ \\mathbb{P}(A_n) \\le \\mathbb{P}(A_n \\cup B_n) \\le 1 \\]\n\\[ 1=\\lim_{n \\to \\infty} \\mathbb{P}(A_n) \\le \\lim_{n \\to \\infty} \\mathbb{P}(A_n \\cup B_n) \\le 1 \\] \\[ \\Rightarrow \\lim_{n \\to \\infty} \\mathbb{P}(A_n \\cup B_n) = 1 \\] Usando a fórmula da união (Propriedade 5): \\[ \\mathbb{P}(A_n \\cup B_n) = \\mathbb{P}(A_n) + \\mathbb{P}(B_n) - \\mathbb{P}(A_n \\cap B_n) \\] Aplicando o limite em todos os termos: \\[ \\lim_{n \\to \\infty} \\mathbb{P}(A_n \\cup B_n) = \\lim_{n \\to \\infty} \\mathbb{P}(A_n) + \\lim_{n \\to \\infty} \\mathbb{P}(B_n) - \\lim_{n \\to \\infty} \\mathbb{P}(A_n \\cap B_n) \\] Substituindo os valores conhecidos: \\[ 1 = 1 + p - \\lim_{n \\to \\infty} \\mathbb{P}(A_n \\cap B_n) \\] \\[ 0 = p - \\lim_{n \\to \\infty} \\mathbb{P}(A_n \\cap B_n) \\] Logo, \\(\\lim_{n \\to \\infty} \\mathbb{P}(A_n \\cap B_n) = p\\).\nSeja \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) um espaço de probabilidade, \\(A \\in \\mathcal{F}, B \\in \\mathcal{F}\\) tal que \\(\\mathbb{P}(A) &lt; 1\\), \\(\\mathbb{P}(B) &gt; 0\\) e \\(\\mathbb{P}(A|B) = 1\\). Então \\(\\mathbb{P}(B^c|A^c) = 1\\).\nSolução: \\[\n\\begin{align*}\n\\mathbb{P}(B^c|A^c) &= 1 - \\mathbb{P}(B|A^c) \\\\\n                   &= 1 - \\frac{\\mathbb{P}(B \\cap A^c)}{\\mathbb{P}(A^c)} \\\\\n                   &= 1 - \\frac{\\mathbb{P}(A^c|B) \\mathbb{P}(B)}{\\mathbb{P}(A^c)} \\\\\n                   &= 1 - \\frac{(1 - \\mathbb{P}(A|B)) \\mathbb{P}(B)}{\\mathbb{P}(A^c)} \\\\\n\\end{align*}\n\\] Dado que \\(\\mathbb{P}(A|B) = 1\\): \\[\n\\begin{align*}\n\\mathbb{P}(B^c|A^c) &= 1 - \\frac{(1 - 1) \\mathbb{P}(B)}{\\mathbb{P}(A^c)} \\\\\n                   &= 1 - \\frac{0 \\cdot \\mathbb{P}(B)}{\\mathbb{P}(A^c)} \\\\\n                   &= 1 - 0 = 1\n\\end{align*}\n\\] (Note que \\(\\mathbb{P}(A^c) = 1 - \\mathbb{P}(A) &gt; 0\\), pois \\(\\mathbb{P}(A) &lt; 1\\), então a divisão é válida).\nUma moeda com probabilidade \\(p\\) de cara em cada lançamento é lançada infinitas vezes, de maneira independente. Sejam \\(A_n\\): ocorre pelo menos uma cara nos \\(n\\) primeiros lançamentos, \\(n \\ge 1\\). \\(A\\): ocorre pelo menos uma cara.\n\nMostre que \\(A_n \\uparrow A\\).\nMostre que \\(\\mathbb{P}(A) = \\begin{cases} 1, \\text{ se } 0 &lt; p \\le 1 \\\\ 0, \\text{ se } p = 0 \\end{cases}\\).\n\nSolução (a): \\(A_n \\subseteq A_{n+1}, n \\ge 1. \\rightarrow \\{A_n\\}_{n \\ge 1}\\) é uma seq. monótona não decrescente.\nLogo, \\(\\lim_{n \\to \\infty} A_n = \\bigcup_{n=1}^{\\infty} A_n\\).\n\\(\\omega \\in \\bigcup_{n=1}^{\\infty} A_n \\Rightarrow \\exists n \\text{ tal que } \\omega \\in A_n \\Rightarrow \\omega \\in A\\). Também, \\(\\omega \\in A \\Rightarrow \\exists n \\text{ tal que } \\omega \\in A_n \\Rightarrow \\omega \\in \\bigcup_{n=1}^{\\infty} A_n\\).\nSolução (b): (em que \\(E_i\\): ocorreu cara no lançamento \\(i\\)) \\[\n\\begin{align*}\n\\mathbb{P}(A) &= \\mathbb{P}(\\bigcup_{n=1}^{\\infty} A_n) = \\mathbb{P}(\\lim_{n \\to \\infty} A_n) = \\lim_{n \\to \\infty} \\mathbb{P}(A_n) = \\lim_{n \\to \\infty} [1 - \\mathbb{P}(A_n^c)] \\\\\n              &= \\lim_{n \\to \\infty} [1 - \\mathbb{P}(E_1^c \\cap E_2^c \\cap \\dots \\cap E_n^c)] \\\\\n              &= \\lim_{n \\to \\infty} [1 - \\prod_{i=1}^n \\mathbb{P}(E_i^c)] \\quad \\text{(indep.)} \\\\\n              &= \\lim_{n \\to \\infty} (1 - (1-p)^n) = \\begin{cases} 1, & \\text{ se } 0 &lt; p \\le 1 \\\\ 0, & \\text{ se } p = 0 \\end{cases}\n\\end{align*}\n\\]\nEm que \\(E_i:\\) ocorreu cara no lançamento \\(i.\\)\n\\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) espaço de probabilidade com \\(A, B, A_1, A_2, \\dots \\in \\mathcal{F}\\). Suponha \\(A_n \\uparrow A\\) e que B é independente de \\(A_n, \\forall n \\ge 1\\). Prove que A e B são independentes.\nSolução: \\[\n\\mathbb{P}(A|B) = \\mathbb{P}(\\bigcup_{n=1}^{\\infty} A_n | B) = \\lim_{n \\to \\infty} \\mathbb{P}(A_n|B) = \\lim_{n \\to \\infty} \\mathbb{P}(A_n) = \\mathbb{P}(\\bigcup_{n=1}^{\\infty} A_n) = \\mathbb{P}(A)\n\\] Logo, A e B são independentes.",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Exercícios</span>"
    ]
  },
  {
    "objectID": "aula06.html",
    "href": "aula06.html",
    "title": "6  Variáveis Aleatórias",
    "section": "",
    "text": "6.1 Espaço de Probabilidade Induzido\nAté agora, lidamos com o espaço amostral \\(\\Omega\\) (ex: o conjunto de todos os usuários) e eventos \\(\\mathcal{F}\\) (ex: “o usuário é VIP”). No entanto, em Data Science, raramente trabalhamos com o evento “bruto” \\((\\omega)\\).\nNão analisamos o log JSON inteiro de um usuário; nós extraímos métricas numéricas dele:\nUma Variável Aleatória (v.a.) é a ferramenta matemática formal que representa essa extração. É uma função que mapeia o resultado complexo de um experimento (\\(\\omega\\)) para um número real (\\(\\mathbb{R}\\)) que podemos medir e modelar.\nEm todo caso, X é uma função de \\(\\Omega\\) em \\(\\mathbb{R}\\), isto é, \\(X: \\Omega \\rightarrow \\mathbb{R}\\).\nEm todo caso, X é uma função de \\(\\Omega\\) em \\(\\mathbb{R}\\), isto é, \\(X: \\Omega \\rightarrow \\mathbb{R}\\).\nVamos impor uma restrição sobre a função X que permitirá atribuir probabilidades a eventos como “número de caras é, no máximo, 5”.\nNotas:\nDado um espaço de probabilidade \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) e uma v.a. X, definimos o espaço de probabilidade induzido por X como \\((\\mathbb{R}, \\mathcal{B}, \\mathbb{P}_X)\\), em que \\(\\mathcal{B}\\) é a \\(\\sigma\\)-álgebra de Borel em \\(\\mathbb{R}\\), que contém todos os subconjuntos de \\(\\mathbb{R}\\) que nos interessam, e \\[ \\mathbb{P}_X(B) = \\mathbb{P}(\\{\\omega \\in \\Omega : X(\\omega) \\in B\\}), \\quad B \\in \\mathcal{B} \\] \\[ = \\mathbb{P}(X \\in B) \\]\nNotas:",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Variáveis Aleatórias</span>"
    ]
  },
  {
    "objectID": "aula06.html#espaço-de-probabilidade-induzido",
    "href": "aula06.html#espaço-de-probabilidade-induzido",
    "title": "6  Variáveis Aleatórias",
    "section": "",
    "text": "Neste caso, o espaço amostral é \\(\\mathbb{R}\\), os eventos aleatórios são os borelianos e a medida de probabilidade é \\(\\mathbb{P}_X\\).\nA medida de probabilidade \\(\\mathbb{P}_X\\) é chamada distribuição de X.\nVerifique que \\(\\mathbb{P}_X\\) é, de fato, uma probabilidade.\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science: O Histograma é a Distribuição Induzida \\(\\mathbb{P}_X\\)\n\n\n\nEste é o passo mais importante da Análise Exploratória de Dados (EDA).\n\nNós jogamos \\(\\Omega\\) fora: Não nos importamos mais com os milhões de logs brutos (\\(\\Omega\\)).\nNós focamos em \\(\\mathbb{P}_X\\): Nós nos importamos apenas com a distribuição da feature \\(X\\).\n\nQuando você plota um histograma da session_duration, você está plotando uma estimativa empírica da distribuição induzida \\(\\mathbb{P}_X\\).\nO histograma da session_duration (\\(X\\)) vive no espaço \\((\\mathbb{R}, \\mathcal{B}, \\mathbb{P}_X)\\). Ele não vive mais no espaço de logs brutos (\\(\\Omega, \\mathcal{F}, \\mathbb{P}\\)). A v.a. \\(X\\) nos permitiu “transportar” a probabilidade de um espaço complexo (logs) para um espaço simples (\\(\\mathbb{R}\\)) onde podemos fazer estatística.\n\n\n\nExemplo 6.8 (Exemplo 2.6) Um experimento coleta 3 features de um usuário: \\(F_1, F_2, F_3\\) (ex: device_type, country, time_of_day). \\(\\Omega = \\{1, \\dots, 6\\} \\times \\{1, \\dots, 10\\} \\times \\{1, \\dots, 24\\}\\) (um espaço amostral com \\(6 \\times 10 \\times 24 = 1440\\) resultados possíveis). \\(\\mathcal{F} = \\mathcal{P}(\\Omega)\\) e \\(\\mathbb{P}\\) é uniforme por simplicidade.\nEstamos interessados apenas na feature \\(X = F_1\\) (device_type, com 6 tipos). \\(X: \\Omega \\rightarrow \\mathbb{R}\\) com \\(X(\\omega) = \\omega_1\\), em que \\(\\omega = (\\omega_1, \\omega_2, \\omega_3) \\in \\Omega\\). Suponha que queiramos calcular \\(\\mathbb{P}(1.5 \\le X \\le 3.4)\\) (ou seja, \\(\\mathbb{P}(X=2 \\text{ ou } X=3)\\)).\nCálculo no espaço original \\((\\Omega)\\): \\[ \\mathbb{P}(\\{\\omega : 1.5 \\le X(\\omega) \\le 3.4\\}) = \\mathbb{P}(\\{\\omega : \\omega_1 \\in \\{2, 3\\}\\}) \\] \\[ = \\frac{n(\\{\\omega : \\omega_1 \\in \\{2, 3\\}\\})}{1440} = \\frac{n(\\{2, 3\\} \\times \\{1, \\dots, 10\\} \\times \\{1, \\dots, 24\\})}{1440} \\] \\[ = \\frac{2 \\times 10 \\times 24}{1440} = \\frac{480}{1440} = \\frac{1}{3} \\] (Este cálculo foi complicado e exigiu pensar nas outras features).\nCálculo no espaço induzido \\((\\mathbb{R}, \\mathcal{B}, \\mathbb{P}_X)\\): A v.a. \\(X\\) induz uma distribuição \\(\\mathbb{P}_X\\) que é simplesmente: \\[ \\mathbb{P}_X(B) = \\frac{n(B \\cap \\{1, 2, 3, 4, 5, 6\\})}{6}, \\quad B \\in \\mathcal{B}. \\] (Nós efetivamente “ignoramos” as features \\(F_2\\) e \\(F_3\\)). Para calcular \\(\\mathbb{P}(1.5 \\le X \\le 3.4)\\), nós perguntamos ao espaço induzido: \\[ \\mathbb{P}_X([1.5, 3.4]) = \\frac{n([1.5, 3.4] \\cap \\{1, 2, 3, 4, 5, 6\\})}{6} \\] \\[ = \\frac{n(\\{2, 3\\})}{6} = \\frac{2}{6} = \\frac{1}{3} \\] (Muito mais simples!)",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Variáveis Aleatórias</span>"
    ]
  },
  {
    "objectID": "aula06.html#implementação-prática-em-r",
    "href": "aula06.html#implementação-prática-em-r",
    "title": "6  Variáveis Aleatórias",
    "section": "6.2 Implementação Prática em R",
    "text": "6.2 Implementação Prática em R\nVamos demonstrar como um data.frame é o nosso \\(\\Omega\\), e as colunas são as Variáveis Aleatórias.\n\n# Carregando pacotes\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tibble)\n\n# 1. Nosso Espaço Amostral Omega (Ω)\n# Cada linha (observação) é um resultado do experimento (ω)\n# O data.frame em si é o nosso universo Omega\nset.seed(42)\nOmega_data &lt;- tibble(\n  user_id = 1:1000,\n  # O 'evento bruto' ω pode ser um log complexo\n  raw_event_log = paste0(\"user_id: \", user_id, \", time: \", rnorm(1000, 50, 20)),\n  \n  # FEATURES (Variáveis Aleatórias)\n  # X é uma v.a. contínua (extraída do log)\n  X_session_duration = abs(rnorm(1000, 120, 40)), \n  \n  # Y é uma v.a. discreta (extraída do log)\n  Y_click_count = rpois(1000, 1.5),\n  \n  # Z é uma v.a. binária (Função Indicadora)\n  Z_is_vip = sample(c(0, 1), 1000, replace = TRUE, prob = c(0.9, 0.1))\n)\n\n\nhead(Omega_data)\n\n\n\n\n\n\nuser_id\nraw_event_log\nX_session_duration\nY_click_count\nZ_is_vip\n\n\n\n\n1\nuser_id: 1, time: 77.4191689429334\n213.00234\n2\n0\n\n\n2\nuser_id: 2, time: 38.7060365720782\n140.96489\n4\n0\n\n\n3\nuser_id: 3, time: 57.2625682267468\n158.82934\n1\n0\n\n\n4\nuser_id: 4, time: 62.6572520992208\n135.07894\n3\n0\n\n\n5\nuser_id: 5, time: 58.08536646282\n80.16266\n0\n0\n\n\n6\nuser_id: 6, time: 47.8775096781703\n96.10068\n1\n0\n\n\n\n\n\n\nV.A.s como Funções\nX_session_duration, Y_click_count e Z_is_vip são nossas v.a.s. Elas mapeiam o raw_event_log (ou user_id, nosso \\(\\omega\\)) para um número.\n\n\nExplorando Eventos \\(\\{X \\le x\\}\\)\nA “condição de mensurabilidade” \\(\\{X \\le x\\} \\in \\mathcal{F}\\) é o que nos permite usar o comando filter().\n\n# O evento A = {ω : X_session_duration(ω) &lt;= 30}\n# Este é o subconjunto de *usuários* (linhas) que satisfazem a condição.\nevento_A &lt;- Omega_data |&gt;\n  filter(X_session_duration &lt;= 30)\n\ncat(\"Número de usuários (ω) no evento {X &lt;= 30}:\", nrow(evento_A), \"\\n\")\n\nNúmero de usuários (ω) no evento {X &lt;= 30}: 13 \n\n# Podemos calcular a probabilidade deste evento\nP_A &lt;- nrow(evento_A) / nrow(Omega_data)\ncat(\"P(X &lt;= 30) =\", P_A, \"\\n\")\n\nP(X &lt;= 30) = 0.013 \n\n\n\n\nO Espaço Induzido \\(\\mathbb{P}_X\\) (O Histograma)\nNão precisamos mais do Omega_data (os logs brutos). Focamos apenas na distribuição da feature \\(X\\).\n\n# P_X é a \"distribuição de X\"\n# O histograma é a nossa visão empírica de P_X\n\nggplot(Omega_data, aes(x = X_session_duration)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 30, fill = \"lightblue\", alpha = 0.7) +\n  geom_density(color = \"red\", linewidth = 1, alpha= 0.9) +\n  labs(\n    title = \"Distribuição Induzida P_X (O Histograma)\",\n    subtitle = \"Jogamos Ω (os logs) fora e focamos no espaço induzido (os números em ℝ)\",\n    x = \"X_session_duration (Nossa V.A. Contínua)\",\n    y = \"Densidade (Probabilidade Induzida)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n6.2.1 Distribuição Induzida de uma Função Indicadora \\(\\mathbb{P}_Z\\)\nPara a dummy variable \\(Z\\) (Z_is_vip), a distribuição \\(\\mathbb{P}_Z\\) é o que chamamos de Distribuição de Bernoulli. A “distribuição” de \\(Z\\) é apenas \\(P(Z=0)\\) e \\(P(Z=1)\\).\n\nOmega_data |&gt;\n  count(Z_is_vip) |&gt; # Agrupa pelos valores da v.a.\n  mutate(P_Z = n / sum(n)) # Calcula a probabilidade induzida\n\n\n\n\n\n\nZ_is_vip\nn\nP_Z\n\n\n\n\n0\n891\n0.891\n\n\n1\n109\n0.109",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Variáveis Aleatórias</span>"
    ]
  },
  {
    "objectID": "aula07.html",
    "href": "aula07.html",
    "title": "7  Função de Distribuição Acumulada (FDA)",
    "section": "",
    "text": "7.1 Tipos de Variáveis Aleatórias\nNa aula anterior, definimos uma variável aleatória (v.a.) \\(X\\) como uma feature ou métrica (ex: session_duration).\nNa prática, especialmente com features contínuas, a pergunta “Qual a probabilidade da sessão durar exatamente 120.53 segundos?” não é útil (a resposta é zero!).\nAs perguntas de negócio que realmente importam são sobre limites (thresholds):\nA Função de Distribuição Acumulada (FDA), ou Cumulative Distribution Function (CDF), é a ferramenta matemática que responde a todas essas perguntas.\nComentário: Toda função F satisfazendo P1, P2, P3 é a função de distribuição de alguma variável aleatória.\nObservação: Uma função de distribuição pode corresponder a várias v.a.s no mesmo espaço de probabilidade. Por exemplo, se \\(X \\sim N(0, 1) \\rightarrow -X \\sim N(0, 1)\\) e \\(F_X = F_{-X}\\). No entanto \\(\\mathbb{P}(X = -X) = \\mathbb{P}(2X = 0) = \\mathbb{P}(X = 0) = 0\\).\nNotação: O símbolo “\\(\\sim\\)” significa “tem como distribuição” ou “está distribuído como”.\nA FDA nos permite classificar as variáveis aleatórias. Na prática, isso se traduz diretamente nos tipos de dados que analisamos: dados de contagem (discretos), dados de medição (contínuos) e dados censurados (mistos).\nNotas:",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Função de Distribuição Acumulada (FDA)</span>"
    ]
  },
  {
    "objectID": "aula07.html#tipos-de-variáveis-aleatórias",
    "href": "aula07.html#tipos-de-variáveis-aleatórias",
    "title": "7  Função de Distribuição Acumulada (FDA)",
    "section": "",
    "text": "Definição 7.2 (Definição 2.3)  \n\nA v.a. X é dita ser discreta se toma valores em um conjunto finito ou infinito enumerável, isto é, se existe um conjunto \\(\\{x_1, x_2, \\dots\\} \\subset \\mathbb{R}\\) tal que \\[ X(\\omega) \\in \\{x_1, x_2, \\dots\\}, \\forall \\omega \\in \\Omega. \\] A função \\[ p(x_i) = \\mathbb{P}(X = x_i), \\quad i=1, 2, \\dots \\] é chamada função de probabilidade (f.p.) de X.\nA v.a. X é dita ser (absolutamente) contínua se existe uma função \\(f(x) \\ge 0\\) tal que \\[ F_X(x) = \\int_{-\\infty}^{x} f(t) dt, \\quad \\forall x \\in \\mathbb{R} \\] Neste caso, dizemos que \\(f\\) é a função densidade de probabilidade (f.d.p.) de X.\n\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science: FP vs. FDP (Gráfico de Barras vs. Densidade)\n\n\n\n\na) Discreta (FP): Pense em feature como click_count, star_rating (1, 2, 3, 4, 5) ou num_purchases.\n\nA função de probabilidade (f.p.) \\(p(x_i)\\) é o que você vê em um gráfico de barras (geom_col) após normalizar (ex: prop.table(count(df, click_count))).\n\\(p(x_i)\\) é uma probabilidade (ex: \\(p(3) = \\mathbb{P}(X=3) = 0.15\\) ou “15% dos usuários clicaram 3 vezes”).\n\nb) Contínua (FDP): Pense em feature como session_duration, transaction_amount ou score_de_risco.\n\nA função densidade de probabilidade (f.d.p.) \\(f(x)\\) é a curva suave que você vê em um gráfico de densidade (geom_density).\n\\(f(x)\\) não é uma probabilidade! É uma “densidade”. A probabilidade é a área sob a curva. A probabilidade de exatamente \\(X=120.53s\\) é zero. A probabilidade de \\(X \\in [120, 121]\\) é a integral (área) de \\(f(x)\\) entre 120 e 121.\n\n\n\n\n\n\nSe X é discreta, então \\(\\{X\\leq x\\}=\\bigcup_{i: x_i \\le x}\\{X=x_i\\},\\) logo \\[ F_X(x) = \\mathbb{P}(X \\le x) = \\mathbb{P}(\\bigcup_{i: x_i \\le x} \\{X = x_i\\}) = \\sum_{i: x_i \\le x} p(x_i).\\]\nDe forma geral, uma f.p. é qualquer função \\(p(\\cdot)\\) tal que \\(p(x) \\ge 0, \\forall x \\in \\mathbb{R}\\) e \\(\\sum_{x \\in K} p(x) = 1\\) (onde K é o conjunto de valores possíveis de X).\nSe X é absolutamente contínua, então \\(F_X\\) é contínua. Tecnicamente, a integral na Definição 2.3.b) é de Lebesgue e X tem densidade se, e só se, \\(F_X\\) é absolutamente contínua (isto é, \\(F_X\\) é a integral de sua densidade). Neste caso, \\[ f(x) = F_X'(x) \\] em quase todo ponto (exceto num conjunto de medida de Lebesgue nula, isto é, comprimento zero).\nUma função \\(f(\\cdot)\\) é uma f.d.p. se:\n\n\\(f(x) \\ge 0, \\forall x \\in \\mathbb{R}\\)\n\\(\\int_{-\\infty}^{\\infty} f(x) dx = 1\\)\n\nA f.d.p. não é única. Por exemplo, seja \\[ F_X(x) = \\begin{cases} 0, & x &lt; 0 \\\\ x, & 0 \\le x &lt; 1 \\\\ 1, & x \\ge 1 \\end{cases} \\] Podemos obter um candidato para \\(f(\\cdot)\\) fazendo \\(f_X^1(x) = \\frac{d}{dx} F(x) = 1, x \\in (0, 1)\\) e 0 caso contrário. Também poderíamos ter \\(f_X^2(x) = 1\\) para \\(x \\in [0, 1/2] \\cup (1/2, 1]\\) (i.e., mudando um ponto).\n\n\nExemplo 7.2 (Exemplo 2.8 (Variável Aleatória Mista)) Seja X tal que \\(X \\sim U(0, 1)\\), isto é, X tem função de dist. \\[ F_X(x) = \\begin{cases} 0, & x &lt; 0 \\\\ x, & 0 \\le x &lt; 1 \\\\ 1, & x \\ge 1 \\end{cases} \\] Defina \\(Y = \\min(X, 1/2)\\). Obtenha a f.d.a. de Y. \\[ Y(\\omega) = \\begin{cases} X(\\omega), & 0 \\le X(\\omega) &lt; 1/2 \\\\ 1/2, & 1/2 \\le X(\\omega) \\le 1 \\end{cases} \\] \\(F_Y(y) = \\mathbb{P}(Y \\le y), y \\in \\mathbb{R}\\).\n\nPara \\(y &lt; 0\\), temos que \\(F_Y(y) = 0\\).\nPara \\(0 \\le y &lt; 1/2\\), temos \\[ F_Y(y) = \\mathbb{P}(Y \\le y) = \\mathbb{P}(\\{\\omega \\in \\Omega : Y(\\omega) \\le y\\}) \\] \\[ = \\mathbb{P}(\\{\\omega \\in \\Omega : X(\\omega) \\le y\\}) = F_X(y) = y \\]\nPara \\(y \\ge 1/2\\), \\(F_Y(y) = 1\\).\n\nEm resumo, \\[ F_Y(y) = \\begin{cases} 0, & y &lt; 0 \\\\ y, & 0 \\le y &lt; 1/2 \\\\ 1, & y \\ge 1/2 \\end{cases} \\]\n\n\n\n\n\n\n\n\n\nNote que \\(F_Y(y)\\) é contínua em \\((-\\infty, 1/2)\\) e \\([1/2, \\infty)\\) e descontínua em \\(y = 1/2\\).\n\n\nDefinição 7.3 (Definição 2.4) Uma v.a. X é dita ser singular se \\(F_X'(x) = 0, \\forall x \\in \\mathbb{R}\\), exceto para um conj. de medida de Lebesgue nula e \\(F_X\\) é contínua.\n\n\nExemplo 7.3 (Exemplo 2.9 (Função de Cantor)) Ver exemplo 7 - James (2003) p. 41.\n\n\nProposição 7.2 (Proposição 2.2)  \n\nSe X é uma v.a. discreta tomando valores em \\(\\{x_1, x_2, \\dots\\}\\) então \\[ \\mathbb{P}_X(B) = \\sum_{i: x_i \\in B} p(x_i), \\quad \\forall B \\in \\mathcal{B} \\]\nSe X é abs. contínua com densidade \\(f\\) então \\[ \\mathbb{P}_X(B) = \\int_{B} f(x) dx, \\quad \\forall B \\in \\mathcal{B} \\]\n\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science: Como Calcular Probabilidades\n\n\n\nEsta proposição é o “como fazer”:\n\na) Discreta: Para saber \\(\\mathbb{P}(\\text{star\\_rating} &gt; 3)\\), você soma as probabilidades das barras: \\(\\mathbb{P}(\\text{rating}=4) + \\mathbb{P}(\\text{rating}=5)\\).\nb) Contínua: Para saber \\(\\mathbb{P}(\\text{duration} \\in [60, 120])\\), você integra (calcula a área sob a curva) \\(f(x)\\) de 60 a 120. Na prática, \\(\\mathbb{P}(X \\le 120) - \\mathbb{P}(X \\le 60) = F_X(120) - F_X(60)\\).",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Função de Distribuição Acumulada (FDA)</span>"
    ]
  },
  {
    "objectID": "aula07.html#implementação-prática-em-r",
    "href": "aula07.html#implementação-prática-em-r",
    "title": "7  Função de Distribuição Acumulada (FDA)",
    "section": "7.2 Implementação Prática em R",
    "text": "7.2 Implementação Prática em R\nNa prática, não conhecemos a \\(F_X\\) teórica; nós a estimamos a partir dos dados. Isso é chamado de Função de Distribuição Acumulada Empírica (eFDA).\n\nlibrary(tidyverse)\nlibrary(patchwork)\n\n# Usando os dados da aula anterior\nset.seed(42)\nOmega_data &lt;- tibble(\n  user_id = 1:1000,\n  X_session_duration = abs(rnorm(1000, 120, 40)), \n  Y_click_count = rpois(1000, 1.5),\n  Z_is_vip = sample(c(0, 1), 1000, replace = TRUE, prob = c(0.9, 0.1))\n)\n\n# Criando a V.A. Mista (Dados Censurados)\n# Vamos \"censurar\" ou \"capar\" a duração em 180s (timeout)\n# W = min(X, 180)\nOmega_data &lt;- Omega_data |&gt;\n  mutate(\n    W_duration_censored = pmin(X_session_duration, 180)\n  )\n\n\nCalculando um Ponto na eFDA\nA definição \\(F_X(x) = \\mathbb{P}(X \\le x)\\) se traduz em R para: mean(X &lt;= x)\nIsso calcula a proporção de observações no dataset que são menores ou iguais a \\(x\\).\n\n# Qual a P(Duração da Sessão &lt;= 100 segundos)?\nx_threshold &lt;- 100\n\n# Usamos mean() que age como P(A) = count(A) / count(Omega)\nprob_acumulada &lt;- Omega_data  |&gt;\n  summarise(\n    F_X_de_100 = mean(X_session_duration &lt;= x_threshold)\n  )  |&gt;\n  pull(F_X_de_100)\n\ncat(\"Estimativa de F_X(100):\", prob_acumulada, \"\\n\")\n\nEstimativa de F_X(100): 0.307 \n\n\nIsso significa que 31% das sessões duram 100s ou menos.\n\n\nPlotando a eFDA Completa\nO ggplot2 tem uma função dedicada para plotar a eFDA: stat_ecdf(). Ela faz o cálculo acima para todos os valores de \\(x\\) e desenha a curva.\n\n# O valor que acabamos de calcular\nx_val &lt;- 100\ny_val &lt;- prob_acumulada\n\nggplot(Omega_data, aes(x = X_session_duration)) +\n  # Plota a eFDA\n  stat_ecdf(geom = \"step\", color = \"blue\", linewidth = 1) +\n  \n  # Linhas de anotação para o nosso ponto\n  geom_hline(yintercept = y_val, color = \"red\", linetype = \"dashed\") +\n  geom_vline(xintercept = x_val, color = \"red\", linetype = \"dashed\") +\n  \n  # Anotação\n  annotate(\"text\", x = 150, y = y_val - 0.1, \n           label = paste0(\"P(X &lt;= 100) = \", round(y_val, 2)), \n           color = \"red\") +\n  \n  labs(\n    title = \"Função de Distribuição Acumulada Empírica (eFDA)\",\n    subtitle = \"Esta é a 'versão prática' da F_X(x) teórica\",\n    x = \"x (Duração da Sessão)\",\n    y = \"F_X(x) - Probabilidade Acumulada P(X &lt;= x)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nVisualizando os 3 Tipos de V.A.s\nVamos comparar as Funções de Probabilidade/Densidade (FP/FDP) com as Funções de Distribuição (FDA) para nossos 3 tipos de v.a.s.\n\nV.A. Discreta (Y_click_count)\n\n# Função de Probabilidade (FP) - Gráfico de Barras\np1 &lt;- Omega_data |&gt;\n  count(Y_click_count) |&gt;\n  mutate(prob = n / sum(n)) |&gt;\n  ggplot(aes(x = factor(Y_click_count), y = prob)) +\n  geom_col(fill = \"blue\", alpha = 0.8) +\n  labs(title = \"V.A. Discreta: Função de Probabilidade (FP)\",\n       x = \"Y (Contagem de Cliques)\",\n       y = \"p(y) = P(Y=y)\") +\n  theme_minimal()\n\n# Função de Distribuição (FDA) - Gráfico de Degraus\np2 &lt;- ggplot(Omega_data, aes(x = Y_click_count)) +\n  stat_ecdf(geom = \"step\", color = \"blue\", linewidth = 1) +\n  labs(title = \"V.A. Discreta: FDA (eCDF)\",\n       x = \"y (Contagem de Cliques)\",\n       y = expression(F[Y](y))) +\n  theme_minimal()\n\n# Combinar gráficos\np1 + p2\n\n\n\n\nFP e FDA de uma V.A. Discreta (Contagem de Cliques)\n\n\n\n\n\n\nV.A. Contínua (X_session_duration)\n\n# Função Densidade de Probabilidade (FDP) - Gráfico de Densidade\np3 &lt;- ggplot(Omega_data, aes(x = X_session_duration)) +\n  geom_density(fill = \"green\", color = \"darkgreen\", alpha = 0.7) +\n  labs(title = \"V.A. Contínua: Função Densidade (FDP)\",\n       x = \"X (Duração da Sessão)\",\n       y = \"f(x) (Densidade)\") +\n  theme_minimal()\n\n# Função de Distribuição (FDA) - Curva Suave\np4 &lt;- ggplot(Omega_data, aes(x = X_session_duration)) +\n  stat_ecdf(geom = \"line\", color = \"green\", linewidth = 1) +\n  labs(title = \"V.A. Contínua: FDA (eCDF)\",\n       x = \"x (Duração da Sessão)\",\n       y = expression(F[X](x))) +\n  theme_minimal()\n\n# Combinar gráficos\np3 + p4\n\n\n\n\nFDP e FDA de uma V.A. Contínua (Duração da Sessão)\n\n\n\n\n\n\nV.A. Mista (W_duration_censored)\n\n# \"Densidade\" - Histograma (note o pico!)\np5 &lt;- ggplot(Omega_data, aes(x = W_duration_censored)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 30, fill = \"purple\", alpha = 0.8) +\n  labs(title = \"V.A. Mista: Histograma (Note o 'pico' da censura)\",\n       x = \"W (Duração Censurada em 180s)\",\n       y = \"Densidade\") +\n  theme_minimal()\n\np6 &lt;- ggplot(Omega_data, aes(x = W_duration_censored)) +\n  stat_ecdf(geom = \"step\", color = \"purple\", linewidth = 1) +\n  labs(title = \"V.A. Mista: FDA (Note o 'Salto')\",\n       x = \"w (Duração Censurada em 180s)\",\n       y = expression(F[W](w))) +\n  theme_minimal()\n\n# Combinar gráficos\np5 + p6\n\n\n\n\nFDP/FDA de uma V.A. Mista (Duração Censurada)",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Função de Distribuição Acumulada (FDA)</span>"
    ]
  },
  {
    "objectID": "aula08.html",
    "href": "aula08.html",
    "title": "8  Principais Modelos Probabilisticos",
    "section": "",
    "text": "8.1 Principais Modelos Discretos\nNesta aula, apresentamos um catálogo das distribuições de probabilidade mais famosas. Por que precisamos disso?\nPense nessas distribuições como uma “caixa de ferramentas” estatística. Cada distribuição é uma ferramenta diferente, projetada para um tipo específico de problema ou “formato” de dados.\nO trabalho do Cientista de Dados é olhar para um problema (ex: “modelar o churn”) e saber qual ferramenta (distribuição) da caixa é a correta para modelar a realidade. Conhecer este catálogo é o primeiro passo para a modelagem estatística.\nModelos para v.a.s que representam contagens.",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Principais Modelos Probabilisticos</span>"
    ]
  },
  {
    "objectID": "aula08.html#principais-modelos-discretos",
    "href": "aula08.html#principais-modelos-discretos",
    "title": "8  Principais Modelos Probabilisticos",
    "section": "",
    "text": "Definição 8.1 (Modelo 1: Uniforme Discreto) Uma v.a. X segue o modelo uniforme discreto com valores \\(\\{x_1, x_2, \\dots, x_k\\}\\) se \\[ \\mathbb{P}(X = x_i) = \\frac{1}{k}, \\quad i=1, 2, \\dots, k.\\] Notação: \\(X \\sim U_d[x_1, x_2, \\dots, x_k]\\).\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science\n\n\n\nEste é o modelo da “ignorância total” ou a baseline de aleatoriedade.\n\nExemplo: A alocação de um usuário em um Teste A/B/C/D (com \\(k=4\\) grupos). Sob um design balanceado, a probabilidade de um usuário cair em qualquer grupo é \\(1/4\\).\nÉ o “ponto de partida”: se seu modelo de classificação não performa melhor do que a \\(U_d\\), ele é inútil.\n\n\n\n\nDefinição 8.2 (Modelo 2: Bernoulli) Uma v.a. X segue o modelo Bernoulli se \\[ \\mathbb{P}(X = x) = p^x (1-p)^{1-x}, \\quad x=0, 1,\\]  \\(p \\in (0, 1)\\). Notação: \\(X \\sim \\text{Bernoulli}(p)\\).\nExperimentos do tipo sucesso (\\(x=1\\)) e fracasso (\\(x=0\\)), ensaios de Bernoulli.\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science\n\n\n\n\nExemplos:\n\nclicou (1) vs. nao_clicou (0)\ncomprou (1) vs. nao_comprou (0)\nchurn (1) vs. nao_churn (0)\nfraude (1) vs. nao_fraude (0)\n\nA taxa de conversão é o parâmetro \\(p\\).\nTodo problema de classificação binária (Regressão Logística, SVM, etc.) está, em essência, tentando estimar o parâmetro \\(p\\) (a probabilidade de sucesso) para cada observação.\n\n\n\n\nDefinição 8.3 (Modelo 3: Binomial) Uma v.a. X segue o modelo binomial com parâmetros \\(n \\in \\mathbb{N}\\) e \\(p \\in (0, 1)\\) se \\[ \\mathbb{P}(X = x) = \\binom{n}{x} p^x (1-p)^{n-x}, \\quad x=0, 1, \\dots, n.\\] Notação: \\(X \\sim B(n, p)\\).\nComentário: A v.a. \\(X\\) pode ser definida como o número de sucessos (ocorrência de 1) em \\(n\\) ensaios de Bernoulli independentes, cada um com probabilidade de sucesso \\(p\\).\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science\n\n\n\nA Binomial é a soma de \\(n\\) Bernoullis. Ela é a base de toda a análise de Testes A/B.\n\nExemplo: Se \\(n=1000\\) usuários (ensaios) visitam uma página, e a taxa de conversão real é \\(p=0.05\\) (5%), a v.a. \\(X\\) (o número de conversões que observamos) segue uma \\(B(1000, 0.05)\\).\nNós usamos a Binomial para responder: “Se \\(p\\) realmente fosse 5%, qual a chance de observarmos \\(X=60\\) conversões? (ou seja, \\(\\mathbb{P}(X=60)\\))”.\n\n\n\n\nDefinição 8.4 (Modelo 4: Geométrico 1) Uma v.a. X segue o modelo Geométrico (tipo 1) com parâmetro \\(p \\in (0, 1)\\) se \\[\\mathbb{P}(X = x) = p (1-p)^x, \\quad x=0, 1, 2, \\dots\\] Notação: \\(X \\sim \\mathrm{Geo}_1(p)\\).\nComentários:\n\n\\(X =\\) número de fracassos que antecedem o primeiro sucesso em experimentos de Bernoulli independentes.\nTambém poderíamos contar o número de tentativas. Neste caso, \\(X \\sim \\mathrm{Geo}_2(p)\\) e \\[\\mathbb{P}(X = x) = p (1-p)^{x-1}, \\quad x=1, 2, \\dots\\]\n\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science\n\n\n\nA Geométrica modela o “tempo de espera” (discreto) até o primeiro sucesso.\n\nTipo 1 (Geo1): Número de produtos visualizados (fracassos) antes da primeira compra (sucesso).\nTipo 2 (Geo2): Número de visitas totais (tentativas) até a primeira conversão. É fundamental para modelar churn (sobrevivência discreta) e time-to-first-event.\n\n\n\n\nDefinição 8.5 (Modelo 5: Poisson) Uma v.a. X segue o modelo de Poisson de parâmetro \\(\\lambda &gt; 0\\) se \\[\\mathbb{P}(X = x) = \\frac{e^{-\\lambda} \\lambda^x}{x!}, \\quad x=0, 1, 2, \\dots\\] Notação: \\(X \\sim \\text{Pois}(\\lambda)\\).\nComentários:\n\nX pode modelar o número de ocorrências em um determinado intervalo de tempo.\n\\(\\lambda\\) representa a taxa de ocorrências por unidade de medida.\n\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science\n\n\n\nA Poisson modela contagens de eventos “raros” em um intervalo fixo (de tempo, espaço, etc.).\n\nExemplos:\n\nNúmero de pageviews em um site por minuto.\nNúmero de compras de um produto por dia.\nNúmero de falhas em um servidor por hora.\n\nO parâmetro \\(\\lambda\\) (lambda) é a taxa média de ocorrências. Se, em média, o site recebe 50 visitas/minuto, modelamos isso como \\(X \\sim \\text{Pois}(\\lambda=50)\\).",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Principais Modelos Probabilisticos</span>"
    ]
  },
  {
    "objectID": "aula08.html#principais-modelos-contínuos",
    "href": "aula08.html#principais-modelos-contínuos",
    "title": "8  Principais Modelos Probabilisticos",
    "section": "8.2 Principais Modelos Contínuos",
    "text": "8.2 Principais Modelos Contínuos\nModelos para v.a.s que representam medições.\n\nDefinição 8.6 (Modelo 1: Uniforme Contínuo) X segue o modelo uniforme contínuo em \\([a, b] \\subset \\mathbb{R}\\) se todos os subintervalos de \\([a, b]\\) com mesmo comprimento tiverem a mesma probabilidade. A f.d.p. de X é: \\[f_X(x) = \\frac{1}{b-a} I_{[a, b]}(x)\\] Notação: \\(X \\sim U(a, b)\\).\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science\n\n\n\nA \\(U(a, b)\\) é a baseline contínua. É a nossa suposição de “não-sei-nada” sobre uma feature, exceto que ela vive entre \\(a\\) e \\(b\\).\n\nExemplo: Em simulações, usamos \\(U(0, 1)\\) para gerar aleatoriedade.\nTeste de Hipótese: Sob a hipótese nula (\\(H_0\\)), os p-values devem seguir uma distribuição \\(U(0, 1)\\). Se o histograma dos seus p-values não é plano, algo está errado (ou certo!) no seu experimento.\nBayesiana: É frequentemente usada como um prior não-informativo.\n\n\n\n\nDefinição 8.7 (Modelo 2: Exponencial) Uma v.a. X segue o modelo exponencial de parâmetro \\(\\lambda &gt; 0\\) se: \\[f_X(x) = \\lambda e^{-\\lambda x} I_{(0, \\infty)}(x)\\] Notação: \\(X \\sim \\text{exp}(\\lambda)\\).\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science\n\n\n\nEsta é a versão contínua da Geométrica. Ela modela o tempo de espera entre eventos de Poisson.\n\nExemplos:\n\ntempo_entre_visitas ao site.\ntempo_entre_falhas de um servidor.\nduracao_da_sessao (assumindo que o usuário pode sair a qualquer momento com a mesma prob., a “falta de memória”).\n\n\\(\\lambda\\) é a taxa (ex: falhas/dia). \\(1/\\lambda\\) é o tempo médio (ex: dias/falha).\n\n\n\n\nDefinição 8.8 (Modelo 3: Normal) Uma v.a. X segue o modelo normal com parâmetros \\(\\mu \\in \\mathbb{R}\\) e \\(\\sigma^2 &gt; 0\\) se: \\[f_X(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left\\{-\\frac{1}{2\\sigma^2}(x-\\mu)^2\\right\\}, \\quad x \\in \\mathbb{R}\\] Notação: \\(X \\sim N(\\mu, \\sigma^2)\\).\nComentários: 1) \\(f(x)\\) é simétrica em torno de \\(\\mu\\). 2) Notação para f.d.a. de \\(Z \\sim N(0, 1): F_Z(z) = \\Phi(z)\\).\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science\n\n\n\nA distribuição mais famosa, graças ao Teorema Central do Limite (TCL).\n\nO TCL diz que a média de (quase) qualquer coisa, se \\(n\\) for grande, se aproxima de uma Normal.\nExemplos:\n\nA distribuição das medias_de_sessoes_por_dia.\nOs resíduos (erros) de um modelo de Regressão Linear são supostos \\(N(0, \\sigma^2)\\).\nMedidas biológicas (ex: altura), erros de medição, etc.\n\nÉ a base para o Teste-t, Teste-Z, e grande parte da estatística inferencial clássica.\n\n\n\n\nDefinição 8.9 (Modelo 4: Gama) \\(X \\sim \\text{Gama}(\\alpha, \\beta)\\), com \\(\\alpha, \\beta &gt; 0\\). \\[f_X(x) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha-1} e^{-\\beta x} I_{(0, \\infty)}(x)\\] Onde \\(\\Gamma(\\alpha)\\) é a função Gama.\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science\n\n\n\nUma versão mais flexível da Exponencial.\n\nA \\(\\text{Gama}(\\alpha=1, \\beta=\\lambda)\\) é exatamente a \\(\\text{exp}(\\lambda)\\).\nSe a Exponencial modela o tempo até o primeiro evento, a Gama modela o tempo até o \\(\\alpha\\)-ésimo evento.\nExemplo: tempo_total_de_espera até o 10º cliente chegar.\nÉ muito usada em Análise de Sobrevivência e para modelar features contínuas que são estritamente positivas e assimétricas (ex: valor_monetario, tempo_de_atendimento).\n\n\n\n\nDefinição 8.10 (Modelo 5: Beta) \\(X \\sim \\text{Beta}(\\alpha, \\beta)\\), com \\(\\alpha, \\beta &gt; 0\\). \\[f_X(x) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} x^{\\alpha-1} (1-x)^{\\beta-1} I_{(0, 1)}(x)\\]\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science\n\n\n\nA distribuição Beta só vive no intervalo [0, 1].\n\nExemplos: Ela modela coisas que são probabilidades, taxas ou proporções.\n\nO score_de_propensao de um cliente.\nA taxa_de_clique (CTR) individual de um anúncio.\nA porcentagem de conclusão de um vídeo.\n\nBayesiana: É a “parceira” da Binomial (o chamado conjugado prior). Se você modela cliques com uma Binomial, você pode modelar sua crença sobre a taxa \\(p\\) com uma Beta. É a base da maioria dos Testes A/B Bayesianos.",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Principais Modelos Probabilisticos</span>"
    ]
  },
  {
    "objectID": "aula08.html#implementação-prática-em-r",
    "href": "aula08.html#implementação-prática-em-r",
    "title": "8  Principais Modelos Probabilisticos",
    "section": "8.3 Implementação Prática em R",
    "text": "8.3 Implementação Prática em R\n\nEm R, para cada distribuição (ex: norm), existe uma “família” de 4 funções identificadas por um prefixo. Conhecer esse padrão é essencial.\n\nd*: densidade (f.d.p.) ou f.p. \\(f(x)\\) ou \\(p(x_i)\\). Responde “Qual a altura da curva/barra no ponto x?”\np*: probabilidade (f.d.a.). \\(F(x) = \\mathbb{P}(X \\le x)\\). Responde “Qual a prob. acumulada até x?”\nq*: quantil. A inversa da f.d.a. Responde “Qual é o valor \\(x\\) que acumula \\(p\\) de prob.?” (ex: percentil 95).\nr*: random. Gera números aleatórios (simulações) dessa distribuição.\n\nVamos ver na prática.\n\nlibrary(tidyverse)\nlibrary(patchwork) # Para combinar gráficos\n\n\nExemplo 1: Binomial (Discreta) - Análise de Teste A/B\nSuponha um Teste A/B. O grupo de controle tem \\(p = 0.05\\) (5% de conversão). Coletamos \\(n = 1000\\) usuários. \\(X \\sim B(n=1000, p=0.05)\\).\n\n# 1. dbinom: Qual a P(exatamente 60 conversões)?\n# P(X = 60)\nprob_exata &lt;- dbinom(x = 60, size = 1000, prob = 0.05)\ncat(\"P(X = 60):\", prob_exata, \"\\n\")\n\nP(X = 60): 0.01966966 \n\n# 2. pbinom: Qual a P(60 conversões OU MENOS)? (O p-value de um teste)\n# P(X &lt;= 60)\nprob_acumulada &lt;- pbinom(q = 60, size = 1000, prob = 0.05)\ncat(\"P(X &lt;= 60):\", prob_acumulada, \"\\n\")\n\nP(X &lt;= 60): 0.9329375 \n\n# 3. qbinom: Qual é o 95º percentil? (O limite de \"surpresa\")\n# q tal que P(X &lt;= q) = 0.95\npercentil_95 &lt;- qbinom(p = 0.95, size = 1000, prob = 0.05)\ncat(\"Percentil 95:\", percentil_95, \"conversões\\n\")\n\nPercentil 95: 62 conversões\n\n# 4. rbinom: Simular 5 resultados desse experimento\nsimulacao &lt;- rbinom(n = 5, size = 1000, prob = 0.05)\ncat(\"5 simulações (nº de conversões):\", simulacao, \"\\n\")\n\n5 simulações (nº de conversões): 48 50 47 53 50 \n\n\n\n\nExemplo 2: Poisson (Discreta) - Tráfego do Site\nNosso site recebe, em média, \\(\\lambda = 10\\) visitas por minuto. \\(X \\sim \\text{Pois}(\\lambda=10)\\).\n\n# 1. dpois: Qual a P(exatamente 10 visitas em um minuto)?\n# P(X = 10)\nprob_exata_pois &lt;- dpois(x = 10, lambda = 10)\ncat(\"P(X = 10):\", prob_exata_pois, \"\\n\")\n\nP(X = 10): 0.12511 \n\n# 2. ppois: Qual a P(MAIS de 15 visitas)? (Risco de sobrecarga)\n# P(X &gt; 15) = 1 - P(X &lt;= 15)\nprob_sobrecarga &lt;- ppois(q = 15, lambda = 10, lower.tail = FALSE)\ncat(\"P(X &gt; 15):\", prob_sobrecarga, \"\\n\")\n\nP(X &gt; 15): 0.0487404 \n\n\n\n\nExemplo 3: Normal (Contínua) - Tempo de Sessão\nO tempo médio de sessão é \\(\\mu = 120\\) segundos, com desvio padrão \\(\\sigma = 30\\) segundos. \\(X \\sim N(\\mu=120, \\sigma^2=30^2)\\).\n\n# 1. pnorm: Qual a P(sessão durar MENOS de 60 segundos)?\n# P(X &lt;= 60)\nprob_curta &lt;- pnorm(q = 60, mean = 120, sd = 30)\ncat(\"P(X &lt;= 60s):\", prob_curta, \"\\n\")\n\nP(X &lt;= 60s): 0.02275013 \n\n# 2. qnorm: Qual é o tempo de sessão que 99% dos usuários NÃO ultrapassam?\n# q tal que P(X &lt;= q) = 0.99\npercentil_99_tempo &lt;- qnorm(p = 0.99, mean = 120, sd = 30)\ncat(\"Percentil 99:\", percentil_99_tempo, \"segundos\\n\")\n\nPercentil 99: 189.7904 segundos\n\n# 3. dnorm: Apenas retorna a \"altura\" da curva de sino.\n# Não é uma probabilidade!\naltura_curva_no_pico &lt;- dnorm(x = 120, mean = 120, sd = 30)\ncat(\"Altura da FDP em x=120:\", altura_curva_no_pico, \"\\n\")\n\nAltura da FDP em x=120: 0.01329808 \n\n\n\n\nVisualizando FP/FDP vs. FDA\n\n# 1. Dados para Binomial B(50, 0.3)\ndf_binom &lt;- tibble(\n  x = 0:50,\n  fp = dbinom(x, size = 50, prob = 0.3),\n  fda = pbinom(x, size = 50, prob = 0.3)\n)\n\n# 2. Dados para Normal N(15, 5^2)\ndf_norm &lt;- tibble(\n  x = seq(0, 30, length.out = 200),\n  fdp = dnorm(x, mean = 15, sd = 5),\n  fda = pnorm(x, mean = 15, sd = 5)\n)\n\n# Gráfico 1: Binomial FP (Discreta)\ng1 &lt;- ggplot(df_binom, aes(x = x, y = fp)) +\n  geom_col(fill = \"blue\", alpha = 0.8) +\n  labs(title = \"FP da Binomial (Discreta)\", y = \"p(x)\") +\n  theme_minimal()\n\n# Gráfico 2: Binomial FDA (Discreta)\ng2 &lt;- ggplot(df_binom, aes(x = x, y = fda)) +\n  geom_step(color = \"blue\", linewidth = 1) +\n  labs(title = \"FDA da Binomial (Discreta)\", y = \"F(x)\") +\n  theme_minimal()\n\n# Gráfico 3: Normal FDP (Contínua)\ng3 &lt;- ggplot(df_norm, aes(x = x, y = fdp)) +\n  geom_area(fill = \"green\", alpha = 0.7) +\n  labs(title = \"FDP da Normal (Contínua)\", y = \"f(x)\") +\n  theme_minimal()\n\n# Gráfico 4: Normal FDA (Contínua)\ng4 &lt;- ggplot(df_norm, aes(x = x, y = fda)) +\n  geom_line(color = \"green\", linewidth = 1) +\n  labs(title = \"FDA da Normal (Contínua)\", y = \"F(x)\") +\n  theme_minimal()\n\n# Combinar os 4 gráficos\n(g1 + g2) / (g3 + g4)\n\n\n\n\nComparação entre FP/FDP (esquerda) e FDA (direita) para Binomial e Normal",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Principais Modelos Probabilisticos</span>"
    ]
  },
  {
    "objectID": "aula09.html",
    "href": "aula09.html",
    "title": "9  Vetores Aleatórios",
    "section": "",
    "text": "9.1 Implementação Prática em R\nContexto: Realiza-se um experimento aleatório e estamos interessados em mais de uma característica numérica do experimento.\nPor exemplo, escolher ao acaso um ponto no círculo unitário. Poderíamos ter X e Y representando as coordenadas do ponto escolhido: \\[ \\underline\\omega = (x, y) = (X(\\omega), Y(\\omega)), \\quad \\underline\\omega \\in \\Omega = \\{(x, y) : \\sqrt{x^2+y^2} \\le 1\\} \\]\nNotas:\nComentários:\nVamos demonstrar esses conceitos visualmente. O data.frame é o nosso vetor aleatório.\nlibrary(tidyverse)\nlibrary(MASS)     # Para simular dados multivariados (vetores aleatórios)\nlibrary(ggExtra)  # Para plotar densidades marginais",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Vetores Aleatórios</span>"
    ]
  },
  {
    "objectID": "aula09.html#implementação-prática-em-r",
    "href": "aula09.html#implementação-prática-em-r",
    "title": "9  Vetores Aleatórios",
    "section": "",
    "text": "O Vetor Aleatório (A Linha do Data Frame)\nVamos simular um dataset (nosso \\(\\Omega\\)) de 5000 usuários. Cada usuário \\(\\omega\\) terá um vetor aleatório \\(\\underline{X} = (X_1, X_2)\\) onde:\n\n\\(X_1\\) = idade (Normal, média 40)\n\\(X_2\\) = renda_k (Normal, média 60, em milhares de reais)\n\nVamos induzir uma correlação positiva: pessoas mais velhas tendem a ter renda maior.\n\nset.seed(42)\nN_usuarios &lt;- 5000\n\n# Parâmetros\nmu &lt;- c(idade = 40, renda_k = 60) # Médias\n# Matriz de Covariância (var=100 e 225, cov=90 -&gt; corr=0.6)\nsigma &lt;- matrix(c(100, 90, \n                  90, 225), ncol = 2) \n\n# mvrnorm = \"multivariate random normal\"\n# Nossas 5000 \"linhas\" (vetores aleatórios)\nvetores_aleatorios &lt;- MASS::mvrnorm(n = N_usuarios, mu = mu, Sigma = sigma)\n\n# Converter para um data.frame (tibble)\nOmega_data &lt;- as_tibble(vetores_aleatorios)\n\n\nhead(Omega_data)\n\n\n\n\n\n\nidade\nrenda_k\n\n\n\n\n50.02146\n80.27825\n\n\n29.42800\n55.01789\n\n\n40.77736\n66.35290\n\n\n45.73767\n68.77947\n\n\n45.19411\n64.80859\n\n\n39.95462\n58.04827\n\n\n\n\n\n\n\nFDA Conjunta: \\(\\mathbb{P}(X_1 \\le x_1, X_2 \\le x_2)\\)\nComo calculamos \\(F(30, 40) = \\mathbb{P}(\\text{idade} \\le 30 \\text{ E } \\text{renda\\_k} \\le 40)\\)? Simplesmente “filtramos” o dataset e contamos a proporção.\n\nprob_conjunta &lt;- Omega_data |&gt;\n  filter(idade &lt;= 30, renda_k &lt;= 40) |&gt;\n  summarise(prob = n() / N_usuarios) |&gt;\n  pull(prob)\n\ncat(\"Probabilidade Conjunta P(idade &lt;= 30, renda_k &lt;= 40):\", scales::percent(prob_conjunta), \"\\n\")\n\nProbabilidade Conjunta P(idade &lt;= 30, renda_k &lt;= 40): 5% \n\n\n\n\nDensidade Conjunta: \\(f(x_1, x_2)\\)\nEsta é a “paisagem 3D” das nossas features. Usamos geom_density_2d para visualizá-la como um mapa de contorno. Os picos são onde os dados são mais densos (ao redor de 40 anos e 60k de renda).\n\nggplot(Omega_data, aes(x = idade, y = renda_k)) +\n  geom_density_2d_filled(alpha = 0.8) +\n  labs(\n    title = \"Visualizando a Densidade Conjunta f(x, y)\",\n    subtitle = \"Os 'picos' mostram onde os vetores (idade, renda) são mais prováveis\",\n    x = \"X1 (Idade)\",\n    y = \"X2 (Renda em k BRL)\"\n  ) +\n  theme_minimal()\n\n\n\n\nDensidade Conjunta f(x,y) visualizada com contornos.\n\n\n\n\n\n\nDensidade Marginal: \\(f_X(x)\\)\nO que acontece se “integrarmos \\(y\\) para fora”? (ou seja, se ignorarmos a renda_k)? Obtemos a densidade marginal da idade, que é apenas o seu histograma!\nO pacote ggExtra nos permite ver a conjunta e as marginais no mesmo gráfico.\n\n# 1. Plotar a conjunta (scatter plot)\np &lt;- ggplot(Omega_data, aes(x = idade, y = renda_k)) +\n  geom_point(alpha = 0.1) +\n  theme_minimal()\n\n# 2. Adicionar as marginais\n# type = \"histogram\" ou \"density\"\nggExtra::ggMarginal(\n  p, \n  type = \"density\", \n  fill = \"lightblue\",\n  alpha = 0.7\n)\n\n\n\n\nDensidade Conjunta (centro) e Densidades Marginais (eixos)\n\n\n\n\nEste gráfico final é a melhor visualização:\n\nGráfico Central: A distribuição conjunta (aqui como scatter plot).\nGráfico no Topo: A densidade marginal \\(f_X(\\text{idade})\\), calculada “integrando” (colapsando) todos os pontos de Y.\nGráfico à Direita: A densidade marginal \\(f_Y(\\text{renda\\_k})\\), calculada “integrando” (colapsando) todos os pontos de X.",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Vetores Aleatórios</span>"
    ]
  },
  {
    "objectID": "aula10.html",
    "href": "aula10.html",
    "title": "10  Independência",
    "section": "",
    "text": "10.1 Implementação Prática em R\nAté agora, vimos vetores aleatórios \\(\\underline{X} = (X_1, \\dots, X_n)\\) e como suas features se relacionam através da densidade conjunta. Agora, vamos focar no caso especial (e muito importante) em que elas não se relacionam.\nA independência é a suposição que nos permite “quebrar” um problema complexo de \\(n\\) dimensões (a densidade conjunta) em \\(n\\) problemas simples de 1 dimensão (as densidades marginais).\nNotas:\nNota: Como as densidades conjuntas não são únicas, para concluir que \\(X_1, \\dots, X_n\\) não são independentes, devemos verificar que existe uma região de medida positiva tal que \\(f_{\\underline{X}}(\\underline{x}) \\ne f_{X_1}(x_1) \\dots f_{X_n}(x_n)\\).\nComo verificamos a independência na prática?",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Independência</span>"
    ]
  },
  {
    "objectID": "aula10.html#implementação-prática-em-r",
    "href": "aula10.html#implementação-prática-em-r",
    "title": "10  Independência",
    "section": "",
    "text": "Caso Discreto: Teste Qui-Quadrado (\\(\\chi^2\\))\nVamos testar se segmento e converteu são independentes. \\(H_0\\): As variáveis são independentes (\\(\\mathbb{P}(X=x, Y=y) = \\mathbb{P}(X=x)\\mathbb{P}(Y=y)\\)). \\(H_1\\): As variáveis são dependentes.\n\n# Criamos um dataset ONDE AS VARIÁVEIS SÃO DEPENDENTES\n# Segmento A converte a 10%, Segmento B converte a 20%\nset.seed(42)\ndados_dependentes &lt;- tibble(\n  segmento = rep(c(\"A\", \"B\"), each = 500),\n  converteu = c(rbinom(500, 1, 0.10), rbinom(500, 1, 0.20))\n)\n\n# Criar a Tabela de Contingência (Prob. Conjunta Observada)\ntabela_contingencia &lt;- table(dados_dependentes$segmento, dados_dependentes$converteu)\n\nTabela de Contingência Observada:\n\nprint(tabela_contingencia)\n\n   \n      0   1\n  A 443  57\n  B 405  95\n\n\n\n# Rodar o Teste Qui-Quadrado\n# Ele calcula as prob. marginais, o \"Esperado\" (sob H0) \n# e compara com o \"Observado\"\nteste_qui2 &lt;- chisq.test(tabela_contingencia)\nprint(teste_qui2)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  tabela_contingencia\nX-squared = 10.621, df = 1, p-value = 0.001118\n\n\nInterpretação: O p-value é muito pequeno. Isso significa que a diferença entre o que observamos e o que esperaríamos (se fossem independentes) é muito grande. Conclusão: Rejeitamos \\(H_0\\). As variáveis segmento e converteu são dependentes.\n\n\nCaso Contínuo: Correlação e Visualização\nVamos revisitar nosso dataset de idade e renda_k.\n\n# Dados Dependentes (Correlação = 0.6)\nset.seed(42)\nmu &lt;- c(idade = 40, renda_k = 60)\nsigma_dep &lt;- matrix(c(100, 90, 90, 225), ncol = 2) # Cov = 90\ndados_dep &lt;- as_tibble(MASS::mvrnorm(n = 2000, mu = mu, Sigma = sigma_dep))\n\n# Calcular correlação\ncor_dep &lt;- cor(dados_dep$idade, dados_dep$renda_k)\ncat(\"Correlação (Dependente):\", cor_dep, \"\\n\")\n\nCorrelação (Dependente): 0.5857922 \n\n# Plotar (o scatter plot é uma elipse \"inclinada\")\np_dep &lt;- ggplot(dados_dep, aes(x = idade, y = renda_k)) +\n  geom_point(alpha = 0.2) + theme_minimal() +\n  labs(title = \"Caso 1: Variáveis Dependentes (Correlacionadas)\",\n       subtitle = paste(\"Correlação =\", round(cor_dep, 2)))\n\nggExtra::ggMarginal(p_dep, type = \"density\", fill = \"lightblue\")\n\n\n\n\nVisualização de variáveis dependentes (correlacionadas).\n\n\n\n\n\n# Dados Independentes (Correlação = 0)\nsigma_indep &lt;- matrix(c(100, 0, 0, 225), ncol = 2) # Cov = 0\ndados_indep &lt;- as_tibble(MASS::mvrnorm(n = 2000, mu = mu, Sigma = sigma_indep))\n\n# Calcular correlação\ncor_indep &lt;- cor(dados_indep$idade, dados_indep$renda_k)\ncat(\"Correlação (Independente):\", cor_indep, \"\\n\")\n\nCorrelação (Independente): -0.0009056449 \n\n# Plotar (o scatter plot é uma elipse \"alinhada\" ou círculo)\np_indep &lt;- ggplot(dados_indep, aes(x = idade, y = renda_k)) +\n  geom_point(alpha = 0.2) + theme_minimal() +\n  labs(title = \"Caso 2: Variáveis Independentes (Não-Correlacionadas)\",\n       subtitle = paste(\"Correlação =\", round(cor_indep, 4)))\n       \nggExtra::ggMarginal(p_indep, type = \"density\", fill = \"lightgreen\")\n\n\n\n\nVisualização de variáveis independentes (não-correlacionadas).\n\n\n\n\n\n\nArmadilha: Correlação Zero \\(\\neq\\) Independência\nCuidado: Correlação mede apenas dependência linear. Variáveis podem ter correlação zero e ainda assim serem altamente dependentes.\n\nset.seed(42)\nn_pontos &lt;- 2000\nX &lt;- runif(n_pontos, -2, 2)\n# Y é uma função quadrática de X (dependência perfeita!)\nY &lt;- X^2 + rnorm(n_pontos, 0, 0.2) # Adiciona ruído\n\ndf_parabola &lt;- tibble(X, Y)\n\n# 1. Calcular a correlação\ncor_parabola &lt;- cor(df_parabola$X, df_parabola$Y)\n\n# 2. Plotar\nggplot(df_parabola, aes(x = X, y = Y)) +\n  geom_point(alpha = 0.3) +\n  labs(\n    title = \"Dependência Não-Linear (Correlação $\\\\approx 0$)\",\n    subtitle = paste(\"Correlação Linear:\", round(cor_parabola, 4)),\n    caption = \"Y é perfeitamente dependente de X, mas a correlação linear é nula.\"\n  ) +\n  theme_minimal()\n\n\n\n\nDependência não-linear com correlação zero.",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Independência</span>"
    ]
  },
  {
    "objectID": "aula11.html",
    "href": "aula11.html",
    "title": "11  Distribuição de Transformações de Vetores Aleatórios",
    "section": "",
    "text": "11.1 Implementação Prática em R\nSeja \\(\\underline{X} = (X_1, \\dots, X_n)\\) um vetor aleatório com \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\). Objetivo: determinar a distribuição de \\(Y = g(\\underline{X}) = g(X_1, \\dots, X_n)\\), com \\(g: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\).\nPara que Y seja uma v.a., vamos supor que \\(g\\) seja uma função mensurável a Borel, isto é: \\[ g^{-1}(B) = \\{\\underline{x} \\in \\mathbb{R}^n : g(\\underline{x}) \\in B\\} \\in \\mathcal{B}^n, \\quad \\forall B \\in \\mathcal{B} \\]\nA função de distribuição de Y é: \\[ F_Y(y) = \\mathbb{P}(Y \\le y) = \\mathbb{P}(g(X_1, \\dots, X_n) \\le y) \\] de modo que \\(g(\\underline{x}) \\le y \\Leftrightarrow \\underline{x} \\in B_y = \\{\\underline{x} \\in \\mathbb{R}^n : g(\\underline{x}) \\le y\\}\\).\nLogo, \\[ F_Y(y) = \\mathbb{P}(\\underline{X} \\in B_y) \\]\nSe \\(\\underline{X}\\) for discreto, então Y também será e \\[ \\mathbb{P}(Y = y_j) = \\mathbb{P}(g(\\underline{X}) = y_j) = \\sum_{i: g(\\underline{x}_i) = y_j} \\mathbb{P}(\\underline{X} = \\underline{x}_i) \\] em que \\(y_j\\) é um valor possível de Y.\nVamos verificar empiricamente os resultados dos exemplos usando simulação.",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Distribuição de Transformações de Vetores Aleatórios</span>"
    ]
  },
  {
    "objectID": "aula11.html#implementação-prática-em-r",
    "href": "aula11.html#implementação-prática-em-r",
    "title": "11  Distribuição de Transformações de Vetores Aleatórios",
    "section": "",
    "text": "Verificando Exemplo 2.14 (\\(Y=X^2\\))\nVamos simular \\(X\\) e calcular \\(Y=X^2\\). A distribuição de \\(Y\\) deve ser uniforme nos quadrados.\n\nlibrary(tidyverse)\n\nn_sim &lt;- 100000\nn_param &lt;- 5 # Parâmetro n do exemplo\n\n# Simular X\nvalores_x &lt;- c(-n_param:-1, 1:n_param)\nX &lt;- sample(valores_x, size = n_sim, replace = TRUE, prob = rep(1/(2*n_param), 2*n_param))\n\n# Transformar Y = X^2\nY &lt;- X^2\n\n# Calcular a distribuição empírica de Y\ndist_y_empirica &lt;- table(Y) / n_sim\n\nprint(dist_y_empirica)\n\nY\n      1       4       9      16      25 \n0.19888 0.19972 0.19819 0.20038 0.20283 \n\n# Valores teóricos esperados: 1/n = 1/5 = 0.2 para y = 1, 4, 9, 16, 25\nvalores_y_teoricos &lt;- (1:n_param)^2\nprob_y_teorica &lt;- rep(1/n_param, n_param)\nnames(prob_y_teorica) &lt;- valores_y_teoricos\n\nprint(prob_y_teorica)\n\n  1   4   9  16  25 \n0.2 0.2 0.2 0.2 0.2 \n\n\n\n\nVerificando Exemplo 2.15 \\((Y = -\\log X \\implies \\text{exp}(1))\\)\nSimulamos \\(X \\sim U(0, 1)\\), calculamos \\(Y = -\\log X\\), e plotamos o histograma de \\(Y\\). Ele deve se parecer com a densidade da \\(\\text{exp}(1)\\).\n\nn_sim &lt;- 100000\n\n# Simular X ~ U(0, 1)\nX &lt;- runif(n_sim, 0, 1)\n\n# Transformar Y = -log(X)\nY &lt;- -log(X)\n\n# Plotar o histograma de Y (normalizado) e a curva teórica exp(1)\nggplot(tibble(Y = Y), aes(x = Y)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"lightblue\", alpha = 0.8) +\n  # Adiciona a curva teórica da exp(1)\n  stat_function(fun = dexp, args = list(rate = 1), color = \"red\", linewidth = 1) +\n  labs(\n    title = \"Verificação: Y = -log(X) ~ Exp(1)\",\n    subtitle = \"Histograma (Empírico) vs. Curva Vermelha (Teórica)\",\n    x = \"Y = -log(X)\",\n    y = \"Densidade\"\n  ) +\n  theme_minimal() +\n  xlim(0, quantile(Y, 0.99)) # Limita eixo x para melhor visualização\n\n\n\n\nHistograma de Y = -log(X) comparado com a densidade teórica da exp(1).\n\n\n\n\n\n\nVerificando Exemplo 2.16 \\((Z = X/Y)\\)\nSimulamos \\(X, Y \\sim U(0, 1)\\), calculamos \\(Z = X/Y\\), e comparamos o histograma de \\(Z\\) com a \\(f_Z(z)\\) que derivamos.\n\nn_sim &lt;- 100000\n\n# Simular X e Y independentes\nX &lt;- runif(n_sim, 0, 1)\nY &lt;- runif(n_sim, 0, 1)\n\n# Transformar Z = X / Y\nZ &lt;- X / Y\n\n# Definir a função de densidade teórica f_Z(z)\nf_Z_teorica &lt;- function(z) {\n  ifelse(z &lt;= 0, 0,\n    ifelse(z &lt; 1, 1/2, 1 / (2 * z^2))\n  )\n}\n\n# Plotar o histograma de Z e a curva teórica f_Z(z)\nggplot(tibble(Z = Z), aes(x = Z)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 100, fill = \"lightgreen\", alpha = 0.8) +\n  stat_function(fun = f_Z_teorica, color = \"red\", linewidth = 1) +\n  labs(\n    title = \"Verificação: Distribuição da Razão Z = X / Y\",\n    subtitle = \"Histograma (Empírico) vs. Curva Vermelha (Teórica)\",\n    x = \"Z = X / Y\",\n    y = \"Densidade\"\n  ) +\n  theme_minimal() +\n  xlim(0, quantile(Z, 0.95))\n\n\n\n\nHistograma de Z = X/Y comparado com a densidade teórica derivada.",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Distribuição de Transformações de Vetores Aleatórios</span>"
    ]
  },
  {
    "objectID": "aula12.html",
    "href": "aula12.html",
    "title": "12  Método do Jacobiano e Estatísticas de Ordem",
    "section": "",
    "text": "12.1 Método do Jacobiano\nNa aula anterior, vimos como encontrar a distribuição de \\(Y = g(X)\\) para uma única v.a. Agora, estendemos para o caso multivariado: encontrar a distribuição de um vetor \\(\\underline{Y} = g(\\underline{X})\\), onde \\(g: \\mathbb{R}^n \\rightarrow \\mathbb{R}^n\\) é uma transformação.\nSeja \\(\\underline{X}\\) um vetor aleatório com f.d.p. conjunta \\(f_{\\underline{X}}\\) e que assume valores em um domínio \\(G_0 \\subseteq \\mathbb{R}^n\\). Suponha que queiramos obter a distribuição de \\(\\underline{Y} = g(\\underline{X})\\).\nVamos assumir que \\(g: G_0 \\rightarrow G\\), \\(G \\subseteq \\mathbb{R}^n\\), é bijetiva e diferenciável com inversa \\(g^{-1} = h: G \\rightarrow G_0\\), também diferenciável.\nNote que \\(\\underline{X} = h(\\underline{Y})\\) e defina os Jacobianos (determinantes das matrizes de derivadas parciais): \\[ J_h(\\underline{y}) = \\det\\left( \\frac{\\partial \\underline{x}}{\\partial \\underline{y}} \\right) = \\det\\left[ \\begin{array}{ccc} \\frac{\\partial x_1}{\\partial y_1} & \\dots & \\frac{\\partial x_1}{\\partial y_n} \\\\ \\vdots & \\ddots & \\vdots \\\\ \\frac{\\partial x_n}{\\partial y_1} & \\dots & \\frac{\\partial x_n}{\\partial y_n} \\end{array} \\right] \\] \\[ J_g(\\underline{x}) = \\det\\left( \\frac{\\partial \\underline{y}}{\\partial \\underline{x}} \\right) = \\det\\left[ \\begin{array}{ccc} \\frac{\\partial y_1}{\\partial x_1} & \\dots & \\frac{\\partial y_1}{\\partial x_n} \\\\ \\vdots & \\ddots & \\vdots \\\\ \\frac{\\partial y_n}{\\partial x_1} & \\dots & \\frac{\\partial y_n}{\\partial x_n} \\end{array} \\right]\\]\nNote que \\(J_h(\\underline{y}) = [J_g(\\underline{x})]^{-1}\\). Sob essas condições, a densidade de \\(\\underline{Y}\\) é: \\[ f_{\\underline{Y}}(\\underline{y}) = f_{\\underline{X}}(h(\\underline{y})) |J_h(\\underline{y})| = f_{\\underline{X}}(h(\\underline{y})) \\left| \\frac{1}{J_g(h(\\underline{y}))} \\right|, \\quad \\underline{y} \\in G \\]",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Método do Jacobiano e Estatísticas de Ordem</span>"
    ]
  },
  {
    "objectID": "aula12.html#método-do-jacobiano",
    "href": "aula12.html#método-do-jacobiano",
    "title": "12  Método do Jacobiano e Estatísticas de Ordem",
    "section": "",
    "text": "DicaPerspectiva de Data Science: O Fator de Correção de Volume\n\n\n\nTODO: ver versão original e verificar se esta está correta.\nO Método do Jacobiano é a generalização da “mudança de variável” na integração para múltiplas dimensões.\n\nIntuição: Quando transformamos o espaço (ex: de coordenadas cartesianas \\((X_1, X_2)\\) para polares \\((Y_1=\\text{raio}, Y_2=\\text{ângulo})\\)), a “densidade” da probabilidade muda. Uma região pequena no espaço original pode ser “esticada” ou “encolhida” no novo espaço.\n\\(|J_h(\\underline{y})|\\): O valor absoluto do Jacobiano é o fator de escala local dessa transformação. Ele nos diz quanto um “pequeno volume” (área em 2D, volume em 3D, etc.) ao redor de \\(\\underline{y}\\) foi expandido ou contraído em relação ao volume correspondente ao redor de \\(\\underline{x} = h(\\underline{y})\\).\nAplicação: Usamos essa técnica (muitas vezes implicitamente) em:\n\nSimulação: Para gerar amostras de distribuições complexas (ex: Transformação de Box-Muller para gerar Normais a partir de Uniformes).\nModelagem: Para entender como a normalização ou outras transformações de features (ex: PCA) afetam a distribuição conjunta dos dados.\nInferência Bayesiana: Na reparametrização de modelos.\n\n\n\n\n\nExemplo 12.1 (Exemplo 2.19) Seja \\(\\underline{X} = (X_1, X_2)\\) com \\(f_{\\underline{X}}(\\underline{x}) = 4 x_1 x_2 I_{[0, 1]}(x_1) I_{[0, 1]}(x_2)\\). Obtenha a distribuição de \\(\\underline{Y} = (Y_1, Y_2)\\) com \\(Y_1 = X_1/X_2\\) e \\(Y_2 = X_1 X_2\\).\nNotemos que \\(\\underline{y} = g(\\underline{x}) = (x_1/x_2, x_1 x_2)\\). A inversa é \\(\\underline{x} = h(\\underline{y})\\): \\(X_1 = (Y_1 Y_2)^{1/2}\\) \\(X_2 = (Y_2 / Y_1)^{1/2}\\)\nO Jacobiano da transformação inversa \\(h(\\underline{y})\\) é: \\[\n\\begin{align*}\n\\frac{\\partial x_1}{\\partial y_1} &= \\frac{1}{2} (Y_1 Y_2)^{-1/2} Y_2 = \\frac{1}{2} \\sqrt{Y_2/Y_1} \\\\\n\\frac{\\partial x_1}{\\partial y_2} &= \\frac{1}{2} (Y_1 Y_2)^{-1/2} Y_1 = \\frac{1}{2} \\sqrt{Y_1/Y_2} \\\\\n\\frac{\\partial x_2}{\\partial y_1} &= \\frac{1}{2} (Y_2 / Y_1)^{-1/2} (-Y_2 / Y_1^2) = -\\frac{1}{2} \\sqrt{Y_1/Y_2} (Y_2/Y_1) = -\\frac{1}{2} \\sqrt{Y_2/Y_1^3} \\\\\n\\frac{\\partial x_2}{\\partial y_2} &= \\frac{1}{2} (Y_2 / Y_1)^{-1/2} (1 / Y_1) = \\frac{1}{2} \\sqrt{Y_1/Y_2} (1/Y_1) = \\frac{1}{2} \\sqrt{1/(Y_1 Y_2)}\n\\end{align*}\n\\] \\[\nJ_h(\\underline{y}) = \\det \\begin{pmatrix} \\frac{1}{2} \\sqrt{Y_2/Y_1} & \\frac{1}{2} \\sqrt{Y_1/Y_2} \\\\ -\\frac{1}{2} \\sqrt{Y_2/Y_1^3} & \\frac{1}{2} \\sqrt{1/(Y_1 Y_2)} \\end{pmatrix}\n= \\frac{1}{4} \\sqrt{\\frac{Y_2}{Y_1} \\frac{1}{Y_1 Y_2}} - (-\\frac{1}{4} \\sqrt{\\frac{Y_1}{Y_2} \\frac{Y_2}{Y_1^3}})\n\\] \\[\n= \\frac{1}{4} \\sqrt{\\frac{1}{Y_1^2}} + \\frac{1}{4} \\sqrt{\\frac{1}{Y_1^2}} = \\frac{1}{4} \\frac{1}{|Y_1|} + \\frac{1}{4} \\frac{1}{|Y_1|} = \\frac{1}{2|Y_1|}\n\\] Como \\(X_1, X_2 \\in [0, 1]\\), temos \\(Y_1=X_1/X_2 &gt; 0\\), então \\(|Y_1| = Y_1\\). Logo \\(|J_h(\\underline{y})| = \\frac{1}{2y_1}\\).\nAplicando a fórmula: \\[\n\\begin{align*}\nf_{\\underline{Y}}(\\underline{y}) &= f_{\\underline{X}}(h(\\underline{y})) |J_h(\\underline{y})| \\\\\n&= 4 x_1 x_2 \\cdot \\frac{1}{2y_1} \\quad \\text{substituindo } x_1, x_2 \\\\\n&= 4 (y_1 y_2)^{1/2} (y_2/y_1)^{1/2} \\cdot \\frac{1}{2y_1} \\\\\n&= 4 (y_2^2)^{1/2} \\cdot \\frac{1}{2y_1} = 4 y_2 \\cdot \\frac{1}{2y_1} = \\frac{2y_2}{y_1}\n\\end{align*}\n\\] O domínio \\(G\\) para \\(\\underline{Y}\\) é determinado pelas restrições \\(0 &lt; x_1 &lt; 1\\) e \\(0 &lt; x_2 &lt; 1\\). \\(0 &lt; (y_1 y_2)^{1/2} &lt; 1 \\implies 0 &lt; y_1 y_2 &lt; 1\\) \\(0 &lt; (y_2 / y_1)^{1/2} &lt; 1 \\implies 0 &lt; y_2 / y_1 &lt; 1 \\implies y_2 &lt; y_1\\) Então, \\(G = \\{(y_1, y_2) : y_1 &gt; 0, y_2 &gt; 0, y_2 &lt; y_1, y_1 y_2 &lt; 1\\}\\). \\[ f_{\\underline{Y}}(y_1, y_2) = \\frac{2y_2}{y_1} I_G(y_1, y_2) \\]\n\n\nExemplo 12.2 (Exemplo 2.20: Soma e Diferença de Normais) Sejam \\(X_1\\) e \\(X_2\\) v.a.s independentes com distribuição \\(N(0, 1)\\). Obtenha a distribuição de \\(\\underline{Y} = (Y_1, Y_2)\\) com \\(Y_1 = X_1 + X_2\\) e \\(Y_2 = X_1 - X_2\\). Verifique se \\(Y_1\\) e \\(Y_2\\) são independentes.\nA transformação é \\(g(x_1, x_2) = (x_1+x_2, x_1-x_2)\\). A inversa é \\(h(y_1, y_2) = (\\frac{y_1 + y_2}{2}, \\frac{y_1 - y_2}{2})\\). O Jacobiano da inversa \\(h\\) é: \\[ J_h(y_1, y_2) = \\det\\left[ \\begin{array}{cc} \\frac{\\partial x_1}{\\partial y_1} & \\frac{\\partial x_1}{\\partial y_2} \\\\ \\frac{\\partial x_2}{\\partial y_1} & \\frac{\\partial x_2}{\\partial y_2} \\end{array} \\right] = \\det\\left[ \\begin{array}{cc} 1/2 & 1/2 \\\\ 1/2 & -1/2 \\end{array} \\right] = -\\frac{1}{4} - \\frac{1}{4} = -\\frac{1}{2} \\] O valor absoluto é \\(|J_h(y_1, y_2)| = 1/2\\).\nA densidade conjunta de \\(X_1, X_2\\) (por independência) é: \\[ f_{\\underline{X}}(x_1, x_2) = f_{X_1}(x_1) f_{X_2}(x_2) = \\frac{1}{\\sqrt{2\\pi}} e^{-x_1^2/2} \\frac{1}{\\sqrt{2\\pi}} e^{-x_2^2/2} = \\frac{1}{2\\pi} e^{-(x_1^2+x_2^2)/2} \\] Aplicando a fórmula do Jacobiano: \\[\n\\begin{align*}\nf_{\\underline{Y}}(y_1, y_2) &= f_{\\underline{X}}(h(y_1, y_2)) |J_h(y_1, y_2)| \\\\\n&= \\frac{1}{2\\pi} \\exp\\left\\{ -\\frac{1}{2} \\left[ \\left(\\frac{y_1+y_2}{2}\\right)^2 + \\left(\\frac{y_1-y_2}{2}\\right)^2 \\right] \\right\\} \\cdot \\frac{1}{2} \\\\\n&= \\frac{1}{4\\pi} \\exp\\left\\{ -\\frac{1}{2} \\left[ \\frac{y_1^2 + 2y_1y_2 + y_2^2}{4} + \\frac{y_1^2 - 2y_1y_2 + y_2^2}{4} \\right] \\right\\} \\\\\n&= \\frac{1}{4\\pi} \\exp\\left\\{ -\\frac{1}{8} (2y_1^2 + 2y_2^2) \\right\\} = \\frac{1}{4\\pi} \\exp\\left\\{ -\\frac{y_1^2}{4} - \\frac{y_2^2}{4} \\right\\}\n\\end{align*}\n\\] Podemos fatorar a densidade conjunta como produto das marginais? \\[ f_{\\underline{Y}}(y_1, y_2) = \\left( \\frac{1}{\\sqrt{4\\pi}} e^{-y_1^2 / (2 \\cdot 2)} \\right) \\left( \\frac{1}{\\sqrt{4\\pi}} e^{-y_2^2 / (2 \\cdot 2)} \\right) \\] Sim! Reconhecemos a forma da densidade Normal \\(N(\\mu=0, \\sigma^2=2)\\). \\(f_{\\underline{Y}}(y_1, y_2) = f_{Y_1}(y_1) f_{Y_2}(y_2)\\), onde \\(Y_1 \\sim N(0, 2)\\) e \\(Y_2 \\sim N(0, 2)\\).\nComo a densidade conjunta fatorou no produto das marginais, \\(Y_1\\) e \\(Y_2\\) são independentes.\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science: Propriedades da Normal e PCA\n\n\n\nEste resultado é muito importante:\n\nSoma/Diferença de Normais: A soma (\\(Y_1\\)) e a diferença (\\(Y_2\\)) de duas Normais independentes também são Normais.\nVariância: A variância da soma/diferença é a soma das variâncias: \\(\\text{Var}(X_1 \\pm X_2) = \\text{Var}(X_1) + \\text{Var}(X_2) = 1 + 1 = 2\\).\nIndependência: A soma e a diferença são independentes. Isso é uma propriedade especial da Normal.\n\nEssa transformação (\\(Y_1=X_1+X_2, Y_2=X_1-X_2\\)) é essencialmente uma rotação de 45 graus no espaço \\((X_1, X_2)\\). O fato de que \\(Y_1\\) e \\(Y_2\\) são independentes (sua covariância é zero) significa que encontramos os eixos principais da distribuição. Isso é a base da Análise de Componentes Principais (PCA), uma técnica fundamental de redução de dimensionalidade. PCA busca rotações do espaço original para encontrar novas variáveis (componentes principais) que são não-correlacionadas (independentes, no caso Normal).",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Método do Jacobiano e Estatísticas de Ordem</span>"
    ]
  },
  {
    "objectID": "aula12.html#estatísticas-de-ordem",
    "href": "aula12.html#estatísticas-de-ordem",
    "title": "12  Método do Jacobiano e Estatísticas de Ordem",
    "section": "12.2 Estatísticas de Ordem",
    "text": "12.2 Estatísticas de Ordem\n\nDefinição 12.1 (Definição 2.8) Variáveis aleatórias que possuem a mesma distribuição são chamadas de identicamente distribuídas (i.d.). Se \\(X_1, \\dots, X_n\\) são v.a.s independentes e i.d. (iid), com função de distribuição \\(F_X\\), dizemos que os \\(X_i\\)’s formam uma amostra aleatória de tamanho \\(n\\).\nAs \\(X_i\\)’s ordenadas em ordem crescente são as estatísticas de ordem da amostra e são representadas por \\(X_{(1)}, X_{(2)}, \\dots, X_{(n)}\\), em que, para \\(\\omega \\in \\Omega\\), \\((X_{(1)}(\\omega), \\dots, X_{(n)}(\\omega))\\) é qualquer permutação que satisfaz \\(X_{(1)}(\\omega) \\le X_{(2)}(\\omega) \\le \\dots \\le X_{(n)}(\\omega)\\).\n\nNota: \\(X_{(1)}\\) é o mínimo da amostra, i.e. \\(X_{(1)} = \\min\\{X_1, \\dots, X_n\\}\\). \\(X_{(n)}\\) é o máximo da amostra, i.e. \\(X_{(n)} = \\max\\{X_1, \\dots, X_n\\}\\).\n\n\n\n\n\n\nDicaPerspectiva de Data Science: Mínimos, Máximos e Quantis\n\n\n\nAs estatísticas de ordem são extremamente práticas:\n\n\\(X_{(1)}\\) (Mínimo): min(column). Usado em análise de risco (pior caso), controle de qualidade (menor tempo de vida), performance (menor latência).\n\\(X_{(n)}\\) (Máximo): max(column). Usado em análise de risco (melhor caso, maior perda), detecção de anomalias (valores extremos), performance (pico de carga).\n\\(X_{(k)}\\) (k-ésima estatística): A base dos quantis e percentis.\n\nA mediana é \\(X_{((n+1)/2)}\\) (se n ímpar) ou a média de \\(X_{(n/2)}\\) e \\(X_{(n/2+1)}\\) (se n par). median(column).\nO Percentil 95 é aproximadamente \\(X_{(0.95 \\cdot n)}\\). quantile(column, 0.95).\n\nAnálise Exploratória: O Box Plot é construído usando estatísticas de ordem (mínimo, Q1=\\(X_{(0.25n)}\\), mediana, Q3=\\(X_{(0.75n)}\\), máximo).\n\n\n\n\nProposição 12.1 (Proposição 2.8) Se \\((X_1, \\dots, X_n)\\) é uma a.a. de X com densidade \\(f\\), então a densidade conjunta das estatísticas de ordem é: \\[ f_{X_{(1)}, \\dots, X_{(n)}}(x_1, \\dots, x_n) = \\begin{cases} n! \\prod_{i=1}^n f(x_i), & x_1 &lt; x_2 &lt; \\dots &lt; x_n \\\\ 0, & \\text{c.c.} \\end{cases} \\]\n\n\nExemplo 12.3 (Exemplo 2.21: FDA do Mínimo e Máximo) Seja \\((X_1, \\dots, X_n)\\) uma a.a. de X com função de distribuição \\(F_X\\). Obtenha expressões para função de distribuição de \\(X_{(1)}\\) e \\(X_{(n)}\\). Temos que, para \\(x \\in \\mathbb{R}\\): \\[\n\\begin{align*}\nF_{X_{(1)}}(x) &= \\mathbb{P}(X_{(1)} \\le x) = \\mathbb{P}(\\min\\{X_1, \\dots, X_n\\} \\le x) \\\\\n&= 1 - \\mathbb{P}(\\min\\{X_1, \\dots, X_n\\} &gt; x) \\\\\n&= 1 - \\mathbb{P}(X_1 &gt; x, \\dots, X_n &gt; x) \\quad \\text{(Mínimo &gt; x sse TODOS &gt; x)}\\\\\n&\\stackrel{\\text{indep.}}{=} 1 - \\prod_{i=1}^n \\mathbb{P}(X_i &gt; x) \\\\\n&= 1 - \\prod_{i=1}^n [1 - \\mathbb{P}(X_i \\le x)] = 1 - \\prod_{i=1}^n [1 - F_{X_i}(x)] \\\\\n&\\stackrel{\\text{i.d.}}{=} 1 - [1 - F_X(x)]^n\n\\end{align*}\n\\] \\[\n\\begin{align*}\nF_{X_{(n)}}(x) &= \\mathbb{P}(X_{(n)} \\le x) = \\mathbb{P}(\\max\\{X_1, \\dots, X_n\\} \\le x) \\\\\n&= \\mathbb{P}(X_1 \\le x, \\dots, X_n \\le x) \\quad \\text{(Máximo &lt;= x sse TODOS &lt;= x)}\\\\\n&\\stackrel{\\text{indep.}}{=} \\prod_{i=1}^n \\mathbb{P}(X_i \\le x) \\\\\n&\\stackrel{\\text{i.d.}}{=} \\prod_{i=1}^n F_X(x) = [F_X(x)]^n\n\\end{align*}\n\\]\n\n\n\n\n\n\n\nDicaPerspectiva de Data Science: Modelando Extremos\n\n\n\nEssas duas fórmulas são muito úteis:\n\nFDA do Mínimo: \\(F_{min}(x) = 1 - [1 - F_X(x)]^n\\)\n\nUsada em Análise de Sobrevivência/Confiabilidade: Se \\(X\\) é o tempo de vida de um componente e temos \\(n\\) componentes em paralelo, o sistema falha quando o último falha (máximo). Se eles estão em série, o sistema falha quando o primeiro falha (mínimo). \\(F_{min}(x)\\) dá a probabilidade do sistema em série falhar antes do tempo \\(x\\).\n\nFDA do Máximo: \\(F_{max}(x) = [F_X(x)]^n\\)\n\nUsada em Gerenciamento de Risco/Engenharia: Qual a probabilidade do pico de carga em \\(n\\) servidores ser menor que \\(x\\)? Qual a probabilidade da pior perda em \\(n\\) investimentos ser menor que \\(x\\)?\n\n\nPodemos derivar essas FDAs para obter as FDPs do mínimo e máximo: * \\(f_{min}(x) = n [1 - F_X(x)]^{n-1} f_X(x)\\) * \\(f_{max}(x) = n [F_X(x)]^{n-1} f_X(x)\\)\n\n\n\nExemplo 12.4 (Exemplo 2.22) \\(X\\) v.a. com \\(f_X(x) = \\frac{1}{2} e^{-|x|}, x \\in \\mathbb{R}\\) (Distribuição de Laplace). Obtenha a distribuição de \\(Y = X^2\\).\nPara \\(y &gt; 0\\): \\[\n\\begin{align*}\nF_Y(y) &= \\mathbb{P}(Y \\le y) = \\mathbb{P}(X^2 \\le y) = \\mathbb{P}(-\\sqrt{y} \\le X \\le \\sqrt{y}) \\\\\n&= \\mathbb{P}(X \\le \\sqrt{y}) - \\mathbb{P}(X &lt; -\\sqrt{y}) \\\\\n&= F_X(\\sqrt{y}) - F_X(-\\sqrt{y}^{-}) \\quad \\text{(Cuidado com pontos discretos, mas aqui X é contínua)} \\\\\n&= F_X(\\sqrt{y}) - F_X(-\\sqrt{y}) \\quad \\text{(pois P(X=x)=0 para X contínua)}\n\\end{align*}\n\\] Derivando a FDA para obter a FDP (usando a Regra da Cadeia): \\[\n\\begin{align*}\nf_Y(y) &= \\frac{d}{dy} F_Y(y) = \\frac{d}{dy} [F_X(\\sqrt{y}) - F_X(-\\sqrt{y})] \\\\\n&= f_X(\\sqrt{y}) \\cdot \\frac{d}{dy}(\\sqrt{y}) - f_X(-\\sqrt{y}) \\cdot \\frac{d}{dy}(-\\sqrt{y}) \\\\\n&= f_X(\\sqrt{y}) \\cdot \\left(\\frac{1}{2\\sqrt{y}}\\right) - f_X(-\\sqrt{y}) \\cdot \\left(-\\frac{1}{2\\sqrt{y}}\\right) \\\\\n&= \\frac{1}{2\\sqrt{y}} [f_X(\\sqrt{y}) + f_X(-\\sqrt{y})]\n\\end{align*}\n\\] Substituindo \\(f_X(x) = \\frac{1}{2} e^{-|x|}\\): \\(f_X(\\sqrt{y}) = \\frac{1}{2} e^{-|\\sqrt{y}|} = \\frac{1}{2} e^{-\\sqrt{y}}\\) (pois \\(y&gt;0 \\implies \\sqrt{y}&gt;0\\)) \\(f_X(-\\sqrt{y}) = \\frac{1}{2} e^{-|-\\sqrt{y}|} = \\frac{1}{2} e^{-\\sqrt{y}}\\) \\[\nf_Y(y) = \\frac{1}{2\\sqrt{y}} [\\frac{1}{2} e^{-\\sqrt{y}} + \\frac{1}{2} e^{-\\sqrt{y}}] = \\frac{1}{2\\sqrt{y}} [e^{-\\sqrt{y}}]\n\\] \\[ f_Y(y) = \\frac{1}{2\\sqrt{y}} e^{-\\sqrt{y}}, \\quad y &gt; 0 \\] (Esta é relacionada à distribuição Gama ou Chi-quadrado).",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Método do Jacobiano e Estatísticas de Ordem</span>"
    ]
  },
  {
    "objectID": "aula12.html#implementação-prática-em-r",
    "href": "aula12.html#implementação-prática-em-r",
    "title": "12  Método do Jacobiano e Estatísticas de Ordem",
    "section": "12.3 Implementação Prática em R",
    "text": "12.3 Implementação Prática em R\n\nVisualizando o Jacobiano (Cartesiano -&gt; Polar)\nVamos transformar pontos \\((X, Y)\\) (Normais independentes) em coordenadas polares \\((R, \\Theta)\\). \\(R = \\sqrt{X^2 + Y^2}\\) \\(\\Theta = \\text{atan2}(Y, X)\\)\nA transformação \\(g(x, y) = (\\sqrt{x^2+y^2}, \\text{atan2}(y, x))\\) não tem um Jacobiano constante. O fator de escala \\(|J|\\) depende do raio \\(r\\).\n\nlibrary(tidyverse)\nlibrary(patchwork)\n\nset.seed(42)\nn_pts &lt;- 5000\ncartesian_data &lt;- tibble(\n  X = rnorm(n_pts, 0, 1),\n  Y = rnorm(n_pts, 0, 1)\n)\n\npolar_data &lt;- cartesian_data |&gt;\n  mutate(\n    R = sqrt(X^2 + Y^2),\n    Theta = atan2(Y, X) # Ângulo em radianos [-pi, pi]\n  )\n\n# Plot Cartesiano (distribuição simétrica)\np_cart &lt;- ggplot(cartesian_data, aes(x = X, y = Y)) +\n  geom_point(alpha = 0.1) +\n  coord_fixed(xlim=c(-3,3), ylim=c(-3,3)) +\n  labs(title = \"Espaço Original (Cartesiano)\") +\n  theme_minimal()\n\n# Plot Polar (distribuição não é uniforme!)\np_polar &lt;- ggplot(polar_data, aes(x = Theta, y = R)) +\n  geom_point(alpha = 0.1) +\n  # coord_polar() # Descomente para ver em formato polar\n  labs(title = \"Espaço Transformado (Polar)\", x=\"Ângulo (Theta)\", y=\"Raio (R)\") +\n  theme_minimal()\n\np_cart + p_polar\n\n\n\n\nTransformação Cartesiana-&gt;Polar. Note como a densidade de pontos muda (efeito do Jacobiano).\n\n\n\n\n\n\n\n\n\n\nDicaObservação Jacobiano Polar\n\n\n\nNo gráfico polar (R vs Theta), a densidade de pontos não é uniforme. Há mais pontos perto de R=0. Isso ocorre porque a transformação cartesiana para polar “comprime” a área perto da origem e “expande” a área longe dela. O Jacobiano \\(|J|=r\\) captura esse fator de escala dependente do raio. A densidade \\(f_{R, \\Theta}(r, \\theta)\\) precisa desse fator \\(r\\) para ser correta.\n\n\n\n\nEstatísticas de Ordem\n\nset.seed(123)\n# Amostra aleatória (IID) de uma Normal\namostra &lt;- rnorm(n = 10, mean = 50, sd = 10)\ncat(\"Amostra Original (X1..X10):\\n\", round(amostra, 1), \"\\n\\n\")\n\nAmostra Original (X1..X10):\n 44.4 47.7 65.6 50.7 51.3 67.2 54.6 37.3 43.1 45.5 \n\n# Ordenar a amostra\nestatisticas_ordem &lt;- sort(amostra)\ncat(\"Estatísticas de Ordem (X(1)..X(10)):\\n\", round(estatisticas_ordem, 1), \"\\n\\n\")\n\nEstatísticas de Ordem (X(1)..X(10)):\n 37.3 43.1 44.4 45.5 47.7 50.7 51.3 54.6 65.6 67.2 \n\n# Mínimo, Máximo, Mediana\nX_min &lt;- min(amostra) # = estatisticas_ordem[1]\nX_max &lt;- max(amostra) # = estatisticas_ordem[10]\nX_mediana &lt;- median(amostra) # = mean(estatisticas_ordem[5], estatisticas_ordem[6])\n\ncat(\"Mínimo X(1):\", round(X_min, 1), \"\\n\")\n\nMínimo X(1): 37.3 \n\ncat(\"Máximo X(10):\", round(X_max, 1), \"\\n\")\n\nMáximo X(10): 67.2 \n\ncat(\"Mediana:\", round(X_mediana, 1), \"\\n\")\n\nMediana: 49.2 \n\n# Quantis (ex: Percentil 25 e 75)\nquantis &lt;- quantile(amostra, probs = c(0.25, 0.75))\ncat(\"Quantil 25% (Q1):\", round(quantis[1], 1), \"\\n\") # ~= X(2.5) -&gt; interpola\n\nQuantil 25% (Q1): 44.7 \n\ncat(\"Quantil 75% (Q3):\", round(quantis[2], 1), \"\\n\") # ~= X(7.5) -&gt; interpola\n\nQuantil 75% (Q3): 53.8 \n\n\n\n\nVerificando as FDAs do Mínimo e Máximo (Exemplo 2.21)\nVamos simular muitas amostras, calcular o min/max de cada uma, e comparar a FDA empírica com a fórmula teórica. Usaremos \\(X_i \\sim U(0, 1)\\) onde \\(F_X(x) = x\\).\n\nTeórica Min: \\(F_{min}(x) = 1 - (1 - x)^n\\)\nTeórica Max: \\(F_{max}(x) = x^n\\)\n\n\nn_amostras &lt;- 10000\nn_tamanho &lt;- 5 # Tamanho de cada amostra\n\n# Gerar n_amostras, cada uma com n_tamanho obs U(0,1)\n# Resultado é uma matriz n_amostras x n_tamanho\nmatriz_amostras &lt;- matrix(runif(n_amostras * n_tamanho), nrow = n_amostras)\n\n# Calcular min e max de cada linha (cada amostra)\nminimos &lt;- apply(matriz_amostras, 1, min)\nmaximos &lt;- apply(matriz_amostras, 1, max)\n\ndf_min_max &lt;- tibble(X_min = minimos, X_max = maximos)\n\n# Plotar FDA Empírica do Mínimo vs. Teórica\np_min &lt;- ggplot(df_min_max, aes(x = X_min)) +\n  stat_ecdf(geom = \"point\", aes(color = \"Empírica\"), alpha=0.5, size=0.5) +\n  stat_function(fun = function(x) 1 - (1 - x)^n_tamanho, aes(color = \"Teórica\"), linewidth=1) +\n  labs(title = \"FDA do Mínimo X(1)\", x = \"x\", y = \"F(x)\") +\n  scale_color_manual(values = c(\"Empírica\" = \"blue\", \"Teórica\" = \"red\")) +\n  theme_minimal() + theme(legend.title=element_blank())\n\n# Plotar FDA Empírica do Máximo vs. Teórica\np_max &lt;- ggplot(df_min_max, aes(x = X_max)) +\n  stat_ecdf(geom = \"point\", aes(color = \"Empírica\"), alpha=0.5, size=0.5) +\n  stat_function(fun = function(x) x^n_tamanho, aes(color = \"Teórica\"), linewidth=1) +\n  labs(title = \"FDA do Máximo X(n)\", x = \"x\", y = \"F(x)\") +\n  scale_color_manual(values = c(\"Empírica\" = \"blue\", \"Teórica\" = \"red\")) +\n  theme_minimal() + theme(legend.title=element_blank())\n\np_min + p_max\n\n\n\n\nFDAs Empíricas (pontos) vs. Teóricas (linhas) para Mínimo e Máximo de n=5 U(0,1).\n\n\n\n\n\n\nVerificando Transformação Univariada \\(Y = X^2\\) (Exemplo 2.22)\nSimulamos \\(X\\) da distribuição de Laplace, calculamos \\(Y = X^2\\), e comparamos o histograma com a \\(f_Y(y)\\) derivada.\n\nn_sim &lt;- 100000\n\n# Função para gerar da Laplace(0, 1): f(x)=0.5*exp(-|x|)\n# (Usando o método da inversa: Exp(1) com sinal aleatório)\nrlaplace &lt;- function(n) {\n  rexp(n, rate = 1) * sample(c(-1, 1), n, replace = TRUE)\n}\n\nX &lt;- rlaplace(n_sim)\nY &lt;- X^2\n\n# Função de densidade teórica derivada para Y\nf_Y_teorica &lt;- function(y) {\n  ifelse(y &lt;= 0, 0, (1 / (2 * sqrt(y))) * exp(-sqrt(y)))\n}\n\n# Plotar\nggplot(tibble(Y = Y), aes(x = Y)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 100, fill = \"orange\", alpha = 0.8) +\n  stat_function(fun = f_Y_teorica, color = \"red\", linewidth = 1) +\n  labs(\n    title = \"Verificação: Y = X^2 (X ~ Laplace)\",\n    subtitle = \"Histograma (Empírico) vs. Curva Vermelha (Teórica)\",\n    x = \"Y = X^2\",\n    y = \"Densidade\"\n  ) +\n  theme_minimal() +\n  # Limitar eixo x para melhor visualização (cauda longa)\n  xlim(0, quantile(Y, 0.98))\n\nWarning: Removed 2000 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\nHistograma de Y=X^2 (X~Laplace) vs. Densidade Teórica Derivada.",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Método do Jacobiano e Estatísticas de Ordem</span>"
    ]
  },
  {
    "objectID": "aula19.html",
    "href": "aula19.html",
    "title": "13  Esperança Condicional",
    "section": "",
    "text": "Definição 13.1 (Definição 4.2) Sejam \\(X\\) e \\(Y\\) v.a.s em \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\). A esperança condicional de \\(X\\) dado \\(Y=y\\), se existir, é dada por: \\[\\begin{align*} E(X|Y=y) &= \\int_{\\mathbb{R}} x dF_{X|Y}(x|Y=y) \\qquad \\text{(integral Riemann-Stieltjes)}\\\\\n& =\n\\begin{cases}\n    \\sum_{x \\in \\mathbb{R}} x \\mathbb{P}(X=x|Y=y), & \\text{se X e Y discretas} \\\\\n    \\int_{\\mathbb{R}} x f_{X|Y}(x|y) dx, & \\text{se X e Y contínuas}\n\\end{cases}\n\\end{align*}\\]\n\nComentários:\n\nSe X é integrável, então \\(E(X|Y=y)\\) existe e é finita quase certamente (com respeito à medida de prob. de Y), isto é, existe boreliano \\(B_0\\) tal que \\(\\mathbb{P}(Y \\in B_0) = 1\\) e \\(E(X|Y=y)\\) é finita \\(\\forall y \\in B_0\\).\nDefinindo \\(\\psi(y) = E(X|Y=y)\\), a v.a. \\(\\psi(Y) = E(X|Y)\\) chama-se esperança condicional de X dado Y. Note que \\(E(X|Y=y)\\) é um número, enquanto \\(E(X|Y)\\) é v.a.\n\n\nTeorema 13.1 (Teorema 4.1 (Esperança Iterada / Lei da Esperança Total)) Sendo X e Y v.a.s em \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\), temos que \\[ E[E(X|Y)] = E(X) \\] desde que as esperanças existam e sejam finitas.\nDemonstração:\nVamos provar separadamente para os casos discreto e contínuo, assumindo que todas as esperanças existem e são finitas.\n\nCaso 1: X e Y são v.a.s discretas\nLembremos que \\(E(X|Y)\\) é uma variável aleatória que assume o valor \\(E(X|Y=y)\\) quando \\(Y=y\\). Portanto, pela definição de esperança de uma função de Y (neste caso, a função \\(\\psi(y) = E(X|Y=y)\\)): \\[ E[E(X|Y)] = \\sum_y E(X|Y=y) \\mathbb{P}(Y=y) \\] Agora, substituímos a definição da esperança condicional para v.a.s discretas, \\(E(X|Y=y) = \\sum_x x \\mathbb{P}(X=x|Y=y)\\): \\[ E[E(X|Y)] = \\sum_y \\left( \\sum_x x \\mathbb{P}(X=x|Y=y) \\right) \\mathbb{P}(Y=y) \\] Usando a definição de probabilidade condicional, \\(\\mathbb{P}(X=x|Y=y) \\mathbb{P}(Y=y) = \\mathbb{P}(X=x, Y=y)\\): \\[ E[E(X|Y)] = \\sum_y \\sum_x x \\mathbb{P}(X=x, Y=y) \\] Podemos trocar a ordem das somas (assumindo convergência absoluta, garantida pela finitude das esperanças): \\[ E[E(X|Y)] = \\sum_x x \\left( \\sum_y \\mathbb{P}(X=x, Y=y) \\right) \\] A soma interna é a probabilidade marginal de X: \\(\\sum_y \\mathbb{P}(X=x, Y=y) = \\mathbb{P}(X=x)\\). \\[ E[E(X|Y)] = \\sum_x x \\mathbb{P}(X=x) \\] Que é, por definição, a esperança de X: \\[ E[E(X|Y)] = E(X) \\]\nCaso 2: X e Y são v.a.s contínuas\nDe forma análoga, \\(E(X|Y)\\) é uma v.a. que é função de Y, \\(\\psi(Y)\\), onde \\(\\psi(y) = E(X|Y=y)\\). A esperança de uma função de Y é calculada como: \\[ E[E(X|Y)] = \\int_{-\\infty}^{\\infty} E(X|Y=y) f_Y(y) dy \\] Substituímos a definição da esperança condicional para v.a.s contínuas, \\(E(X|Y=y) = \\int_{-\\infty}^{\\infty} x f_{X|Y}(x|y) dx\\): \\[ E[E(X|Y)] = \\int_{-\\infty}^{\\infty} \\left( \\int_{-\\infty}^{\\infty} x f_{X|Y}(x|y) dx \\right) f_Y(y) dy \\] Usando a relação \\(f_{X|Y}(x|y) f_Y(y) = f_{X,Y}(x, y)\\): \\[ E[E(X|Y)] = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} x f_{X,Y}(x, y) dx dy \\] Podemos trocar a ordem de integração (pelo Teorema de Fubini-Tonelli, aplicável pois as esperanças são finitas): \\[ E[E(X|Y)] = \\int_{-\\infty}^{\\infty} x \\left( \\int_{-\\infty}^{\\infty} f_{X,Y}(x, y) dy \\right) dx \\] A integral interna é a densidade marginal de X: \\(\\int_{-\\infty}^{\\infty} f_{X,Y}(x, y) dy = f_X(x)\\). \\[ E[E(X|Y)] = \\int_{-\\infty}^{\\infty} x f_X(x) dx \\] Que é, por definição, a esperança de X: \\[ E[E(X|Y)] = E(X) \\]\n\n\n\nExemplo 13.1 (Exemplo 4.4) Sejam X e Y v.a.s com f.d.p. conjunta \\[ f_{X,Y}(x, y) = 2 \\cdot I_A(x, y) \\] onde \\(A = \\{(x, y) \\in \\mathbb{R}^2 : x &gt; 0, y &gt; 0, x+y &lt; 1\\}\\).\n\nObtenha \\(f_{X|Y}(x|y)\\).\n\nPrimeiro, a marginal de Y: \\[ f_Y(y) = \\int_0^{1-y} 2 dx = 2 [x]_0^{1-y} = 2(1-y), \\quad \\text{para } 0 &lt; y &lt; 1. \\]\nAgora a condicional: \\[ f_{X|Y}(x|y) = \\frac{f_{X,Y}(x, y)}{f_Y(y)} = \\frac{2}{2(1-y)} = \\frac{1}{1-y}, \\quad \\text{para } 0 &lt; x &lt; 1-y \\text{ (e } 0 &lt; y &lt; 1 \\text{)} \\] Ou seja, \\(X|Y=y \\sim U(0, 1-y).\\)\n\nObtenha \\(E(X|Y=y)\\). \\[ E(X|Y=y) = \\int_{\\mathbb{R}} x f_{X|Y}(x|y) dx = \\int_0^{1-y} x \\frac{1}{1-y} dx \\] \\[ = \\frac{1}{1-y} \\left[ \\frac{x^2}{2} \\right]_0^{1-y} = \\frac{1}{1-y} \\frac{(1-y)^2}{2} = \\frac{1-y}{2} \\]\nCalcule \\(E[E(X|Y)]\\). Primeiro, \\(E(Y)\\): \\[ E(Y) = \\int_0^1 y f_Y(y) dy = \\int_0^1 y \\cdot 2(1-y) dy = 2 \\int_0^1 (y - y^2) dy \\] \\[ = 2 \\left[ \\frac{y^2}{2} - \\frac{y^3}{3} \\right]_0^1 = 2 (\\frac{1}{2} - \\frac{1}{3}) = 2 (\\frac{1}{6}) = \\frac{1}{3} \\] Agora, \\(E[E(X|Y)]\\): \\[ E[E(X|Y)] = E\\left[ \\frac{1-Y}{2} \\right] = \\frac{1 - E(Y)}{2} = \\frac{1 - 1/3}{2} = \\frac{2/3}{2} = \\frac{1}{3} \\] Note que \\(E(X) = 1/3\\) por simetria, confirmando o Teorema 13.1\n\n\n\nDefinição 13.2 (Definição 4.3) Sejam X e Y v.a.s em \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\). A variância condicional de X, dado que \\(Y=y\\), é dada por \\[ Var(X|Y=y) = E\\{[X - E(X|Y=y)]^2 | Y=y \\} \\] \\[ = E[X^2 | Y=y] - [E(X|Y=y)]^2 \\] supondo que as esperanças existam e sejam finitas.\n\n\nDefinição 13.3 (Definição 4.4) Sejam X, Y, Z v.a.s em \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\). A covariância condicional entre X e Y dado \\(Z=z\\) é \\[ Cov(X, Y | Z=z) = E(XY | Z=z) - E(X|Z=z)E(Y|Z=z) \\] desde que as esperanças existam e sejam finitas.",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Esperança Condicional</span>"
    ]
  },
  {
    "objectID": "aula20.html",
    "href": "aula20.html",
    "title": "14  Tipos de Convergência",
    "section": "",
    "text": "Contexto: \\(X, X_1, X_2, \\dots\\) v.a.s definidas em \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\). Nosso objetivo é estudar formas de convergência de \\(X_n\\) para \\(X\\).\nNota: Convergência de funções. Dizemos que \\(X_n \\rightarrow X\\) quando \\(n \\rightarrow \\infty\\) se, para cada \\(\\epsilon &gt; 0\\) e \\(\\omega \\in \\Omega\\), \\(\\exists n_0 = n(\\epsilon, \\omega)\\) tal que \\[|X_n(\\omega) - X(\\omega)| &lt; \\epsilon, \\forall n &gt; n_0.\\]\nNote que, para cada \\(\\omega \\in \\Omega\\), \\(X_n(\\omega)\\) é uma sequência de números e a definição acima é a definição de convergência de sequências reais. Essa convergência é chamada de convergência pontual ou ponto a ponto.\nNa teoria das probabilidades existem outras formas de convergência que são de interesse.\n\nDefinição 14.1 (Definição 5.1 (Convergência Quase Certa)) A sequência \\(\\{X_n\\}_{n \\ge 1}\\) tem convergência quase certa para X se existir um conjunto \\(A \\in \\mathcal{F}\\) tal que \\(\\mathbb{P}(A) = 0\\) e \\(X_n(\\omega) \\rightarrow X(\\omega)\\) em \\(A^c\\), quando \\(n \\rightarrow \\infty\\). Equivalentemente, se, e somente se, \\[ \\mathbb{P}(\\lim_{n \\to \\infty} X_n = X) = 1 \\Leftrightarrow \\mathbb{P}(\\{\\omega \\in \\Omega : \\lim_{n \\to \\infty} X_n(\\omega) = X(\\omega)\\}) = 1 \\] Notação: \\(X_n \\xrightarrow{q.c.} X\\).\nNote que a convergência quase certa é a convergência pontual com probabilidade 1. Essa convergência é também chamada de convergência forte.\n\n\nDefinição 14.2 (Definição 5.2 (Convergência em Probabilidade)) A sequência \\(\\{X_n\\}_{n \\ge 1}\\) tem convergência em probabilidade para X se, \\(\\forall \\epsilon &gt; 0\\), \\[ \\lim_{n \\to \\infty} \\mathbb{P}(|X_n - X| \\geq \\epsilon) = 0 \\Leftrightarrow \\lim_{n \\to \\infty} \\mathbb{P}(\\{\\omega \\in \\Omega : |X_n(\\omega) - X(\\omega)| \\geq \\epsilon\\}) = 0 \\] Notação: \\(X_n \\xrightarrow{P} X\\).\nA convergência em probabilidade não diz respeito à convergência pontual, apenas afirma que, para \\(n\\) grande, as v.a.s \\(X_n\\) e X são aproximadamente iguais com probabilidade alta. Essa convergência é chamada de convergência fraca.\n\n\nExemplo 14.1 (Exemplo 5.1) Seja \\(\\Omega = (0, 1)\\) e defina \\(X_n(\\omega) = \\frac{\\omega}{n}\\). Para cada \\(\\omega \\in \\Omega\\), \\(\\lim_{n \\to \\infty} X_n(\\omega) = 0\\). Dessa forma, \\[ \\mathbb{P}(\\{\\omega \\in \\Omega : \\lim_{n \\to \\infty} X_n(\\omega) = 0\\}) = \\mathbb{P}(\\Omega) = 1 \\] Logo, \\(X_n \\xrightarrow{q.c.} 0\\). Note que \\(X_n \\rightarrow 0\\) (pontualmente).\n\n\nExemplo 14.2 (Exemplo 5.2) Seja \\(X_n \\sim \\text{Bernoulli}(p_n)\\), \\(p_n = (1/2)^n, n=1, 2, \\dots\\) Mostre que \\(X_n \\xrightarrow{P} 0\\).\nPara todo \\(\\epsilon &gt; 0\\), \\[ 0 \\le \\lim_{n \\to \\infty} \\mathbb{P}(|X_n| \\ge \\epsilon) \\le \\lim_{n \\to \\infty} \\frac{E(|X_n|)}{\\epsilon} \\] Como \\(X_n\\) só assume valores 0 e 1, \\(|X_n| = X_n\\). \\(E(X_n) = p_n = (1/2)^n\\) \\[ \\le \\lim_{n \\to \\infty} \\frac{(1/2)^n}{\\epsilon} = 0 \\] Logo, \\(\\lim_{n \\to \\infty} \\mathbb{P}(|X_n - 0| \\ge \\epsilon) = 0\\), portanto \\(X_n \\xrightarrow{P} 0\\).\n\n\nExemplo 14.3 (Exemplo 5.3) Seja \\(([0, 1], \\mathcal{B}([0, 1]), \\mathbb{P})\\) um espaço de probabilidade com \\(\\mathbb{P}(I) = \\text{comprimento}(I), I \\in \\mathcal{B}([0, 1])\\). Seja \\(X_n\\) tal que \\(X_n(\\omega) = n I_{[0, 1/n]}(\\omega), n=1, 2, \\dots\\) Mostre que \\(X_n \\xrightarrow{q.c.} 0\\).\nNote que \\(X_n(0) = n.\\) Mostramos que \\(\\lim_{n \\to \\infty} X_n(\\omega) = 0, \\forall \\omega \\in (0, 1]\\). (Se \\(\\omega &gt; 0\\), existe \\(N\\) tal que \\(1/N &lt; \\omega\\). Para todo \\(n \\ge N\\), \\(1/n \\le 1/N &lt; \\omega\\), então \\(\\omega \\notin (0, 1/n]\\), logo \\(X_n(\\omega) = n \\cdot 0 = 0\\). Portanto, \\(\\lim_{n \\to \\infty} X_n(\\omega) = 0\\).) Como \\(\\mathbb{P}((0, 1]) = 1\\), temos que \\(X_n \\xrightarrow{q.c.} 0\\).\n\nA principal ferramenta para provar convergência quase certa é o lema de Borel-Cantelli, enunciado a seguir.\n\nTeorema 14.1 (Lema de Borel-Cantelli) Sejam \\(A_1, A_2, \\dots\\) eventos em \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\), em que \\(\\mathbb{P}(A_n) = p_n, n=1, 2, \\dots\\) Temos que\n\nSe \\(\\sum_{n=1}^\\infty p_n &lt; \\infty\\), então \\(\\mathbb{P}(\\limsup A_n) = 0\\).\nSe \\(\\sum_{n=1}^\\infty p_n = \\infty\\) e os \\(A_n\\)’s são independentes, então \\(\\mathbb{P}(\\limsup A_n) = 1\\).\n\nDemonstração: Seja \\(B_n = \\bigcup_{k=n}^\\infty A_k\\). Notemos que \\(\\{B_n\\}_{n \\ge 1}\\) é uma sequência não crescente e \\(\\lim_{n \\to \\infty} B_n = \\bigcap_{n=1}^\\infty B_n = \\bigcap_{n=1}^\\infty \\bigcup_{k=n}^\\infty A_k = \\limsup A_n\\).\n(i): \\[ 0 \\le \\mathbb{P}(\\limsup A_n) = \\mathbb{P}(\\lim_{n \\to \\infty} B_n) = \\lim_{n \\to \\infty} \\mathbb{P}(B_n) \\quad (\\text{Continuidade da Prob.}) \\] \\[ = \\lim_{n \\to \\infty} \\mathbb{P}(\\bigcup_{k=n}^\\infty A_k) \\le \\lim_{n \\to \\infty} \\sum_{k=n}^\\infty \\mathbb{P}(A_k) \\quad (\\text{Subaditividade}) \\] \\[ = \\lim_{n \\to \\infty} \\sum_{k=n}^\\infty p_k = 0 \\quad (\\text{Cauda de série convergente}) \\] Logo, \\(\\mathbb{P}(\\limsup A_n) = 0\\).\n(ii):\nVamos trabalhar com eventos complementares. Seja \\((\\limsup A_n)^c =\\)  \\(\\bigcup_{n=1}^\\infty B_n^c\\) com \\(B_n^c = \\bigcap_{k=n}^\\infty A_k^c,\\) \\(n=1,2,\\dots\\). Consideremos \\(m\\) inteiro positivo com \\(m &gt; n\\). Então \\[ 0 \\le \\mathbb{P}(B_n^c) = \\mathbb{P}(\\bigcap_{k=n}^\\infty A_k^c) \\le \\mathbb{P}(\\bigcap_{k=n}^m A_k^c) \\] \\[ \\stackrel{\\text{indep.}}{=} \\prod_{k=n}^m \\mathbb{P}(A_k^c) = \\prod_{k=n}^m (1 - p_k) \\] Usando a desigualdade \\(1 - x \\le e^{-x}, \\forall x \\in [0,1]\\): \\[ \\le \\prod_{k=n}^m e^{-p_k} = \\exp\\left\\{ -\\sum_{k=n}^m p_k \\right\\} \\] Fixado n, temos que \\(\\lim_{m \\to \\infty} \\sum_{k=n}^m p_k = \\infty\\), pois a série diverge. \\[ \\Rightarrow \\lim_{m \\to \\infty} \\exp\\left\\{ -\\sum_{k=n}^m p_k \\right\\} = 0 \\] Logo, \\(\\mathbb{P}(B_n^c) = 0\\). Assim, \\[ \\mathbb{P}((\\limsup A_n)^c) = \\mathbb{P}(\\bigcup_{n=1}^\\infty B_n^c) \\le \\sum_{n=1}^\\infty \\mathbb{P}(B_n^c) = \\sum_{n=1}^\\infty 0 = 0,\\] pois \\(\\mathbb{P}(B_n^c)=0, \\forall n=1,2,\\dots.\\) \\[\\Rightarrow \\mathbb{P}((\\limsup A_n)^c) = 0 \\Rightarrow \\mathbb{P}(\\limsup A_n) = 1.\\]\n\n\nLema 14.1 (Lema 5.1) Seja \\(A_{n,m} = \\{\\omega \\in \\Omega : |X_n(\\omega) - X(\\omega)| &gt; 1/m\\}\\). Se, para todo \\(m \\in \\mathbb{N}\\), \\(\\sum_{n=1}^\\infty \\mathbb{P}(A_{n,m}^c) &lt; \\infty\\), então \\(X_n \\xrightarrow{q.c.} X\\). (Prova: exercício)\nComentário: Equivalentemente, se \\(\\sum_{n=1}^\\infty \\mathbb{P}(|X_n - X| \\geq \\epsilon) &lt; \\infty, \\forall \\epsilon &gt; 0\\), então \\(X_n \\xrightarrow{q.c.} X\\). \n\n\nExemplo 14.4 (Exemplo 5.4) Seja \\(\\{X_n\\}_{n \\ge 1}\\) uma sequência de v.a.s iid com \\(X_n \\sim U(0, 1), n=1, 2, \\dots\\) Seja \\(Y_n = \\min\\{X_1, \\dots, X_n\\}, n \\ge 1\\). Mostre que \\(Y_n \\xrightarrow{q.c.} 0\\).\nTemos que, \\(\\forall n \\in \\mathbb{N}\\) e \\(\\forall \\epsilon \\in (0, 1)\\): \\[\\begin{align*} \\mathbb{P}(|Y_n - 0| &gt; \\epsilon) &= \\mathbb{P}(Y_n &gt; \\epsilon) \\quad\\quad (\\text{pois } Y_n &gt; 0) \\\\\n&= \\mathbb{P}(\\min\\{X_1, \\dots, X_n\\} &gt; \\epsilon) \\\\\n&= \\mathbb{P}(X_1 &gt; \\epsilon, \\dots, X_n &gt; \\epsilon) \\\\\n&\\stackrel{\\text{iid}}{=} [\\mathbb{P}(X_1 &gt; \\epsilon)]^n = [1 - \\mathbb{P}(X_1 \\le \\epsilon)]^n \\\\\n&= [1 - F_{X_1}(\\epsilon)]^n \\\\\n&= (1 - \\epsilon)^n\n\\end{align*}\\] Logo, \\[ \\sum_{n=1}^\\infty \\mathbb{P}(|Y_n| &gt; \\epsilon) = \\sum_{n=1}^\\infty (1 - \\epsilon)^n \\] Esta é uma série geométrica com razão \\(r = (1 - \\epsilon)\\). Como \\(\\epsilon \\in (0, 1)\\), temos \\(0 &lt; r &lt; 1\\). A série converge. Pelo Lema 5.1 ((lema-conv-qc?)), Portanto, \\(Y_n \\xrightarrow{q.c.} 0\\).",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Tipos de Convergência</span>"
    ]
  },
  {
    "objectID": "aula21.html",
    "href": "aula21.html",
    "title": "15  Outros Tipos de Convergência",
    "section": "",
    "text": "Definição 15.1 (Definição 5.3 (Convergência em Distribuição)) Sejam \\(\\{X_n\\}_{n \\ge 1}\\) e X v.a.s com f.d.a. \\(F_n\\) e F, respectivamente. Dizemos que \\(X_n\\) converge em distribuição para X se, para todo ponto \\(x\\) em que F é contínua, tivermos \\[ \\lim_{n \\to \\infty} F_n(x) = F(x) \\] Notação: \\(X_n \\xrightarrow{D} X\\).\n\n\nExemplo 15.1 (Exemplo 5.5) Seja \\(\\{X_n\\}_{n \\ge 1}\\) uma sequência de v.a.s independentes (e identicamente distribuídas) com distribuição Uniforme em \\((0, \\theta)\\), \\(\\theta &gt; 0\\). Mostre que \\(X_{(n)} \\xrightarrow{D} \\theta\\).\nSeja \\(X_{(n)} = \\max\\{X_1, \\dots, X_n\\}\\). A f.d.a. de \\(X_{(n)}\\) é: \\[\n\\begin{align*}\nF_{X_{(n)}}(x) &= \\mathbb{P}(X_{(n)} \\le x) = \\mathbb{P}(\\max\\{X_1, \\dots, X_n\\} \\le x) \\\\\n&= \\mathbb{P}(X_1 \\le x, \\dots, X_n \\le x) \\\\\n&\\stackrel{\\text{iid}}{=} \\prod_{i=1}^n \\mathbb{P}(X_i \\le x) = [\\mathbb{P}(X_1 \\le x)]^n\n\\end{align*}\n\\] Como \\(X_1 \\sim U(0, \\theta)\\), \\(F_{X_1}(x) = x/\\theta\\) para \\(x \\in (0, \\theta)\\). \\[ F_{X_{(n)}}(x) = (x/\\theta)^n, \\quad \\forall x \\in (0, \\theta) \\] A f.d.a. completa é: \\[ F_{X_{(n)}}(x) = \\begin{cases} 0, & x &lt; 0 \\\\ (x/\\theta)^n, & 0 \\le x &lt; \\theta \\\\ 1, & x \\ge \\theta \\end{cases} \\] A f.d.a. da v.a. constante \\(X = \\theta\\) é: \\[ F_X(x) = \\begin{cases} 0, & x &lt; \\theta \\\\ 1, & x \\ge \\theta \\end{cases} \\]  \n\n\n\n\nEm que $X=, portanto \\(X_{(n)} \\xrightarrow{D} \\theta.\\)\n\nO requisito de continuidade é necessário para evitar anomalias. Veja o próximo exemplo.\n\nExemplo 15.2 (Exemplo 5.6) Sejam \\(\\{X_n\\}_{n \\ge 1}\\) e X v.a.s com \\(X_n = 1/n, n \\ge 1,\\) e \\(X = 0\\). Mostre que \\(X_n \\xrightarrow{D} X\\).\nA f.d.a. de \\(X_n\\) (v.a. degenerada em \\(1/n\\)) é: \\[ F_{X_n}(x) = \\begin{cases} 0, & x &lt; 1/n \\\\ 1, & x \\ge 1/n \\end{cases} \\] A f.d.a. de X (v.a. degenerada em 0) é: \\[ F_X(x) = \\begin{cases} 0, & x &lt; 0 \\\\ 1, & x \\ge 0 \\end{cases} \\] Analisando o limite:\n\nPara \\(x &lt; 0\\): \\(\\lim_{n \\to \\infty} F_{X_n}(x) = \\lim_{n \\to \\infty} 0 = 0 = F_X(x)\\).\nPara \\(x &gt; 0\\): \\(\\exists N\\) tal que \\(1/N &lt; x\\). Para \\(n \\ge N\\), \\(1/n \\le 1/N &lt; x\\), então \\(F_{X_n}(x) = 1\\). \\(\\lim_{n \\to \\infty} F_{X_n}(x) = 1 = F_X(x)\\).\n\nNotemos que \\(F_X(x)\\) é descontínua em \\(x=0\\). \\(F_{X_n}(0) = 0\\) para todo \\(n\\), mas \\(F_X(0) = 1\\). Dessa forma, \\(\\lim_{n \\to \\infty} F_{X_n}(x) = F_X(x)\\), para todo ponto \\(x\\) tal que \\(F_X\\) é contínua, isto é, \\(x \\neq 0\\). Logo, \\(X_n \\xrightarrow{D} X\\).\n\nSejam \\(X, X_1, X_2, \\dots\\) v.a.s com funções características \\(\\varphi, \\varphi_1, \\varphi_2, \\dots\\) respectivamente. Se \\(\\varphi_{X_n}(t) \\rightarrow \\varphi(t)\\), para todo \\(t \\in \\mathbb{R}\\), e \\(\\varphi\\) é contínua em \\(t=0\\), então \\(\\varphi\\) é a função característica de alguma v.a., digamos \\(\\varphi = \\varphi_X\\), e \\(X_n \\xrightarrow{D} X\\).\nEm particular, se \\(\\varphi_{X_n}(t) \\rightarrow e^{-t^2/2}\\) para todo \\(t\\), então \\(X_n \\xrightarrow{D} Z\\), onde \\(Z \\sim N(0, 1)\\).\nUm resultado similar vale para f.g.m.: Se \\(\\exists \\epsilon &gt; 0\\) tal que \\(\\lim_{n \\to \\infty} M_{X_n}(t) = M_X(t), \\forall t \\in [-\\epsilon, \\epsilon]\\), então \\(X_n \\xrightarrow{D} X\\).\n\nDefinição 15.2 (Definição 5.4 (Convergência em Média)) A sequência \\(\\{X_n\\}_{n \\ge 1}\\) tem convergência em média r, ou em \\(L^r\\), para X se \\[ \\lim_{n \\to \\infty} E[|X_n - X|^r] = 0 \\] Notação: \\(X_n \\xrightarrow{L^r} X\\). Para \\(r=2\\), temos convergência em média quadrática.\n\n\nExemplo 15.3 (Exemplo 5.7) Sejam \\(X_n\\) v.a.s com \\(X_n \\sim U(0, 1/n)\\). Mostre que \\(X_n \\xrightarrow{L^r} 0\\) para qualquer \\(r \\ge 1\\).\nTemos que \\(X_n \\sim U(0, 1/n)\\), \\(n \\ge 1\\). A f.d.p. é \\(f_n(x) = n I_{(0, 1/n)}(x)\\). Dessa forma, \\[\n\\begin{align*}\nE(|X_n - 0|^r) &= E(X_n^r) \\quad (\\text{pois } X_n &gt; 0) \\\\\n&= \\int_0^{1/n} x^r n \\, dx \\\\\n&= n \\left[ \\frac{x^{r+1}}{r+1} \\right]_0^{1/n} \\\\\n&= n \\left( \\frac{(1/n)^{r+1}}{r+1} - 0 \\right) \\\\\n&= \\frac{n}{r+1} \\frac{1}{n^{r+1}} \\\\\n&= \\frac{1}{(r+1)n^r}\n\\end{align*}\n\\] Assim, \\[ \\lim_{n \\to \\infty} E(|X_n - 0|^r) = \\lim_{n \\to \\infty} \\frac{1}{(r+1)n^r} = 0, \\quad \\text{para qualquer } r \\ge 1 \\] Logo, \\(X_n \\xrightarrow{L^r} 0, \\forall r \\ge 1\\).\n\n\nProposição 15.1 (Proposição 5.1 (Relações entre tipos de convergência)) Sejam \\(\\{X_n\\}\\) e X v.a.s em \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\). Então,\n\nSe \\(\\{ X_n \\xrightarrow{q.c.} X \\text{ ou } X_n \\xrightarrow{L^r} X \\} \\implies X_n \\xrightarrow{P} X\\)\nSe \\(X_n \\xrightarrow{P} X \\implies X_n \\xrightarrow{D} X\\)\nSe \\(X_n \\xrightarrow{D} c \\text{ (constante)} \\implies X_n \\xrightarrow{P} c.\\)\n\n\n\nProposição 15.2 (Proposição 5.2 (Conv. em distribuição - casos discreto e contínuo))  \n\nSe a f.p. de \\(X_n\\) é \\(p_n(x_k) = \\mathbb{P}(X_n = x_k)\\) e a de X é \\(p(x_k)\\), e as v.a.s tomam valores \\(x_1, x_2, \\dots\\), então \\[ p_n(x_k) \\rightarrow p(x_k), n \\rightarrow \\infty \\text{ e }\\forall k \\implies X_n \\xrightarrow{D} X \\]\nSejam \\(X, X_1, X_2, \\dots\\) com f.d.p. \\(f, f_1, f_2, \\dots\\), respectivamente. Se \\(f_n(x) \\rightarrow f(x)\\) quando \\(n \\rightarrow \\infty\\) para quase todo \\(x\\) relativamente à medida de Lebesgue, então \\(X_n \\xrightarrow{D} X\\). Nota: O conjunto \\(\\{x : f_n(x) \\not\\rightarrow f(x)\\}\\) deve ter medida de Lebesgue nula (comprimento zero).",
    "crumbs": [
      "Módulo Probabilidade",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Outros Tipos de Convergência</span>"
    ]
  },
  {
    "objectID": "020_inferencia.html",
    "href": "020_inferencia.html",
    "title": "Módulo Inferência Estatística",
    "section": "",
    "text": "TODO: descrever essa parte",
    "crumbs": [
      "Módulo Inferência Estatística"
    ]
  },
  {
    "objectID": "aula24.html",
    "href": "aula24.html",
    "title": "16  24 Introdução: O Dilema do Teste A/B",
    "section": "",
    "text": "16.1 O Framework da Inferência: Do Problema à Modelagem\nImagine que você é um Cientista de Dados em uma empresa de e-commerce. O time de design propõe um novo botão de “Comprar” (Versão B), com uma cor diferente, alegando que ele aumentará a taxa de cliques em relação ao botão atual (Versão A).\nPara validar essa hipótese, você implementa um teste A/B: 500 usuários aleatórios veem a Versão A, e outros 500 veem a Versão B. Ao final do experimento, você observa os resultados:\nA Versão B parece melhor. Mas a pergunta central que define a sua carreira como cientista é: essa diferença de 1% é real e significativa, ou pode ser apenas fruto do acaso? Se mostrarmos os botões para outros 500 usuários, talvez os resultados se invertam.\nPara responder a essa pergunta com confiança, precisamos de um framework rigoroso para “aprender” sobre a realidade a partir de dados limitados e ruidosos. Esta aula irá construir esse framework, peça por peça, usando a inferência estatística.\nO primeiro passo é traduzir nosso problema prático para uma linguagem matemática formal.",
    "crumbs": [
      "Módulo Inferência Estatística",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>24 Introdução: O Dilema do Teste A/B</span>"
    ]
  },
  {
    "objectID": "aula24.html#o-framework-da-inferência-do-problema-à-modelagem",
    "href": "aula24.html#o-framework-da-inferência-do-problema-à-modelagem",
    "title": "16  24 Introdução: O Dilema do Teste A/B",
    "section": "",
    "text": "Dados (observações): Os dados são valores observados de variáveis aleatórias que seguem uma distribuição de probabilidade conjunta P, que pertence a uma classe (conhecida) \\(\\mathcal{P}\\). Frequentemente, \\(\\mathcal{P}\\) é indexada por um parâmetro \\(\\theta \\in \\Theta\\). \\[ \\mathcal{P} = \\{ P_{\\theta}, \\theta \\in \\Theta \\} \\]\nObjetivo: fazer inferência sobre \\(\\theta\\) ou \\(g(\\theta)\\) com base nos dados observados.\n\nestimação pontual ou intervalar\nteste de hipóteses\n\n\n\nPerspectiva de Data Science:\n\nParâmetro (\\(\\theta\\)): A Verdade Oculta. \\(\\theta\\) é a verdadeira, mas desconhecida, taxa de cliques de um botão se pudéssemos mostrá-lo a um número infinito de usuários. É a realidade que queremos descobrir. No nosso caso, temos dois parâmetros de interesse: \\(\\theta_A\\) e \\(\\theta_B\\).\nModelo (\\(\\mathcal{P}\\)): Nossa Hipótese sobre o Mundo. \\(\\mathcal{P}\\) é a nossa escolha de modelagem. Ao rodar o teste A/B, assumimos que a decisão de cada usuário de clicar (ou não) é um evento independente, como um “cara ou coroa” com uma moeda viciada. Esse processo é descrito pela distribuição de Bernoulli. Portanto, nosso modelo para a Versão B é a família de todas as distribuições de Bernoulli, \\(\\mathcal{P} = \\{ \\text{Bernoulli}(\\theta_B), \\theta_B \\in [0, 1] \\}\\).",
    "crumbs": [
      "Módulo Inferência Estatística",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>24 Introdução: O Dilema do Teste A/B</span>"
    ]
  },
  {
    "objectID": "aula24.html#estimação-pontual-o-melhor-chute-a-partir-dos-dados",
    "href": "aula24.html#estimação-pontual-o-melhor-chute-a-partir-dos-dados",
    "title": "16  24 Introdução: O Dilema do Teste A/B",
    "section": "16.2 Estimação Pontual: O Melhor Chute a partir dos Dados",
    "text": "16.2 Estimação Pontual: O Melhor Chute a partir dos Dados\nNosso primeiro objetivo é usar os dados para dar um “chute” único e bem fundamentado sobre o valor do nosso parâmetro \\(\\theta\\).\nIngredientes:\n\nUma função real g, definida no espaço paramétrico \\(\\Theta\\), cujo valor \\(g(\\theta)\\) é o que gostaríamos de obter informação / estimar. \\(g(\\theta)\\): estimando.\nUm vetor aleatório \\(\\underline{X}\\) (observável) tomando valores no espaço amostral \\(\\mathcal{X}\\), de acordo com uma distribuição \\(P_{\\theta} \\in \\mathcal{P}\\). O valor observado de \\(\\underline{X}\\), \\(\\underline{x}\\) é o conjunto de dados. Muitas vezes, nos referimos a \\(\\underline{X} = (X_1, ..., X_n)\\) como amostra.\n\nIdeia: especificar um valor plausível para \\(g(\\theta)\\).\n\nDefinição 16.1 (Estatística e Estimador) Qualquer função da amostra \\(\\underline{X}\\) que não depende de quantidades desconhecidas é uma estatística. Uma estatística usada para estimar \\(g(\\theta)\\) é chamada de estimador.\nNotação:\n\nEstatística: \\(T = T(X_1, ..., X_n)\\)\nEstimador: \\(\\delta = \\delta(X_1, ..., X_n)\\) ou \\(\\hat{\\theta} = \\hat{\\theta}(X_1, ..., X_n)\\)\nValor observado do estimador, isto é \\(\\delta(\\underline{x})\\), é chamado de estimativa.\n\n\n\nPerspectiva de Data Science:\n\nAmostra (\\(\\underline{X}\\)): A Evidência Coletada. Para o botão B, nossa amostra é um vetor de 500 elementos, \\(\\underline{X} = (X_1, ..., X_{500})\\), onde \\(X_i=1\\) se o i-ésimo usuário clicou, e \\(X_i=0\\) caso contrário.\nEstimador (\\(\\hat{\\theta}\\)): Nosso Algoritmo de Aprendizagem. O estimador é a receita ou algoritmo que transforma os dados brutos em um chute para \\(\\theta\\). A receita mais intuitiva para estimar a taxa de cliques é simplesmente calcular a média da amostra: \\(\\hat{\\theta}_B = \\bar{X}_n = \\frac{1}{n}\\sum X_i\\).\nEstimativa: A estimativa é o número que nosso algoritmo produz: \\(\\hat{\\theta}_B(\\underline{x}) = 30/500 = 0.06\\).\n\n\n\nExemplo 16.1 (Tempo de Vida de Lâmpadas) Seja X = tempo de vida de lâmpadas de certa marca. Assuma que \\(X \\sim \\text{exp}(\\theta)\\), \\(\\theta &gt; 0\\). Suponha que \\((X_1, ..., X_n)\\) é uma a.a. de X.\nAqui, temos que \\(\\mathcal{P} = \\{f_{\\theta}, \\theta &gt; 0\\}\\), com \\(f_{\\theta}(x) = \\theta e^{-\\theta x} \\mathbb{I}_{(0, \\infty)}(x)\\).\nExemplos de estatísticas:\n\n\\(S_n = X_1 + ... + X_n\\) (tempo total de vida)\n\\(X_{(1)} = \\min\\{X_1, ..., X_n\\}\\) (menor tempo de vida)\n\\(\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i\\) (média amostral dos tempos de vida)\n\\(S_n^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\bar{X}_n)^2\\) (variância amostral)\n\nQual é um estimador razoável para o tempo médio de vida? E para \\(\\theta\\)?\n\n\\(g(\\theta) = E_{\\theta}(X) = \\frac{1}{\\theta} \\rightarrow\\) possível estimador: \\(\\widehat{g(\\theta)} = \\bar{X}_n\\).\n\\(g(\\theta) = \\theta \\rightarrow\\) possível estimador: \\(\\hat{\\theta} = \\frac{1}{\\bar{X}_n}\\).",
    "crumbs": [
      "Módulo Inferência Estatística",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>24 Introdução: O Dilema do Teste A/B</span>"
    ]
  },
  {
    "objectID": "aula24.html#o-motor-da-inferência-a-função-de-verossimilhança",
    "href": "aula24.html#o-motor-da-inferência-a-função-de-verossimilhança",
    "title": "16  24 Introdução: O Dilema do Teste A/B",
    "section": "16.3 O Motor da Inferência: A Função de Verossimilhança",
    "text": "16.3 O Motor da Inferência: A Função de Verossimilhança\nTemos um algoritmo intuitivo para estimar \\(\\theta\\) (a média amostral), mas como podemos justificar que ele é um bom algoritmo? E se houvesse outros? A resposta está em um dos conceitos mais importantes da estatística e do Machine Learning: a verossimilhança.\nA verossimilhança responde à seguinte pergunta: “Dado os dados que observei, qual valor do parâmetro \\(\\theta\\) torna minhas observações mais prováveis (ou menos surpreendentes)?”\nEla funciona como uma função de pontuação (score) para diferentes hipóteses sobre a “verdade” \\(\\theta\\).\n\nDefinição 16.2 (Função de Verossimilhança) A função de verossimilhança de \\(\\theta \\in \\Theta\\), com base na amostra observada \\(\\underline{x} = (x_1, ..., x_n)\\), é dada por \\[ L(\\theta) = L(\\theta; \\underline{x}) = f_{X_1, ..., X_n}(x_1, ..., x_n; \\theta), \\quad \\theta \\in \\Theta \\]\nNota: se \\(\\underline{X}\\) é uma a.a. de X, então \\(L(\\theta) = \\prod_{i=1}^{n} f_X(x_i; \\theta)\\) (i.i.d.’s)\n\n\nExemplo 16.2 (Funções de Verossimilhança) Obtenha a função de verossimilhança em cada caso assumindo uma a.a. \\(\\underline{X} = (X_1, ..., X_n)\\) de X.\na) \\(X \\sim \\text{Bernoulli}(\\theta)\\) \\[ L(\\theta) = \\prod_{i=1}^{n} \\theta^{x_i} (1-\\theta)^{1-x_i} = \\theta^{\\sum_{i=1}^{n} x_i} (1-\\theta)^{n - \\sum_{i=1}^{n} x_i}, \\quad \\theta \\in (0,1). \\] \\(\\rightarrow L(\\theta)\\) depende da realização de \\(T = \\sum_{i=1}^{n} X_i\\).\n\nConexão com o Teste A/B: Esta é exatamente a função de verossimilhança para o nosso problema! Para o botão B, observamos \\(\\sum x_i = 30\\) e \\(n=500\\). A função se torna \\(L(\\theta_B) = \\theta_B^{30}(1-\\theta_B)^{470}\\). Agora podemos “testar” diferentes valores de \\(\\theta_B\\) e ver qual deles maximiza essa função. O valor que a maximiza é, de fato, \\(30/500 = 0.06\\), justificando nosso estimador intuitivo. Este é o Princípio da Máxima Verossimilhança.\n\nb) \\(X \\sim \\text{Poisson}(\\theta)\\) \\[ L(\\theta) = \\prod_{i=1}^{n} \\frac{e^{-\\theta} \\theta^{x_i}}{x_i!} = \\frac{e^{-n\\theta} \\theta^{\\sum_{i=1}^{n} x_i}}{\\prod_{i=1}^{n} x_i!}, \\quad \\theta &gt; 0. \\] \\(\\rightarrow L(\\theta)\\) depende da realização de \\(T = \\sum_{i=1}^{n} X_i\\).\nc) \\(X \\sim U(0, \\theta)\\), \\(\\theta &gt; 0\\) \\[ L(\\theta) = \\prod_{i=1}^{n} f_{\\theta}(x_i) = \\prod_{i=1}^{n} \\frac{1}{\\theta} \\mathbb{I}_{(0, \\theta)}(x_i) = \\frac{1}{\\theta^n} \\prod_{i=1}^{n} \\mathbb{I}_{(0, \\theta)}(x_i) \\] A indicadora \\(\\prod_{i=1}^{n} \\mathbb{I}_{(0, \\theta)}(x_i) = 1\\) se, e somente se, \\(0 &lt; x_i &lt; \\theta\\) para todo \\(i=1, ..., n\\), o que é equivalente a \\(0 &lt; x_{(1)} \\le ... \\le x_{(n)} &lt; \\theta\\). Então, \\[ L(\\theta) = \\frac{1}{\\theta^n} \\mathbb{I}_{(x_{(n)}, \\infty)}(\\theta), \\quad \\theta &gt; 0 \\] \\(\\rightarrow L(\\theta)\\) envolve a realização de \\(T = X_{(n)}\\).\nd) \\(X \\sim N(\\mu, \\sigma^2)\\), \\(\\theta = (\\mu, \\sigma^2)\\), \\(\\mu \\in \\mathbb{R}, \\sigma^2 &gt; 0\\) \\[ L(\\theta) = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x_i - \\mu)^2}{2\\sigma^2}} = \\frac{1}{(2\\pi\\sigma^2)^{n/2}} e^{-\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i - \\mu)^2} \\] \\[ = \\frac{1}{(2\\pi)^{n/2}} \\frac{1}{(\\sigma^2)^{n/2}} \\exp\\left\\{-\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i^2 - 2x_i\\mu + \\mu^2)\\right\\} \\] \\[ = \\frac{1}{(2\\pi)^{n/2}} \\frac{1}{(\\sigma^2)^{n/2}} \\exp\\left\\{-\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} x_i^2 + \\frac{\\mu}{\\sigma^2} \\sum_{i=1}^{n} x_i - \\frac{n\\mu^2}{2\\sigma^2}\\right\\}, \\quad \\mu \\in \\mathbb{R}, \\sigma^2 &gt; 0. \\] \\(\\rightarrow L(\\theta)\\) envolve a realização de \\(T_n = (\\sum_{i=1}^{n} X_i^2, \\sum_{i=1}^{n} X_i)\\).\n\n\nConexão com Aprendizagem Estatística: O processo de “treinar” um modelo de Aprendizagem Estatística (como uma Regressão Logística ou mesmo uma rede neural para classificação) é, em sua essência, um processo de otimização para encontrar os parâmetros do modelo (\\(\\theta\\)) que maximizam a função de verossimilhança (ou a log-verossimilhança) para os dados de treinamento. O framework que construímos aqui é a base teórica para a maior parte do aprendizado de máquina supervisionado.",
    "crumbs": [
      "Módulo Inferência Estatística",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>24 Introdução: O Dilema do Teste A/B</span>"
    ]
  },
  {
    "objectID": "aula24.html#implementação-prática-em-r",
    "href": "aula24.html#implementação-prática-em-r",
    "title": "16  24 Introdução: O Dilema do Teste A/B",
    "section": "16.4 Implementação Prática em R",
    "text": "16.4 Implementação Prática em R\n\nNa aula, afirmamos que a nossa estimativa intuitiva para a taxa de cliques (6%) era justificada pelo Princípio da Máxima Verossimilhança. Ou seja, de todas as “verdades” possíveis (\\(\\theta_B\\)), o valor \\(0.06\\) é o que torna os dados que realmente observamos (\\(k=30\\) cliques em \\(n=500\\) tentativas) os mais prováveis.\nVamos provar isso visualmente. Em vez de usar cálculo para encontrar o máximo da função, vamos simplesmente “testar” milhares de valores de \\(\\theta_B\\) e plotar a pontuação de verossimilhança que cada um recebe.\nConforme o Exemplo (a), a função de verossimilhança para um processo Bernoulli é:\n\\[L(\\theta) = \\theta^{k} (1-\\theta)^{n - k}\\]\nOnde:\n\n\\(n = 500\\) (visualizações da Versão B)\n\\(k = 30\\) (cliques na Versão B)\n\nNota Importante: \\(L(\\theta)\\) é um número absurdamente pequeno (ex: \\(0.06^{30} \\times (1-0.06)^{470}\\)). Computadores têm dificuldade com números tão próximos de zero. Por isso, na prática, nós sempre trabalhamos com a Log-Verossimilhança (ou “log-likelihood”).\n\\[\\ell(\\theta) = \\log(L(\\theta)) = k \\cdot \\log(\\theta) + (n - k) \\cdot \\log(1-\\theta)\\]\nEncontrar o \\(\\theta\\) que maximiza \\(L(\\theta)\\) é o mesmo que encontrar o \\(\\theta\\) que maximiza \\(\\ell(\\theta)\\), mas os números são muito mais estáveis.\nNão precisamos implementar essa função manualmente. O R já a possui: é a função de densidade da distribuição Binomial, dbinom(). Pedindo o logarítmico dela (log = TRUE), obtemos exatamente a log-verossimilhança.\nVamos: 1. Definir nossos dados observados. 2. Criar um “grid” de hipóteses para \\(\\theta_B\\) (ex: de 0.01 a 0.15). 3. Calcular a log-verossimilhança para cada hipótese. 4. Plotar e encontrar o pico.\n\nlibrary(ggplot2) \n\n# Nossos dados observados para a Versão B\nn_B &lt;- 500\ncliques_B &lt;- 30\nestimativa_observada &lt;- cliques_B / n_B\n\n# Criar um \"grid\" de hipóteses para a verdadeira taxa de cliques (theta_B)\n# Vamos testar 1000 valores possíveis entre 1% e 15%\nhipoteses_theta &lt;- seq(from = 0.01, to = 0.15, by = 0.0001)\n\n# Calcular a log-verossimilhança para cada hipótese\nlog_like &lt;- dbinom(x = cliques_B, \n                   size = n_B, \n                   prob = hipoteses_theta, \n                   log = TRUE)\n\n# Preparar os dados para plotar\ndf_like &lt;- data.frame(\n  theta = hipoteses_theta,\n  log_likelihood = log_like\n)\n\n# Encontrar o valor de theta que maximiza a log-verossimilhança\ntheta_max &lt;- hipoteses_theta[which.max(log_like)]\n\nprint(paste(\"Estimativa Observada (nosso 'chute'):\", estimativa_observada))\n\n[1] \"Estimativa Observada (nosso 'chute'): 0.06\"\n\nprint(paste(\"Estimativa de Máxima Verossimilhança (pico do gráfico):\", theta_max))\n\n[1] \"Estimativa de Máxima Verossimilhança (pico do gráfico): 0.06\"\n\nggplot(df_like, aes(x = theta, y = log_likelihood)) +\n  geom_line(color = \"blue\", size = 1) +\n  geom_vline(xintercept = theta_max, \n             color = \"red\", \n             linetype = \"dashed\", \n             size = 1) +\n  labs(\n    title = \"O Princípio da Máxima Verossimilhança na Prática\",\n    subtitle = paste(\"O pico da curva (vermelho) está em\", round(theta_max, 2), \"que é exatamente a nossa estimativa observada.\"),\n    x = \"Hipótese sobre a 'Verdadeira' Taxa de Cliques (theta_B)\",\n    y = \"Log-Verossimilhança (Pontuação da Hipótese)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nComo o gráfico demonstra, a função de log-verossimilhança atinge seu valor máximo exatamente em \\(\\theta = 0.06\\).\nIsso confirma nossa intuição: o “melhor chute” para a realidade desconhecida (\\(\\theta_B\\)) é, de fato, a média que observamos nos nossos dados. O que fizemos aqui foi validar nosso estimador intuitivo \\(\\hat{\\theta} = \\bar{X}_n\\) usando o rigoroso framework da Máxima Verossimilhança.",
    "crumbs": [
      "Módulo Inferência Estatística",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>24 Introdução: O Dilema do Teste A/B</span>"
    ]
  }
]